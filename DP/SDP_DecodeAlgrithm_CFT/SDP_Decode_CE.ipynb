{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import math\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "from gpt2.modeling_gpt2 import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CanaryDataset(Dataset):\n",
    "    def __init__(self, canary, tokenizer, num_digit):\n",
    "        self.canary = canary\n",
    "        self.tokenizer = tokenizer\n",
    "        if num_digit == 1:\n",
    "            self.data = self.build_data_1()\n",
    "        elif num_digit == 2:\n",
    "            self.data = self.build_data_2()\n",
    "        elif num_digit == 3:\n",
    "            self.data = self.build_data_3()\n",
    "        elif num_digit == 4:\n",
    "            self.data = self.build_data_4()\n",
    "        elif num_digit == 5:\n",
    "            self.data = self.build_data_5()\n",
    "        elif num_digit == 6:\n",
    "            self.data = self.build_data_6()\n",
    "    \n",
    "    def build_data_1(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            text = f'我的单号是54168{i}'\n",
    "            texts.append(text)\n",
    "            encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "    \n",
    "    def build_data_2(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                text = f'我的单号是5416{i}{j}'\n",
    "                texts.append(text)\n",
    "                encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "\n",
    "    def build_data_3(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    text = f'我的单号是541{i}{j}{k}'\n",
    "                    texts.append(text)\n",
    "                    encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "    \n",
    "    def build_data_4(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    for l in range(10):\n",
    "                        text = f'我的单号是54{i}{j}{k}{l}'\n",
    "                        texts.append(text)\n",
    "                        encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "    \n",
    "    def build_data_5(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    for l in range(10):\n",
    "                        for m in range(10):\n",
    "                            text = f'我的单号是5{i}{j}{k}{l}{m}'\n",
    "                            texts.append(text)\n",
    "                            encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "    \n",
    "    def build_data_6(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    for l in range(10):\n",
    "                        for m in range(10):\n",
    "                            for n in range(10):\n",
    "                                text = f'我的单号是{i}{j}{k}{l}{m}{n}'\n",
    "                                texts.append(text)\n",
    "                                encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def collate(self, unpacked_data):\n",
    "        texts, encoded_texts = zip(*unpacked_data)\n",
    "        max_length = max([len(encoded_text) for encoded_text in encoded_texts])\n",
    "        padded_encoded_texts = [\n",
    "            encoded_text + [self.tokenizer.pad_token_id] * (max_length - len(encoded_text))\n",
    "            for encoded_text in encoded_texts\n",
    "        ]\n",
    "        return texts, torch.tensor(padded_encoded_texts)\n",
    "\n",
    "def calculate_ppl(inputs, model, sigma, tokenizer):\n",
    "    device = model.device\n",
    "    input_ids = inputs.to(device)\n",
    "    label_ids = input_ids.clone()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, labels=label_ids, sigma=sigma, tokenizer=tokenizer)\n",
    "        loss = output.loss\n",
    "        sequence_lengths = len(input_ids)\n",
    "        ppl_steps = torch.exp(loss / sequence_lengths)\n",
    "\n",
    "    return ppl_steps.cpu().numpy()\n",
    "\n",
    "def get_exposure(model, dataloader, CANARY, TOTAL_CANDIDATES, sigma, tokenizer):\n",
    "    ppls = {}\n",
    "    forward_pbar = tqdm(dataloader)\n",
    "    forward_pbar.set_description('forward execution')\n",
    "    for batch_input in forward_pbar:\n",
    "        input_text, input_encoded_text = batch_input\n",
    "        # batch_ppl = calculate_ppl(input_encoded_text, model)\n",
    "        batch_ppl = [calculate_ppl(encoded_text, model, sigma, tokenizer) for encoded_text in input_encoded_text]\n",
    "        ppls.update(dict(zip(input_text, batch_ppl)))\n",
    "        forward_pbar.set_postfix({'ppl': '{:.7f}'.format(np.array(batch_ppl).mean())})\n",
    "\n",
    "    sorted_ppls = {k: (i+1, v) for i, (k, v) in enumerate(sorted(ppls.items(), key=lambda item: item[1]))}\n",
    "    N = len(sorted_ppls)\n",
    "    canary_rank, canary_ppl = sorted_ppls[CANARY]\n",
    "\n",
    "    canary_exposure = math.log(TOTAL_CANDIDATES, 2) - math.log(canary_rank, 2)\n",
    "\n",
    "    print(\"canary ppl = \", canary_ppl)\n",
    "    print(\"canary exposure = \", canary_exposure)\n",
    "    print(\"canary ranking = \", canary_rank)\n",
    "\n",
    "    return canary_exposure, canary_rank, canary_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel::init\n",
      "config =  GPT2Config {\n",
      "  \"_name_or_path\": \"..\\\\..\\\\Attack_Canary\\\\Tiny_CFT_GPT2\\\\model\\\\best_model\\\\\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"output_past\": true,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 320\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "using device:cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(21128, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"..\\\\..\\\\Attack_Canary\\\\Tiny_CFT_GPT2\\\\model\\\\best_model\\\\\"\n",
    "tok_path = '..\\\\..\\\\Raw_GPT2\\\\vocab.txt'\n",
    "CANARY = '我的单号是541684'\n",
    "tokenizer = BertTokenizer(vocab_file=tok_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device:{}'.format(device))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.tokenization_bert.BertTokenizer"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "now testing generate  1  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5001.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 1/1 [00:01<00:00,  1.92s/it, ppl=2.5854137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  2.565043\n",
      "canary exposure =  1.7369655941662063\n",
      "canary ranking =  3\n",
      "============================================================\n",
      "============================================================\n",
      "now testing generate  2  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 526.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 7/7 [00:03<00:00,  1.80it/s, ppl=2.5968392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  2.6018865\n",
      "canary exposure =  0.6214883767462709\n",
      "canary ranking =  65\n",
      "============================================================\n",
      "============================================================\n",
      "now testing generate  3  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 50.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 63/63 [00:38<00:00,  1.65it/s, ppl=2.6122794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  2.6178288\n",
      "canary exposure =  0.26881675842779984\n",
      "canary ranking =  830\n",
      "============================================================\n",
      "============================================================\n",
      "now testing generate  4  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 625/625 [06:10<00:00,  1.69it/s, ppl=2.5879192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  2.5818481\n",
      "canary exposure =  1.875142532744242\n",
      "canary ranking =  2726\n",
      "============================================================\n",
      "============================================================\n",
      "now testing generate  5  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 6250/6250 [1:01:09<00:00,  1.70it/s, ppl=2.5979857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  2.5682805\n",
      "canary exposure =  3.1182884008733787\n",
      "canary ranking =  11516\n",
      "============================================================\n",
      "============================================================\n",
      "now testing generate  6  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:05<00:00, 12.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 62500/62500 [10:02:16<00:00,  1.73it/s, ppl=2.5985806]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  2.5712838\n",
      "canary exposure =  2.8920818534292785\n",
      "canary ranking =  134709\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "test_num = [1, 2, 3, 4, 5, 6]\n",
    "sigma = 0.810546875\n",
    "for i in test_num:\n",
    "    print('='*60)\n",
    "    print('now testing generate ', i, ' number:')\n",
    "    canary_corpus = CanaryDataset(CANARY, tokenizer, i)\n",
    "    print('len(canary_corpus) = ', len(canary_corpus))\n",
    "    dataloader = DataLoader(dataset=canary_corpus,\n",
    "                            shuffle=False,\n",
    "                            batch_size=16,\n",
    "                            collate_fn=canary_corpus.collate)\n",
    "\n",
    "    canary_exposure, canary_rank, canary_ppl = get_exposure(model, dataloader, CANARY, len(canary_corpus), sigma, tokenizer)\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
