{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2.modeling_gpt2 import GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers import BertTokenizer, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"Util to make training reproducible\"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    if os.getenv(\"CUBLAS_WORKSPACE_CONFIG\") is not None:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def worker_init(worked_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def set_logger(path):\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    handler = logging.FileHandler(path + \"/train_log.txt\")\n",
    "    logger.setLevel(level=logging.INFO)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(filename)s - %(funcName)s - %(lineno)s - %(levelname)s\\n%(message)s\",\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    console = logging.StreamHandler()\n",
    "    console.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.addHandler(console)\n",
    "\n",
    "\n",
    "class Chinese_Medical_DS(Dataset):\n",
    "    def __init__(self, path, tokenizer, max_len=1024):\n",
    "        self.path = path\n",
    "        sentence = []\n",
    "        self.private_positions_list = []\n",
    "        \n",
    "        self.total_private_tokens = 0\n",
    "        self.total_tokens = 0\n",
    "        self.private_tokens_per_sentence = []\n",
    "        \n",
    "        with open(self.path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                sen_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(line.strip()))\n",
    "                full_sen = []\n",
    "                \n",
    "                full_sen.append(tokenizer.convert_tokens_to_ids('[MASK]'))\n",
    "                full_sen.extend(sen_ids)\n",
    "                full_sen.append(tokenizer.convert_tokens_to_ids('[CLS]'))\n",
    "                private_positions = [i for i, token_id in enumerate(full_sen) if tokenizer.decode([token_id]).isdigit()]\n",
    "                self.private_positions_list.append(private_positions)\n",
    "                if len(full_sen) <= max_len:\n",
    "                    sentence.append(full_sen)\n",
    "                \n",
    "                num_private_tokens = len(private_positions)\n",
    "                self.total_private_tokens += num_private_tokens\n",
    "                self.total_tokens += len(full_sen)\n",
    "                self.private_tokens_per_sentence.append(num_private_tokens)\n",
    "                \n",
    "        self.data = sentence\n",
    "        \n",
    "        # 计算平均每句话中的隐私token数\n",
    "        average_private_tokens_per_sentence = sum(self.private_tokens_per_sentence) / len(self.private_tokens_per_sentence)\n",
    "\n",
    "        # 计算总的隐私token占总token的比例\n",
    "        private_token_ratio = self.total_private_tokens / self.total_tokens\n",
    "\n",
    "        # 计算隐私token个数的均值和方差\n",
    "        private_token_mean = np.mean(self.private_tokens_per_sentence)\n",
    "        private_token_variance = np.var(self.private_tokens_per_sentence)\n",
    "\n",
    "        # 打印统计信息\n",
    "        print(f\"Average private tokens per sentence: {average_private_tokens_per_sentence:.2f}\")\n",
    "        print(f\"Private token ratio: {private_token_ratio:.4f}\")\n",
    "        print(f\"Private token count mean: {private_token_mean:.2f}\")\n",
    "        print(f\"Private token count variance: {private_token_variance:.2f}\")\n",
    "        \n",
    "    # need to overload\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # need to overload\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.data[idx]\n",
    "        target = input\n",
    "        private_positions = self.private_positions_list[idx]\n",
    "        return input, target, private_positions\n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, save_path, patience=2, verbose=True, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            save_path : 模型保存文件夹\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.save_path = save_path\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        model_to_save.save_pretrained(self.save_path + 'best_model')\n",
    "        \n",
    "        # path = os.path.join(self.save_path, \"best_network.pth\")\n",
    "        # torch.save(model.state_dict(), path)  # 这里会存储迄今最优模型的参数\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "tok_path = '..\\\\..\\\\Raw_GPT2\\\\vocab.txt'\n",
    "pretrain_model_path = \"..\\\\..\\\\Raw_GPT2\\\\\"\n",
    "output_dir = \"model\\\\\"\n",
    "\n",
    "epochs = 50\n",
    "warmup_steps = 1000\n",
    "lr = 1e-5\n",
    "gradient_accumulation = 18\n",
    "max_grad_norm = 1.0\n",
    "log_step = 10000\n",
    "set_logger(output_dir)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel::init\n",
      "config =  GPT2Config {\n",
      "  \"_name_or_path\": \"..\\\\..\\\\Raw_GPT2\\\\\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"output_past\": true,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 320\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 14:36:42 - 945538542.py - <module> - 4 - INFO\n",
      "using device:cuda\n",
      "2023-04-01 14:36:42 - 945538542.py - <module> - 4 - INFO\n",
      "using device:cuda\n",
      "2023-04-01 14:36:42 - 945538542.py - <module> - 4 - INFO\n",
      "using device:cuda\n",
      "2023-04-01 14:36:43 - 945538542.py - <module> - 7 - INFO\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(21128, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",
      ")\n",
      "2023-04-01 14:36:43 - 945538542.py - <module> - 7 - INFO\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(21128, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",
      ")\n",
      "2023-04-01 14:36:43 - 945538542.py - <module> - 7 - INFO\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(21128, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer(vocab_file=tok_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(pretrain_model_path)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "logger.info('using device:{}'.format(device))\n",
    "model.train()\n",
    "model.to(device)\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average private tokens per sentence: 1.22\n",
      "Private token ratio: 0.0055\n",
      "Private token count mean: 1.22\n",
      "Private token count variance: 4.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 14:37:13 - 3687209076.py - <module> - 5 - INFO\n",
      "len(train_dataloader), len(valid_dataloader) = 9000, 1500\n",
      "2023-04-01 14:37:13 - 3687209076.py - <module> - 5 - INFO\n",
      "len(train_dataloader), len(valid_dataloader) = 9000, 1500\n",
      "2023-04-01 14:37:13 - 3687209076.py - <module> - 5 - INFO\n",
      "len(train_dataloader), len(valid_dataloader) = 9000, 1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average private tokens per sentence: 1.22\n",
      "Private token ratio: 0.0055\n",
      "Private token count mean: 1.22\n",
      "Private token count variance: 5.27\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Chinese_Medical_DS(\"..\\\\..\\\\Data\\\\tiny_train.txt\", tokenizer)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, worker_init_fn=worker_init)\n",
    "valid_dataset = Chinese_Medical_DS(\"..\\\\..\\\\Data\\\\tiny_valid.txt\", tokenizer)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, worker_init_fn=worker_init)\n",
    "logger.info(\"len(train_dataloader), len(valid_dataloader) = {}, {}\".format(len(train_dataloader), len(valid_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
    "                                                          num_training_steps=len(train_dataloader))\n",
    "tb_path = output_dir + \"/tb\"\n",
    "if not os.path.exists(tb_path):\n",
    "    os.mkdir(tb_path)\n",
    "writer = SummaryWriter(tb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1e-05, 0.810546875)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_log = len(train_dataloader) * np.log(len(train_dataloader))\n",
    "delta = 1.0 / train_num_log if 1.0 / train_num_log < 1e-5 else 1e-5\n",
    "epsilon = 0.5\n",
    "sigma = 0.810546875\n",
    "epsilon, delta, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 14:31:40 - 2840535088.py - <module> - 6 - INFO\n",
      "epoch 1\n",
      "2023-04-01 14:31:40 - 2840535088.py - <module> - 6 - INFO\n",
      "epoch 1\n",
      "2023-04-01 14:31:40 - 2840535088.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 14:31:40.233154\n",
      "2023-04-01 14:31:40 - 2840535088.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 14:31:40.233154\n",
      "epoch-1:   0%|          | 0/9000 [00:00<?, ?it/s, loss=4.0664477]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 2140, 2140,  671, 4684, 4717,  833, 3221, 1538, 3694, 1036, 8043,\n",
      "        2769, 2157, 2140, 2140,  738, 3221, 3300,  673,  702, 3299,  749, 8024,\n",
      "         702, 2094, 2798, 8399, 8024,  860, 7028, 2798, 1282, 1061, 3165, 8024,\n",
      "        5307, 2382, 2476, 2458, 1673, 2349,  679, 5052, 3221, 4717, 1286, 6230,\n",
      "        6820, 3221, 4635, 1921, 8024, 2769, 6574, 4542,  800, 3221, 1538, 3694,\n",
      "        1036, 8024, 6821, 1008, 1408, 8043, 6716, 3332, 4765, 2207, 8024, 1928,\n",
      "        1741,  856,  754, 3633, 2382, 8024, 1928, 1184,  510, 1400, 2520, 4764,\n",
      "        8024, 3359, 6956, 2398, 1439, 2793, 1928,  511, 7568, 4764,  510, 4649,\n",
      "        5502, 2160, 3351,  511, 7755, 7977, 2382, 5862, 1400,  754, 2399, 7977,\n",
      "        8024, 1139, 4280, 2454, 1400,  684, 2382, 7231,  855,  511, 1928, 1355,\n",
      "        5301, 6763, 5445, 6772, 2208,  511, 1184, 1727, 1394, 2879, 3241, 8024,\n",
      "        7553, 3359,  704, 5296, 1377, 3300, 5018,  753, 1727, 7305,  511, 1724,\n",
      "        5501, 4764, 8024, 4507,  754, 7505, 2372, 3351, 2474, 8024, 1068, 5688,\n",
      "        1377, 6814, 2428, 2482, 2835, 8024, 2797, 2900, 5110, 4764, 8024, 2207,\n",
      "        2900,  704, 5688, 7755, 1355, 5509,  679, 5679,  886, 2207, 2900, 1403,\n",
      "        1079, 2482, 2835, 8024, 2900, 7755, 4764, 8024, 2797, 2958,  676, 1349,\n",
      "        4157, 1403, 6823, 4999, 4919,  855, 8024, 2382, 6224, 6858, 6581, 2958,\n",
      "        5292,  510, 5770, 7490, 6639, 8024, 2859, 6644, 4413, 6956, 5276, 1288,\n",
      "        3144,  809,  677, 2642, 1036, 1439, 2469, 2501, 4649, 5292,  511, 2382,\n",
      "        1439, 4385, 1139, 1328, 7608, 1469, 1585, 1075, 1737, 7410,  511,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2140, 2140,  671, 4684, 4717,  833, 3221, 1538, 3694, 1036, 8043,\n",
      "        2769, 2157, 2140, 2140,  738, 3221, 3300,  673,  702, 3299,  749, 8024,\n",
      "         702, 2094, 2798, 8399, 8024,  860, 7028, 2798, 1282, 1061, 3165, 8024,\n",
      "        5307, 2382, 2476, 2458, 1673, 2349,  679, 5052, 3221, 4717, 1286, 6230,\n",
      "        6820, 3221, 4635, 1921, 8024, 2769, 6574, 4542,  800, 3221, 1538, 3694,\n",
      "        1036, 8024, 6821, 1008, 1408, 8043, 6716, 3332, 4765, 2207, 8024, 1928,\n",
      "        1741,  856,  754, 3633, 2382, 8024, 1928, 1184,  510, 1400, 2520, 4764,\n",
      "        8024, 3359, 6956, 2398, 1439, 2793, 1928,  511, 7568, 4764,  510, 4649,\n",
      "        5502, 2160, 3351,  511, 7755, 7977, 2382, 5862, 1400,  754, 2399, 7977,\n",
      "        8024, 1139, 4280, 2454, 1400,  684, 2382, 7231,  855,  511, 1928, 1355,\n",
      "        5301, 6763, 5445, 6772, 2208,  511, 1184, 1727, 1394, 2879, 3241, 8024,\n",
      "        7553, 3359,  704, 5296, 1377, 3300, 5018,  753, 1727, 7305,  511, 1724,\n",
      "        5501, 4764, 8024, 4507,  754, 7505, 2372, 3351, 2474, 8024, 1068, 5688,\n",
      "        1377, 6814, 2428, 2482, 2835, 8024, 2797, 2900, 5110, 4764, 8024, 2207,\n",
      "        2900,  704, 5688, 7755, 1355, 5509,  679, 5679,  886, 2207, 2900, 1403,\n",
      "        1079, 2482, 2835, 8024, 2900, 7755, 4764, 8024, 2797, 2958,  676, 1349,\n",
      "        4157, 1403, 6823, 4999, 4919,  855, 8024, 2382, 6224, 6858, 6581, 2958,\n",
      "        5292,  510, 5770, 7490, 6639, 8024, 2859, 6644, 4413, 6956, 5276, 1288,\n",
      "        3144,  809,  677, 2642, 1036, 1439, 2469, 2501, 4649, 5292,  511, 2382,\n",
      "        1439, 4385, 1139, 1328, 7608, 1469, 1585, 1075, 1737, 7410,  511,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([27], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 1/9000 [00:00<32:41,  4.59it/s, loss=2.8775215]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 2111, 2094, 2793, 3425,  860, 1355, 4142, 1355, 4173, 2582, 3416,\n",
      "        1394, 4415, 7650, 7608, 8043, 2769, 2157, 4638, 2111, 2094, 3221, 4511,\n",
      "        2140, 2140, 8024,  124, 2259, 8024, 1157, 2458, 1993, 8024, 1624, 2094,\n",
      "        4706, 3300, 4157, 4578, 8024, 1355, 4385, 8024,  845, 3300, 6768, 2544,\n",
      "        4638, 1495, 1644, 8024, 1369, 1912, 8024, 3300, 4157, 1355, 4173,  738,\n",
      "        3766, 5125, 4868, 8024, 6435, 7309, 8038, 2111, 2094, 2793, 3425,  860,\n",
      "        1355, 4142, 1355, 4173, 2582, 3416, 1394, 4415, 7650, 7608,  511, 1355,\n",
      "        4385, 2793, 3425,  860, 4142, 1218, 2553, 6206, 1350, 3198, 5314, 2111,\n",
      "        2094, 3780, 4545, 8024, 1369, 1912, 3189, 2382, 7650, 7608, 1377,  809,\n",
      "        1914, 1391,  671,  763, 5922, 5831, 1469, 3717, 3362, 8024, 7370,  749,\n",
      "        3926, 3909,  679, 1173, 4080,  722, 1912, 8024, 6821, 5102, 7608, 4289,\n",
      "        4638, 5852, 1075, 5162,  738, 3221, 3683, 6772,  705, 2168, 4638, 8024,\n",
      "        3300, 1221,  754, 2376, 1221, 2850, 2539, 4565, 4567, 8024,  679, 6814,\n",
      "        3717, 3362, 4638, 6848, 2885,  677, 6206, 3800, 2692, 6912, 1048, 6814,\n",
      "         754, 2170, 1117, 4638, 8024, 1377,  809, 6848, 2885,  671,  763, 2595,\n",
      "        2398, 4638, 8024, 3683, 1963, 5741, 3362, 8024, 4334, 4347, 3425,  722,\n",
      "        5102, 4638, 8024, 3189, 2382, 7650, 7608, 2418, 6848, 2885, 3211,  754,\n",
      "        3867, 1265, 4638, 8024, 3683, 1963, 5114,  510, 7481, 3340, 5023, 8024,\n",
      "        1008, 4281, 5399, 5489,  510, 2157, 4896, 6028,  809, 1350, 3862, 7831,\n",
      "        5023, 1355, 4289, 6821,  671, 7348, 3667, 2218,  679, 6206, 5314, 2111,\n",
      "        2094, 1391,  749, 8024, 2496, 4197,  738, 1259, 2886, 1173, 4080, 6789,\n",
      "        6793, 4638, 7937, 6793, 4176,  510, 4125, 7222,  722, 5102, 4638, 8024,\n",
      "        1398, 3198,  738, 6206, 3800, 2692, 2376, 1221, 2111, 2094, 3121, 3633,\n",
      "        2904, 7608, 1328, 7608, 4638, 1776,  739, 2679, 8024,  924, 6395, 5852,\n",
      "        1075, 1059, 7481, 1429, 3119,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2111, 2094, 2793, 3425,  860, 1355, 4142, 1355, 4173, 2582, 3416,\n",
      "        1394, 4415, 7650, 7608, 8043, 2769, 2157, 4638, 2111, 2094, 3221, 4511,\n",
      "        2140, 2140, 8024,  124, 2259, 8024, 1157, 2458, 1993, 8024, 1624, 2094,\n",
      "        4706, 3300, 4157, 4578, 8024, 1355, 4385, 8024,  845, 3300, 6768, 2544,\n",
      "        4638, 1495, 1644, 8024, 1369, 1912, 8024, 3300, 4157, 1355, 4173,  738,\n",
      "        3766, 5125, 4868, 8024, 6435, 7309, 8038, 2111, 2094, 2793, 3425,  860,\n",
      "        1355, 4142, 1355, 4173, 2582, 3416, 1394, 4415, 7650, 7608,  511, 1355,\n",
      "        4385, 2793, 3425,  860, 4142, 1218, 2553, 6206, 1350, 3198, 5314, 2111,\n",
      "        2094, 3780, 4545, 8024, 1369, 1912, 3189, 2382, 7650, 7608, 1377,  809,\n",
      "        1914, 1391,  671,  763, 5922, 5831, 1469, 3717, 3362, 8024, 7370,  749,\n",
      "        3926, 3909,  679, 1173, 4080,  722, 1912, 8024, 6821, 5102, 7608, 4289,\n",
      "        4638, 5852, 1075, 5162,  738, 3221, 3683, 6772,  705, 2168, 4638, 8024,\n",
      "        3300, 1221,  754, 2376, 1221, 2850, 2539, 4565, 4567, 8024,  679, 6814,\n",
      "        3717, 3362, 4638, 6848, 2885,  677, 6206, 3800, 2692, 6912, 1048, 6814,\n",
      "         754, 2170, 1117, 4638, 8024, 1377,  809, 6848, 2885,  671,  763, 2595,\n",
      "        2398, 4638, 8024, 3683, 1963, 5741, 3362, 8024, 4334, 4347, 3425,  722,\n",
      "        5102, 4638, 8024, 3189, 2382, 7650, 7608, 2418, 6848, 2885, 3211,  754,\n",
      "        3867, 1265, 4638, 8024, 3683, 1963, 5114,  510, 7481, 3340, 5023, 8024,\n",
      "        1008, 4281, 5399, 5489,  510, 2157, 4896, 6028,  809, 1350, 3862, 7831,\n",
      "        5023, 1355, 4289, 6821,  671, 7348, 3667, 2218,  679, 6206, 5314, 2111,\n",
      "        2094, 1391,  749, 8024, 2496, 4197,  738, 1259, 2886, 1173, 4080, 6789,\n",
      "        6793, 4638, 7937, 6793, 4176,  510, 4125, 7222,  722, 5102, 4638, 8024,\n",
      "        1398, 3198,  738, 6206, 3800, 2692, 2376, 1221, 2111, 2094, 3121, 3633,\n",
      "        2904, 7608, 1328, 7608, 4638, 1776,  739, 2679, 8024,  924, 6395, 5852,\n",
      "        1075, 1059, 7481, 1429, 3119,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([27], device='cuda:0')\n",
      "input_ids =  tensor([ 103, 2797, 6639, 1366, 4567, 2571, 1962,  749, 2397, 1445, 3221,  784,\n",
      "         720, 1333, 1728, 8043, 1762, 1036, 4997, 1278, 7368, 2899,  749,  671,\n",
      "        3215, 3309, 4638, 3717, 8024, 1726, 2157,  671, 1921, 1400, 3241,  677,\n",
      "        2347, 5307, 2458, 1993, 2397, 1445, 8024,  671, 3146, 1915, 1402,  749,\n",
      "        1962, 1126, 3613,  749, 8024, 3300, 3198, 6820,  833,  671, 7347,  671,\n",
      "        7347, 4638, 1355, 7588,  511, 2797, 6639, 1366, 4567, 2571, 1962,  749,\n",
      "        2397, 1445, 3221,  784,  720, 1333, 1728, 8043, 2797, 6639, 1366, 4567,\n",
      "        1400, 2397, 1445,  679, 1188, 7370,  680, 2797, 6639, 1366, 4567, 2772,\n",
      "        4567, 3681, 4557, 4562, 3300, 1068,  511, 1762, 2797, 6639, 1366, 4567,\n",
      "        4638, 6629, 1993, 7348, 3667, 8024, 1377, 5543,  833, 3300, 6768, 2544,\n",
      "        4638,  677, 6956, 4568, 4307,  511, 4507,  754, 1366, 5579, 3971, 4550,\n",
      "        4638, 4563, 4578, 8024, 1036, 4997, 3837, 3870, 2400, 1726, 5318, 2961,\n",
      "         912,  511, 2797, 6639, 1366, 4567, 3221, 4567, 3681, 2697, 3381, 5636,\n",
      "         886, 4638, 8024,  833, 1086, 3613, 1139, 4385, 1366, 5579, 3300, 4557,\n",
      "        4562, 8024, 2797, 2552, 5558, 2552, 3300, 4546, 4609, 8024,  698, 7028,\n",
      "        3198, 1086, 3613, 1139, 4385, 1355, 4173, 8024,  852, 3221, 5318,  679,\n",
      "         833, 5636,  886, 2397, 1445, 8024, 1008, 4385, 1762, 2111, 2094, 4638,\n",
      "        2658, 1105, 2397, 1445, 8024, 2456, 6379, 1168, 1278, 7368,  976, 5554,\n",
      "        4510, 1745, 3466, 3389, 8024, 4692,  671, 4692, 3221,  679, 3221, 3300,\n",
      "        5554, 4142,  511, 1963, 3362, 3300, 5554, 4142, 8024, 6929,  720, 2533,\n",
      "         798, 5301, 3466, 3389, 4692,  671, 4692, 3221, 5301, 5826, 5636,  886,\n",
      "        4638, 6820, 3221, 4567, 3681, 2697, 3381, 5636,  886, 4638, 8024, 2190,\n",
      "        4568, 5314, 5790, 3131, 3780, 8024, 1086, 5314,  680, 5852, 1075, 5554,\n",
      "        5301, 5528, 4638, 5790, 4289, 8024, 5314,  680, 7360, 7565, 1327, 4638,\n",
      "        5790, 4289,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2797, 6639, 1366, 4567, 2571, 1962,  749, 2397, 1445, 3221,  784,\n",
      "         720, 1333, 1728, 8043, 1762, 1036, 4997, 1278, 7368, 2899,  749,  671,\n",
      "        3215, 3309, 4638, 3717, 8024, 1726, 2157,  671, 1921, 1400, 3241,  677,\n",
      "        2347, 5307, 2458, 1993, 2397, 1445, 8024,  671, 3146, 1915, 1402,  749,\n",
      "        1962, 1126, 3613,  749, 8024, 3300, 3198, 6820,  833,  671, 7347,  671,\n",
      "        7347, 4638, 1355, 7588,  511, 2797, 6639, 1366, 4567, 2571, 1962,  749,\n",
      "        2397, 1445, 3221,  784,  720, 1333, 1728, 8043, 2797, 6639, 1366, 4567,\n",
      "        1400, 2397, 1445,  679, 1188, 7370,  680, 2797, 6639, 1366, 4567, 2772,\n",
      "        4567, 3681, 4557, 4562, 3300, 1068,  511, 1762, 2797, 6639, 1366, 4567,\n",
      "        4638, 6629, 1993, 7348, 3667, 8024, 1377, 5543,  833, 3300, 6768, 2544,\n",
      "        4638,  677, 6956, 4568, 4307,  511, 4507,  754, 1366, 5579, 3971, 4550,\n",
      "        4638, 4563, 4578, 8024, 1036, 4997, 3837, 3870, 2400, 1726, 5318, 2961,\n",
      "         912,  511, 2797, 6639, 1366, 4567, 3221, 4567, 3681, 2697, 3381, 5636,\n",
      "         886, 4638, 8024,  833, 1086, 3613, 1139, 4385, 1366, 5579, 3300, 4557,\n",
      "        4562, 8024, 2797, 2552, 5558, 2552, 3300, 4546, 4609, 8024,  698, 7028,\n",
      "        3198, 1086, 3613, 1139, 4385, 1355, 4173, 8024,  852, 3221, 5318,  679,\n",
      "         833, 5636,  886, 2397, 1445, 8024, 1008, 4385, 1762, 2111, 2094, 4638,\n",
      "        2658, 1105, 2397, 1445, 8024, 2456, 6379, 1168, 1278, 7368,  976, 5554,\n",
      "        4510, 1745, 3466, 3389, 8024, 4692,  671, 4692, 3221,  679, 3221, 3300,\n",
      "        5554, 4142,  511, 1963, 3362, 3300, 5554, 4142, 8024, 6929,  720, 2533,\n",
      "         798, 5301, 3466, 3389, 4692,  671, 4692, 3221, 5301, 5826, 5636,  886,\n",
      "        4638, 6820, 3221, 4567, 3681, 2697, 3381, 5636,  886, 4638, 8024, 2190,\n",
      "        4568, 5314, 5790, 3131, 3780, 8024, 1086, 5314,  680, 5852, 1075, 5554,\n",
      "        5301, 5528, 4638, 5790, 4289, 8024, 5314,  680, 7360, 7565, 1327, 4638,\n",
      "        5790, 4289,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 5/9000 [00:00<14:41, 10.21it/s, loss=2.7803459]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 2207, 2140, 2140,  679, 4263, 1391, 7649, 2418, 6421, 2582,  720,\n",
      "        1215, 8043, 2140, 2140,  671, 2259, 1288, 8024,  679, 4263, 1391, 7649,\n",
      "        2418, 6421, 2582,  720, 1215, 8043, 2140, 6564, 4385, 1762, 3221,  122,\n",
      "        2259, 8024,  679, 4263, 1391, 7649, 8024, 1328, 7608, 3683, 6772,  698,\n",
      "        7028, 8024, 6821, 4905, 2658, 1105, 2418, 6421, 2582,  720, 1215, 1962,\n",
      "        8043,  122, 2259, 1288, 2140, 2140,  679, 4263, 1391, 7649, 2418, 6421,\n",
      "        2582,  720, 1215, 1450, 8043, 2644, 1962, 8024, 2140, 2140,  679, 4263,\n",
      "        1391, 7649, 1333, 1728, 3300, 2523, 1914,  511, 5375, 7159, 5375, 7227,\n",
      "         510, 1585, 1075,  679, 2496,  510, 3698,  952, 2512, 1510, 6963, 3221,\n",
      "        2382, 6224, 4638, 1333, 1728,  511, 1968, 1968, 6206, 1914, 1217, 4522,\n",
      "        2692, 8024, 6912, 1048, 2140, 2140, 1728, 6716,  860,  679, 6844, 7270,\n",
      "        3309,  679, 1391, 7649,  511,  671, 3190, 2140, 2140, 1139, 4385, 7608,\n",
      "        3617,  679, 2920,  510, 5592, 5515,  510, 1445, 1402, 4568, 4307, 8024,\n",
      "        7444, 1217,  809, 6444, 4415, 8024, 3121, 1587, 2140, 2140, 4638, 7650,\n",
      "        7608, 8024, 1914, 6375, 2140, 2140, 1391,  671,  763, 3173, 7831, 4638,\n",
      "        5922, 3362, 8024, 2208, 6375, 2140, 2140, 1391, 3779, 5594,  679, 3211,\n",
      "        3867, 1265, 4638, 7608, 4289,  511, 2140, 2140, 4324, 7608,  974, 7608,\n",
      "        4638,  739, 2679,  738, 6206, 6375, 1961, 3121, 2957,  511, 1369, 1912,\n",
      "        8024,  711,  749,  914, 6822, 2140, 2140, 4638, 7608, 3617,  511,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2207, 2140, 2140,  679, 4263, 1391, 7649, 2418, 6421, 2582,  720,\n",
      "        1215, 8043, 2140, 2140,  671, 2259, 1288, 8024,  679, 4263, 1391, 7649,\n",
      "        2418, 6421, 2582,  720, 1215, 8043, 2140, 6564, 4385, 1762, 3221,  122,\n",
      "        2259, 8024,  679, 4263, 1391, 7649, 8024, 1328, 7608, 3683, 6772,  698,\n",
      "        7028, 8024, 6821, 4905, 2658, 1105, 2418, 6421, 2582,  720, 1215, 1962,\n",
      "        8043,  122, 2259, 1288, 2140, 2140,  679, 4263, 1391, 7649, 2418, 6421,\n",
      "        2582,  720, 1215, 1450, 8043, 2644, 1962, 8024, 2140, 2140,  679, 4263,\n",
      "        1391, 7649, 1333, 1728, 3300, 2523, 1914,  511, 5375, 7159, 5375, 7227,\n",
      "         510, 1585, 1075,  679, 2496,  510, 3698,  952, 2512, 1510, 6963, 3221,\n",
      "        2382, 6224, 4638, 1333, 1728,  511, 1968, 1968, 6206, 1914, 1217, 4522,\n",
      "        2692, 8024, 6912, 1048, 2140, 2140, 1728, 6716,  860,  679, 6844, 7270,\n",
      "        3309,  679, 1391, 7649,  511,  671, 3190, 2140, 2140, 1139, 4385, 7608,\n",
      "        3617,  679, 2920,  510, 5592, 5515,  510, 1445, 1402, 4568, 4307, 8024,\n",
      "        7444, 1217,  809, 6444, 4415, 8024, 3121, 1587, 2140, 2140, 4638, 7650,\n",
      "        7608, 8024, 1914, 6375, 2140, 2140, 1391,  671,  763, 3173, 7831, 4638,\n",
      "        5922, 3362, 8024, 2208, 6375, 2140, 2140, 1391, 3779, 5594,  679, 3211,\n",
      "        3867, 1265, 4638, 7608, 4289,  511, 2140, 2140, 4324, 7608,  974, 7608,\n",
      "        4638,  739, 2679,  738, 6206, 6375, 1961, 3121, 2957,  511, 1369, 1912,\n",
      "        8024,  711,  749,  914, 6822, 2140, 2140, 4638, 7608, 3617,  511,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([35, 61], device='cuda:0')\n",
      "input_ids =  tensor([ 103, 7481, 4611, 7481, 5491, 4570, 2908, 3780, 4638, 1962, 1408, 8043,\n",
      "        2769, 6134, 1520, 3300, 7481, 4611, 8024, 2157, 7027, 7481,  782, 2372,\n",
      "         800, 1343, 4692, 6814,  702, 1278, 4495, 8024,  852, 3221, 6820, 3221,\n",
      "         679, 2159, 3211, 3780, 4545, 1962, 8024, 1728,  711, 5643, 5643, 2157,\n",
      "        3766,  784,  720, 7178, 8024, 2218, 3766, 1343, 1920, 1814, 2356, 5314,\n",
      "         800, 3780, 4545,  511,  852, 3221,  800, 5307, 2382, 6821, 3416,  738,\n",
      "        3766,  782, 5507, 2063, 5314,  800,  511,  679, 4761, 3236, 7481, 4611,\n",
      "        7481, 5491, 4570, 2908, 3780, 4638, 1962, 1408, 8043,  794, 2644, 4385,\n",
      "        1762, 2792, 6835, 2658, 1105, 5440, 5991, 8024, 4385, 1762, 3300, 7481,\n",
      "        4611, 8024, 7481, 5491, 4570, 2908, 6821, 4905, 2658, 1105, 4638, 6413,\n",
      "        8024,  738, 3221, 1377,  809, 2141, 3177, 3780, 4545, 4638, 8024, 6821,\n",
      "        4905, 2658, 1105, 4638, 6413, 8024, 2456, 6379, 1377,  809, 4692,  671,\n",
      "         678,  704, 1278, 8024, 6858, 6814,  704, 1278, 5549, 8024, 4197, 1400,\n",
      "        7023, 1357,  704, 5790, 2141, 3177, 6444, 1075, 1469, 3780, 4545, 8024,\n",
      "        4385, 1762, 2418, 6421, 6206, 3800, 2692,  828, 2622, 8024, 5125, 4868,\n",
      "        8024,  679, 6206, 1922, 6814, 5165, 2476, 8024, 1327, 1213,  679, 6206,\n",
      "        1922, 1920, 8024,  679, 6206, 1391, 6789, 6793, 3353, 1107, 1173, 4080,\n",
      "        2595, 4638, 7608, 4289, 8024,  679,  788, 1963, 3634, 8024, 2642, 5442,\n",
      "        6206, 1075, 2768, 6226, 2526,  868, 2622, 4638, 4495, 3833, 1962,  739,\n",
      "        2679, 8024, 1780, 2898, 3780, 4545, 8024, 2400,  684, 6206, 3926, 3909,\n",
      "        7650, 7608, 1914,  976, 3300, 3709, 6817, 1220, 8024, 6821, 3416, 2798,\n",
      "        5543, 2990,  897, 5632, 6716, 1048, 4554, 1213, 7360,  856, 2642, 4567,\n",
      "        7599, 7372,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 7481, 4611, 7481, 5491, 4570, 2908, 3780, 4638, 1962, 1408, 8043,\n",
      "        2769, 6134, 1520, 3300, 7481, 4611, 8024, 2157, 7027, 7481,  782, 2372,\n",
      "         800, 1343, 4692, 6814,  702, 1278, 4495, 8024,  852, 3221, 6820, 3221,\n",
      "         679, 2159, 3211, 3780, 4545, 1962, 8024, 1728,  711, 5643, 5643, 2157,\n",
      "        3766,  784,  720, 7178, 8024, 2218, 3766, 1343, 1920, 1814, 2356, 5314,\n",
      "         800, 3780, 4545,  511,  852, 3221,  800, 5307, 2382, 6821, 3416,  738,\n",
      "        3766,  782, 5507, 2063, 5314,  800,  511,  679, 4761, 3236, 7481, 4611,\n",
      "        7481, 5491, 4570, 2908, 3780, 4638, 1962, 1408, 8043,  794, 2644, 4385,\n",
      "        1762, 2792, 6835, 2658, 1105, 5440, 5991, 8024, 4385, 1762, 3300, 7481,\n",
      "        4611, 8024, 7481, 5491, 4570, 2908, 6821, 4905, 2658, 1105, 4638, 6413,\n",
      "        8024,  738, 3221, 1377,  809, 2141, 3177, 3780, 4545, 4638, 8024, 6821,\n",
      "        4905, 2658, 1105, 4638, 6413, 8024, 2456, 6379, 1377,  809, 4692,  671,\n",
      "         678,  704, 1278, 8024, 6858, 6814,  704, 1278, 5549, 8024, 4197, 1400,\n",
      "        7023, 1357,  704, 5790, 2141, 3177, 6444, 1075, 1469, 3780, 4545, 8024,\n",
      "        4385, 1762, 2418, 6421, 6206, 3800, 2692,  828, 2622, 8024, 5125, 4868,\n",
      "        8024,  679, 6206, 1922, 6814, 5165, 2476, 8024, 1327, 1213,  679, 6206,\n",
      "        1922, 1920, 8024,  679, 6206, 1391, 6789, 6793, 3353, 1107, 1173, 4080,\n",
      "        2595, 4638, 7608, 4289, 8024,  679,  788, 1963, 3634, 8024, 2642, 5442,\n",
      "        6206, 1075, 2768, 6226, 2526,  868, 2622, 4638, 4495, 3833, 1962,  739,\n",
      "        2679, 8024, 1780, 2898, 3780, 4545, 8024, 2400,  684, 6206, 3926, 3909,\n",
      "        7650, 7608, 1914,  976, 3300, 3709, 6817, 1220, 8024, 6821, 3416, 2798,\n",
      "        5543, 2990,  897, 5632, 6716, 1048, 4554, 1213, 7360,  856, 2642, 4567,\n",
      "        7599, 7372,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103, 2140, 2140, 5439, 1599, 3614, 3123, 2230, 3221,  711,  784,  720,\n",
      "        8043, 2111, 2094, 1157, 1139, 4495,  679, 4761, 6887, 2582,  720, 1726,\n",
      "         752, 8024, 6716,  677, 2600, 3221, 3300, 5273, 4157, 8024, 5445,  684,\n",
      "        1402, 1959, 8024, 6435, 7309, 2140, 2140, 5439, 1599, 3614, 3123, 2230,\n",
      "        3221,  711,  784,  720,  872, 4638, 6821, 4905, 2658, 1105, 1377, 5543,\n",
      "        3221, 3867, 1265,  679, 5679, 8024, 2456, 6379,  679, 6206, 1391, 3779,\n",
      "        5594,  722, 1501, 8024, 1377,  809, 4500,  924, 1469,  709, 1217, 1121,\n",
      "        3780, 4545, 8024, 2772, 4500, 5850, 1301, 5104, 4143, 4225, 1400, 1343,\n",
      "        1900, 4203, 3302, 8024, 3126, 3362, 3683, 6772, 1962,  511, 8024, 2111,\n",
      "        2094, 6158, 3173, 4495, 1036, 4565, 4567, 2792, 1314, 2154, 8024, 1728,\n",
      "        3634, 8024, 2157,  782,  671, 2137, 6206, 2372, 2111, 2094, 1350, 3198,\n",
      "        2218, 1278, 3780, 4545, 8024, 6912, 1048, 4683, 4680,  886, 4500, 2207,\n",
      "        2408, 1440, 5790, 4289, 8024, 7444, 6206, 1394, 4415, 4500, 5790, 8024,\n",
      "        2190,  754, 2157, 7270, 3341, 6432, 6206, 5314,  750, 2111, 2094, 6639,\n",
      "        1916, 4638, 1068, 2552, 1469, 4212, 7560, 8024, 6206, 2226, 1377, 5543,\n",
      "        4638, 2376, 1221, 2111, 2094, 1350, 3198, 3780, 4545, 4565, 4567,  511,\n",
      "         101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2140, 2140, 5439, 1599, 3614, 3123, 2230, 3221,  711,  784,  720,\n",
      "        8043, 2111, 2094, 1157, 1139, 4495,  679, 4761, 6887, 2582,  720, 1726,\n",
      "         752, 8024, 6716,  677, 2600, 3221, 3300, 5273, 4157, 8024, 5445,  684,\n",
      "        1402, 1959, 8024, 6435, 7309, 2140, 2140, 5439, 1599, 3614, 3123, 2230,\n",
      "        3221,  711,  784,  720,  872, 4638, 6821, 4905, 2658, 1105, 1377, 5543,\n",
      "        3221, 3867, 1265,  679, 5679, 8024, 2456, 6379,  679, 6206, 1391, 3779,\n",
      "        5594,  722, 1501, 8024, 1377,  809, 4500,  924, 1469,  709, 1217, 1121,\n",
      "        3780, 4545, 8024, 2772, 4500, 5850, 1301, 5104, 4143, 4225, 1400, 1343,\n",
      "        1900, 4203, 3302, 8024, 3126, 3362, 3683, 6772, 1962,  511, 8024, 2111,\n",
      "        2094, 6158, 3173, 4495, 1036, 4565, 4567, 2792, 1314, 2154, 8024, 1728,\n",
      "        3634, 8024, 2157,  782,  671, 2137, 6206, 2372, 2111, 2094, 1350, 3198,\n",
      "        2218, 1278, 3780, 4545, 8024, 6912, 1048, 4683, 4680,  886, 4500, 2207,\n",
      "        2408, 1440, 5790, 4289, 8024, 7444, 6206, 1394, 4415, 4500, 5790, 8024,\n",
      "        2190,  754, 2157, 7270, 3341, 6432, 6206, 5314,  750, 2111, 2094, 6639,\n",
      "        1916, 4638, 1068, 2552, 1469, 4212, 7560, 8024, 6206, 2226, 1377, 5543,\n",
      "        4638, 2376, 1221, 2111, 2094, 1350, 3198, 3780, 4545, 4565, 4567,  511,\n",
      "         101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 7/9000 [00:00<12:53, 11.63it/s, loss=3.8173072]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 2207, 1036, 7481, 4611, 7151, 4132,  833, 4578, 1408, 8043, 2111,\n",
      "        2094, 1920, 3519, 3221, 1762, 8108, 1384, 4638, 3198,  952,  678, 7433,\n",
      "        1921, 1107, 1168, 1912, 7481, 1430, 6814, 7599, 8024, 1071,  800, 3766,\n",
      "        3300,  679, 5653, 3302, 8024, 1962, 1008, 3221, 5018,  123, 1921, 2218,\n",
      "        1355, 4385, 1381, 1673, 3639,  749, 2340, 4706, 4714, 7308,  679, 5165,\n",
      "        8024, 7961, 5586, 2094, 2340, 6804, 4026, 3698, 8024, 2340, 6804, 1391,\n",
      "         691, 6205,  738,  833, 1853,  511, 8124, 1384, 2458, 1993,  857, 7368,\n",
      "        8024, 2802, 1396, 7151, 8024, 1400, 3341, 1126, 1921, 6820,  698, 7028,\n",
      "         749, 6206, 7151, 4132, 8024, 2207, 1036, 7151,  833, 4578, 1408, 8043,\n",
      "        7481, 4611, 2642, 5442, 2398, 3198, 2418, 3800, 2692, 7564, 7344, 8024,\n",
      "         924, 2898, 5125, 4868, 2690, 2571, 8024,  924, 6395, 6844, 2496, 4638,\n",
      "        4717, 4697, 1469,  828, 2622,  511, 1915, 7313, 6912, 1048, 1358, 1107,\n",
      "        7599,  909, 6159,  511,  671, 3190, 2642, 4567, 6206, 3800, 2692, 7344,\n",
      "        2844, 8024, 1107, 1921, 1912, 1139, 2785, 1366, 5388, 8024, 4706, 4714,\n",
      "        7308, 1394,  679, 1962, 3198, 2418, 2785, 4706, 5388, 8024,  809, 7344,\n",
      "        6235, 5606, 1358,  839,  511, 7481, 4611, 4638, 1314, 2154, 4685, 2496,\n",
      "        4638, 1920,  511, 1728, 3634, 1963, 3362, 1355, 4385,  749, 5632, 2346,\n",
      "        2100, 1762, 7481, 4611, 4638, 4568, 4307, 6134, 4385, 8024, 2218, 6206,\n",
      "        2471, 6629, 7028, 6228,  749, 3353, 3300, 1377, 5543, 3221, 2642,  677,\n",
      "        7481, 4611,  749, 8024, 2456, 6379, 7481, 4611, 2642, 5442, 2418, 6421,\n",
      "        1350, 3198, 4638, 1343, 2518, 3633, 6226, 4638, 1278, 7368, 6822, 6121,\n",
      "        6402, 3171, 8024,  809, 1048, 2454, 6428,  749, 3297,  881, 4638, 3780,\n",
      "        4545, 3198, 3322, 8024, 2372, 3341, 3291, 1914, 4638, 4578, 5736,  511,\n",
      "        2456, 6379, 6848, 4500,  704, 1278, 4868, 5307, 2398, 6130, 4545, 3791,\n",
      "        6822, 6121, 3780, 4545,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2207, 1036, 7481, 4611, 7151, 4132,  833, 4578, 1408, 8043, 2111,\n",
      "        2094, 1920, 3519, 3221, 1762, 8108, 1384, 4638, 3198,  952,  678, 7433,\n",
      "        1921, 1107, 1168, 1912, 7481, 1430, 6814, 7599, 8024, 1071,  800, 3766,\n",
      "        3300,  679, 5653, 3302, 8024, 1962, 1008, 3221, 5018,  123, 1921, 2218,\n",
      "        1355, 4385, 1381, 1673, 3639,  749, 2340, 4706, 4714, 7308,  679, 5165,\n",
      "        8024, 7961, 5586, 2094, 2340, 6804, 4026, 3698, 8024, 2340, 6804, 1391,\n",
      "         691, 6205,  738,  833, 1853,  511, 8124, 1384, 2458, 1993,  857, 7368,\n",
      "        8024, 2802, 1396, 7151, 8024, 1400, 3341, 1126, 1921, 6820,  698, 7028,\n",
      "         749, 6206, 7151, 4132, 8024, 2207, 1036, 7151,  833, 4578, 1408, 8043,\n",
      "        7481, 4611, 2642, 5442, 2398, 3198, 2418, 3800, 2692, 7564, 7344, 8024,\n",
      "         924, 2898, 5125, 4868, 2690, 2571, 8024,  924, 6395, 6844, 2496, 4638,\n",
      "        4717, 4697, 1469,  828, 2622,  511, 1915, 7313, 6912, 1048, 1358, 1107,\n",
      "        7599,  909, 6159,  511,  671, 3190, 2642, 4567, 6206, 3800, 2692, 7344,\n",
      "        2844, 8024, 1107, 1921, 1912, 1139, 2785, 1366, 5388, 8024, 4706, 4714,\n",
      "        7308, 1394,  679, 1962, 3198, 2418, 2785, 4706, 5388, 8024,  809, 7344,\n",
      "        6235, 5606, 1358,  839,  511, 7481, 4611, 4638, 1314, 2154, 4685, 2496,\n",
      "        4638, 1920,  511, 1728, 3634, 1963, 3362, 1355, 4385,  749, 5632, 2346,\n",
      "        2100, 1762, 7481, 4611, 4638, 4568, 4307, 6134, 4385, 8024, 2218, 6206,\n",
      "        2471, 6629, 7028, 6228,  749, 3353, 3300, 1377, 5543, 3221, 2642,  677,\n",
      "        7481, 4611,  749, 8024, 2456, 6379, 7481, 4611, 2642, 5442, 2418, 6421,\n",
      "        1350, 3198, 4638, 1343, 2518, 3633, 6226, 4638, 1278, 7368, 6822, 6121,\n",
      "        6402, 3171, 8024,  809, 1048, 2454, 6428,  749, 3297,  881, 4638, 3780,\n",
      "        4545, 3198, 3322, 8024, 2372, 3341, 3291, 1914, 4638, 4578, 5736,  511,\n",
      "        2456, 6379, 6848, 4500,  704, 1278, 4868, 5307, 2398, 6130, 4545, 3791,\n",
      "        6822, 6121, 3780, 4545,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([17, 45, 78], device='cuda:0')\n",
      "input_ids =  tensor([ 103, 2111, 2094, 1724, 2259, 4717, 6230, 5558, 1355, 4176, 8043, 2207,\n",
      "        2111, 2094, 4717, 6230, 3198, 6677, 6158, 2094, 4500, 2797, 3043, 5558,\n",
      "        1355, 4176, 2644, 1962, 3221,  784,  720, 1333, 1728, 6468, 6468,  679,\n",
      "        3926, 3295, 5307, 4638, 3131, 3780, 2658, 1105, 1469, 3126, 3362, 8038,\n",
      "        3187, 1762,  725, 2582, 3416, 4638, 1291, 1221, 8038, 2682, 4761, 6887,\n",
      "        1072,  860, 1333, 1728, 2582, 3416, 3030, 2398,  122,  117, 4559, 4916,\n",
      "        5569, 5994,  117, 7755, 5489, 2552, 1355, 4176, 1071, 1333, 1728,  671,\n",
      "        3221, 7650, 7608,  679, 5688,  117, 1315, 3300, 4638, 7650, 7608, 3187,\n",
      "        2428,  117, 7608,  679, 2137, 3198,  117, 2382, 1391, 7439, 7608,  117,\n",
      "        7270, 3309,  678, 1343, 1377,  839, 2938, 5569, 5517, 1216, 5543,  117,\n",
      "        2471, 3341, 6817, 1265, 1927, 2382,  117, 3354, 2768, 4916, 4005,  117,\n",
      "        4916, 4005, 3189,  719,  117, 3717, 6484, 5125, 2544, 3210, 2435, 4159,\n",
      "        1265,  117, 3354, 2768, 4559, 4916, 5445, 1355, 4176,  511,  753, 3221,\n",
      "        2642, 1071, 2124, 4565, 4567, 1400,  117, 1963, 1445, 6847,  117, 4581,\n",
      "        4565,  117, 2164, 4495, 6001, 4567, 5023, 3131, 3780,  679, 2496,  117,\n",
      "        6810, 2454, 3189,  719,  117,  839, 2938, 3698, 6117,  117, 5636,  886,\n",
      "        5852, 1075,  679, 5679, 5445, 3354, 2768, 4559, 4916, 1355, 4176,  511,\n",
      "        6821, 6956, 1146, 2382, 6224,  711, 7755, 5489, 2552, 1355, 4176,  117,\n",
      "        7481, 7942, 5491, 4607,  117, 3688, 1355, 2397, 3369,  117, 5592, 6956,\n",
      "        5515, 1920,  117, 7608, 3617,  679,  881,  117, 2382, 7608, 2460, 4289,\n",
      "         117, 1915, 4717,  679, 2123,  117, 1920,  912, 6772, 4921,  117, 3300,\n",
      "         679, 3867, 1265, 7608, 4289,  117, 2207,  912, 7942, 3843, 1963, 5101,\n",
      "         100,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2111, 2094, 1724, 2259, 4717, 6230, 5558, 1355, 4176, 8043, 2207,\n",
      "        2111, 2094, 4717, 6230, 3198, 6677, 6158, 2094, 4500, 2797, 3043, 5558,\n",
      "        1355, 4176, 2644, 1962, 3221,  784,  720, 1333, 1728, 6468, 6468,  679,\n",
      "        3926, 3295, 5307, 4638, 3131, 3780, 2658, 1105, 1469, 3126, 3362, 8038,\n",
      "        3187, 1762,  725, 2582, 3416, 4638, 1291, 1221, 8038, 2682, 4761, 6887,\n",
      "        1072,  860, 1333, 1728, 2582, 3416, 3030, 2398,  122,  117, 4559, 4916,\n",
      "        5569, 5994,  117, 7755, 5489, 2552, 1355, 4176, 1071, 1333, 1728,  671,\n",
      "        3221, 7650, 7608,  679, 5688,  117, 1315, 3300, 4638, 7650, 7608, 3187,\n",
      "        2428,  117, 7608,  679, 2137, 3198,  117, 2382, 1391, 7439, 7608,  117,\n",
      "        7270, 3309,  678, 1343, 1377,  839, 2938, 5569, 5517, 1216, 5543,  117,\n",
      "        2471, 3341, 6817, 1265, 1927, 2382,  117, 3354, 2768, 4916, 4005,  117,\n",
      "        4916, 4005, 3189,  719,  117, 3717, 6484, 5125, 2544, 3210, 2435, 4159,\n",
      "        1265,  117, 3354, 2768, 4559, 4916, 5445, 1355, 4176,  511,  753, 3221,\n",
      "        2642, 1071, 2124, 4565, 4567, 1400,  117, 1963, 1445, 6847,  117, 4581,\n",
      "        4565,  117, 2164, 4495, 6001, 4567, 5023, 3131, 3780,  679, 2496,  117,\n",
      "        6810, 2454, 3189,  719,  117,  839, 2938, 3698, 6117,  117, 5636,  886,\n",
      "        5852, 1075,  679, 5679, 5445, 3354, 2768, 4559, 4916, 1355, 4176,  511,\n",
      "        6821, 6956, 1146, 2382, 6224,  711, 7755, 5489, 2552, 1355, 4176,  117,\n",
      "        7481, 7942, 5491, 4607,  117, 3688, 1355, 2397, 3369,  117, 5592, 6956,\n",
      "        5515, 1920,  117, 7608, 3617,  679,  881,  117, 2382, 7608, 2460, 4289,\n",
      "         117, 1915, 4717,  679, 2123,  117, 1920,  912, 6772, 4921,  117, 3300,\n",
      "         679, 3867, 1265, 7608, 4289,  117, 2207,  912, 7942, 3843, 1963, 5101,\n",
      "         100,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([68], device='cuda:0')\n",
      "input_ids =  tensor([ 103, 2048, 1036, 5554, 4611, 4638, 4568, 4307, 6134, 4385, 3300, 1525,\n",
      "         763, 8043, 2048, 1036, 5554, 4611, 4638, 4568, 4307, 6134, 4385, 3300,\n",
      "        1525,  763,  136, 2048, 1036, 5554, 4611, 4638, 4568, 4307, 6134, 4385,\n",
      "        3300, 1525,  763,  136, 2682, 2533, 1168, 4638, 2376, 1221, 8038, 2048,\n",
      "        1036, 5554, 4611, 4638, 4568, 4307, 6134, 4385, 3300, 1525,  763, 2207,\n",
      "        1036, 5554, 4611, 4638, 3297, 1159, 4568, 4307, 3221, 8038, 3173, 4495,\n",
      "        1036, 2772,  124,  702, 3299, 1920, 4638, 2048, 1036, 2159, 3211, 1139,\n",
      "        4385,  828, 1046, 8024, 1526, 7317, 8024,  745, 2791, 1469, 4717, 4697,\n",
      "        1737, 7410,  511, 3193, 3309, 6822, 7608, 8024, 6822, 7608, 1469, 1463,\n",
      "        1715, 8024, 1600, 3717, 8024, 1411, 1498, 1737, 7410, 8024, 3837, 1366,\n",
      "        3717, 8024, 1461, 1429, 7397, 4809, 5023,  511, 5554, 4611, 3221,  671,\n",
      "        4905, 4868, 5307, 5143, 5320, 4565, 4567, 8024, 3221,  671, 4905, 4507,\n",
      "        3187, 6822, 2245, 2595, 5554, 2938,  839, 1469,  794, 1358, 2097, 1168,\n",
      "        2048, 1036, 3198, 3309, 4638, 1355, 5509, 5375, 7379, 2471, 6629, 4638,\n",
      "        5341, 1394, 4568, 8024,  712, 6206, 6134, 4385,  711, 6817, 1220, 7397,\n",
      "        4809, 1469, 2013, 1232, 2460, 2382,  511,  809,  677, 3221, 2190,  100,\n",
      "        2048, 1036, 5554, 4611, 4638, 4568, 4307, 3300, 1525,  763, 8043,  100,\n",
      "        4638, 2456, 6379,  511, 2361, 3307, 2190, 2644, 3300, 2792, 2376, 1221,\n",
      "        8024, 4867, 2644,  978, 2434, 8013,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2048, 1036, 5554, 4611, 4638, 4568, 4307, 6134, 4385, 3300, 1525,\n",
      "         763, 8043, 2048, 1036, 5554, 4611, 4638, 4568, 4307, 6134, 4385, 3300,\n",
      "        1525,  763,  136, 2048, 1036, 5554, 4611, 4638, 4568, 4307, 6134, 4385,\n",
      "        3300, 1525,  763,  136, 2682, 2533, 1168, 4638, 2376, 1221, 8038, 2048,\n",
      "        1036, 5554, 4611, 4638, 4568, 4307, 6134, 4385, 3300, 1525,  763, 2207,\n",
      "        1036, 5554, 4611, 4638, 3297, 1159, 4568, 4307, 3221, 8038, 3173, 4495,\n",
      "        1036, 2772,  124,  702, 3299, 1920, 4638, 2048, 1036, 2159, 3211, 1139,\n",
      "        4385,  828, 1046, 8024, 1526, 7317, 8024,  745, 2791, 1469, 4717, 4697,\n",
      "        1737, 7410,  511, 3193, 3309, 6822, 7608, 8024, 6822, 7608, 1469, 1463,\n",
      "        1715, 8024, 1600, 3717, 8024, 1411, 1498, 1737, 7410, 8024, 3837, 1366,\n",
      "        3717, 8024, 1461, 1429, 7397, 4809, 5023,  511, 5554, 4611, 3221,  671,\n",
      "        4905, 4868, 5307, 5143, 5320, 4565, 4567, 8024, 3221,  671, 4905, 4507,\n",
      "        3187, 6822, 2245, 2595, 5554, 2938,  839, 1469,  794, 1358, 2097, 1168,\n",
      "        2048, 1036, 3198, 3309, 4638, 1355, 5509, 5375, 7379, 2471, 6629, 4638,\n",
      "        5341, 1394, 4568, 8024,  712, 6206, 6134, 4385,  711, 6817, 1220, 7397,\n",
      "        4809, 1469, 2013, 1232, 2460, 2382,  511,  809,  677, 3221, 2190,  100,\n",
      "        2048, 1036, 5554, 4611, 4638, 4568, 4307, 3300, 1525,  763, 8043,  100,\n",
      "        4638, 2456, 6379,  511, 2361, 3307, 2190, 2644, 3300, 2792, 2376, 1221,\n",
      "        8024, 4867, 2644,  978, 2434, 8013,  101], device='cuda:0')\n",
      "private_positions =  tensor([74], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 11/9000 [00:00<11:39, 12.84it/s, loss=3.1658878]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 2048, 1036, 4570, 2908, 4568, 6206, 2582,  720, 2902, 3040, 8043,\n",
      "        2769, 1995, 1995, 3221,  671,  855, 2802, 2339,  798, 8024, 2382, 2399,\n",
      "        1139, 1912, 2802, 7439, 2339, 8024, 4385, 1762, 4495, 6814, 2111, 2094,\n",
      "         749, 8024, 1377, 3221, 2111, 2094, 2642, 1196, 4164, 4563, 4578, 8024,\n",
      "        1762, 1278, 7368,  976,  749, 3131, 3780, 8024, 2644, 1962, 2048, 1036,\n",
      "        4570, 2908, 4568, 2582,  720, 2972, 2897, 8043, 2797, 6956, 3013, 2987,\n",
      "        6237, 1104,  131, 6768, 6768, 2861, 4684, 2797, 2900,  511, 3030, 1220,\n",
      "         872, 4638, 2797, 2900, 8024, 6768, 2902,  872, 4638, 2900, 2211, 8024,\n",
      "        2972, 2897,  872, 4638, 5491, 5489,  511, 3131, 3780, 2207, 5597, 2853,\n",
      "        5025,  131, 1348, 4917, 2207, 5597, 2853, 5025, 8024, 1348, 4917, 5578,\n",
      "        5499, 5491, 5491, 5588,  511, 1920, 5597,  131, 1777, 1762, 1765, 3352,\n",
      "         677, 8024, 1920, 5597,  847, 2398, 8024, 4197, 1400,  678, 1327, 5607,\n",
      "        4667, 8024, 1920, 5597, 5491, 5489,  847, 2398,  511, 3918, 6702,  131,\n",
      "        6375, 2642, 5442, 6720,  678, 8024,  847, 2398, 5607, 4667, 1469, 5558,\n",
      "        6644, 8024, 2199, 5558, 1327, 1762, 5533, 7755,  677, 8024, 2972, 2897,\n",
      "        5165, 5367, 4638, 5491, 5489,  511, 4522, 2692, 2111, 2094, 2199, 3341,\n",
      "        4638, 2844, 4415, 2612, 1908,  978, 2434,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2048, 1036, 4570, 2908, 4568, 6206, 2582,  720, 2902, 3040, 8043,\n",
      "        2769, 1995, 1995, 3221,  671,  855, 2802, 2339,  798, 8024, 2382, 2399,\n",
      "        1139, 1912, 2802, 7439, 2339, 8024, 4385, 1762, 4495, 6814, 2111, 2094,\n",
      "         749, 8024, 1377, 3221, 2111, 2094, 2642, 1196, 4164, 4563, 4578, 8024,\n",
      "        1762, 1278, 7368,  976,  749, 3131, 3780, 8024, 2644, 1962, 2048, 1036,\n",
      "        4570, 2908, 4568, 2582,  720, 2972, 2897, 8043, 2797, 6956, 3013, 2987,\n",
      "        6237, 1104,  131, 6768, 6768, 2861, 4684, 2797, 2900,  511, 3030, 1220,\n",
      "         872, 4638, 2797, 2900, 8024, 6768, 2902,  872, 4638, 2900, 2211, 8024,\n",
      "        2972, 2897,  872, 4638, 5491, 5489,  511, 3131, 3780, 2207, 5597, 2853,\n",
      "        5025,  131, 1348, 4917, 2207, 5597, 2853, 5025, 8024, 1348, 4917, 5578,\n",
      "        5499, 5491, 5491, 5588,  511, 1920, 5597,  131, 1777, 1762, 1765, 3352,\n",
      "         677, 8024, 1920, 5597,  847, 2398, 8024, 4197, 1400,  678, 1327, 5607,\n",
      "        4667, 8024, 1920, 5597, 5491, 5489,  847, 2398,  511, 3918, 6702,  131,\n",
      "        6375, 2642, 5442, 6720,  678, 8024,  847, 2398, 5607, 4667, 1469, 5558,\n",
      "        6644, 8024, 2199, 5558, 1327, 1762, 5533, 7755,  677, 8024, 2972, 2897,\n",
      "        5165, 5367, 4638, 5491, 5489,  511, 4522, 2692, 2111, 2094, 2199, 3341,\n",
      "        4638, 2844, 4415, 2612, 1908,  978, 2434,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103,  697, 2259, 2207, 2111, 1391,  749,  704, 5790, 2861, 4921, 3633,\n",
      "        2382, 1408, 8043, 6818,  697,  702, 3299, 2207, 2111,  679, 5507, 1391,\n",
      "        7649, 8024, 8020, 5307, 2382,  679, 5507, 1391, 5114, 7649, 8024, 8021,\n",
      "        7623, 7623, 1391,  671, 4157, 4157, 8024, 5439, 1419, 1673, 7027,  679,\n",
      "        1402,  678, 1343, 8024, 1419,  719,  749, 2218, 1445, 1139, 3341, 8024,\n",
      "        2372, 1343, 4692,  749,  704, 1278, 6432, 3300, 4491, 4916, 8024, 5499,\n",
      "        5517, 4178, 3698,  117, 2398, 3198, 1391,  671, 4157, 1920,  912,  974,\n",
      "        4801, 2861, 1139, 3341, 2768, 5108, 4307, 8024, 8020,  671, 4684, 3300,\n",
      "        1600, 2157, 1075, 5399, 1959, 8024,  679, 4761, 6887, 3300, 3766, 2512,\n",
      "        1510, 8021, 3300, 1377, 5543, 1469, 5569, 5517, 5994, 2483, 2471, 6629,\n",
      "        4638, 4568, 4307, 8024, 3221, 1377,  809, 3302, 4500,  704, 2768, 5790,\n",
      "        2207, 1036,  673, 3215, 5763, 6444, 4415, 8024, 1075, 2768, 5679, 1962,\n",
      "        4638, 4495, 3833,  739, 2679, 8024, 1872, 1217, 5852, 1075, 1872, 1217,\n",
      "        5335, 4495, 5162, 2544, 7030, 1039, 5162, 8024, 6912, 1048,  679, 5679,\n",
      "        1173, 4080,  511, 8024, 6863, 2768, 2048, 2405, 1036, 5592, 3811, 4638,\n",
      "        1728, 5162, 6772, 1914, 8024, 1963, 3362, 2111, 2094, 6158, 1316, 4802,\n",
      "        6402,  711, 2048, 2405, 1036, 5592, 3811,  749, 8024, 2157, 7270, 7444,\n",
      "        6206, 6981, 1394, 1278, 4495, 4989, 1315, 3780, 4545, 8024, 6981, 1394,\n",
      "        5499, 5517, 1121, 1327, 8024, 2400, 1075, 2768, 5679, 1962, 4638, 1310,\n",
      "        4495,  739, 2679,  511, 2157, 7270, 2418, 6421, 3800, 2692,  679, 6206,\n",
      "        1075, 2768, 2111, 2094, 2904, 7608,  974, 7608, 4638, 3688, 4567, 8024,\n",
      "        1394, 4415, 5612, 7608,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103,  697, 2259, 2207, 2111, 1391,  749,  704, 5790, 2861, 4921, 3633,\n",
      "        2382, 1408, 8043, 6818,  697,  702, 3299, 2207, 2111,  679, 5507, 1391,\n",
      "        7649, 8024, 8020, 5307, 2382,  679, 5507, 1391, 5114, 7649, 8024, 8021,\n",
      "        7623, 7623, 1391,  671, 4157, 4157, 8024, 5439, 1419, 1673, 7027,  679,\n",
      "        1402,  678, 1343, 8024, 1419,  719,  749, 2218, 1445, 1139, 3341, 8024,\n",
      "        2372, 1343, 4692,  749,  704, 1278, 6432, 3300, 4491, 4916, 8024, 5499,\n",
      "        5517, 4178, 3698,  117, 2398, 3198, 1391,  671, 4157, 1920,  912,  974,\n",
      "        4801, 2861, 1139, 3341, 2768, 5108, 4307, 8024, 8020,  671, 4684, 3300,\n",
      "        1600, 2157, 1075, 5399, 1959, 8024,  679, 4761, 6887, 3300, 3766, 2512,\n",
      "        1510, 8021, 3300, 1377, 5543, 1469, 5569, 5517, 5994, 2483, 2471, 6629,\n",
      "        4638, 4568, 4307, 8024, 3221, 1377,  809, 3302, 4500,  704, 2768, 5790,\n",
      "        2207, 1036,  673, 3215, 5763, 6444, 4415, 8024, 1075, 2768, 5679, 1962,\n",
      "        4638, 4495, 3833,  739, 2679, 8024, 1872, 1217, 5852, 1075, 1872, 1217,\n",
      "        5335, 4495, 5162, 2544, 7030, 1039, 5162, 8024, 6912, 1048,  679, 5679,\n",
      "        1173, 4080,  511, 8024, 6863, 2768, 2048, 2405, 1036, 5592, 3811, 4638,\n",
      "        1728, 5162, 6772, 1914, 8024, 1963, 3362, 2111, 2094, 6158, 1316, 4802,\n",
      "        6402,  711, 2048, 2405, 1036, 5592, 3811,  749, 8024, 2157, 7270, 7444,\n",
      "        6206, 6981, 1394, 1278, 4495, 4989, 1315, 3780, 4545, 8024, 6981, 1394,\n",
      "        5499, 5517, 1121, 1327, 8024, 2400, 1075, 2768, 5679, 1962, 4638, 1310,\n",
      "        4495,  739, 2679,  511, 2157, 7270, 2418, 6421, 3800, 2692,  679, 6206,\n",
      "        1075, 2768, 2111, 2094, 2904, 7608,  974, 7608, 4638, 3688, 4567, 8024,\n",
      "        1394, 4415, 5612, 7608,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103, 2207, 2111, 4638, 7991, 1928,  677, 3300, 4635, 5682, 4638, 4157,\n",
      "        4307, 4289,  117,  679, 4563,  119,  679, 4573,  119, 3221,  784, 8043,\n",
      "        3297, 6818, 1355, 4385, 2207, 2111, 7991, 1928, 3300, 7151, 4157, 4307,\n",
      "        4638, 2207, 4635, 4157, 8024, 6814,  749, 1126, 1921, 1359, 1920,  749,\n",
      "         511,  679, 4761, 6887,  784,  720, 1726,  752, 8043,  872, 2989, 6835,\n",
      "        4638, 3221, 7991, 1928, 4142, 8024, 6224,  754, 5632, 6716, 1259, 4649,\n",
      "        6814, 7270, 8024, 1259, 5749, 8024, 2772,  702,  782, 1310, 4495, 2792,\n",
      "        5636, 4638,  511, 2456, 6379, 6783, 3890, 7474, 4017, 2834, 4495, 5162,\n",
      "        8024,  738, 1377,  809, 4500, 1963, 2692, 7032, 7942, 3141, 6763, 5601,\n",
      "        1912, 3864, 3780, 4545,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2207, 2111, 4638, 7991, 1928,  677, 3300, 4635, 5682, 4638, 4157,\n",
      "        4307, 4289,  117,  679, 4563,  119,  679, 4573,  119, 3221,  784, 8043,\n",
      "        3297, 6818, 1355, 4385, 2207, 2111, 7991, 1928, 3300, 7151, 4157, 4307,\n",
      "        4638, 2207, 4635, 4157, 8024, 6814,  749, 1126, 1921, 1359, 1920,  749,\n",
      "         511,  679, 4761, 6887,  784,  720, 1726,  752, 8043,  872, 2989, 6835,\n",
      "        4638, 3221, 7991, 1928, 4142, 8024, 6224,  754, 5632, 6716, 1259, 4649,\n",
      "        6814, 7270, 8024, 1259, 5749, 8024, 2772,  702,  782, 1310, 4495, 2792,\n",
      "        5636, 4638,  511, 2456, 6379, 6783, 3890, 7474, 4017, 2834, 4495, 5162,\n",
      "        8024,  738, 1377,  809, 4500, 1963, 2692, 7032, 7942, 3141, 6763, 5601,\n",
      "        1912, 3864, 3780, 4545,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 13/9000 [00:01<10:49, 13.84it/s, loss=2.2564116]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 1063, 2259, 2207, 2111, 4706, 4714,  679,  977, 4699, 2582,  720,\n",
      "        1215, 8043, 1063, 2259, 2207, 1036, 4706, 4714, 4699, 2582,  720, 1215,\n",
      "        1343, 3389,  671,  678, 6228, 1213, 8024, 4692,  833,  679,  833, 2235,\n",
      "        1045,  679, 3633,  511, 6206, 2831, 5165, 8024, 2207, 1377,  809, 4763,\n",
      "        3633, 8024, 7370,  749, 1350, 3198, 3780, 4545, 2207, 1036, 1912, 4706,\n",
      "        4567, 1912, 8024, 2642, 5442, 7444, 6206, 1914, 1486, 6418,  683, 2157,\n",
      "        2456, 6379, 8024, 1469, 1278, 4495,  924, 2898, 3765, 6858, 8024, 2642,\n",
      "        5442, 6820, 7444, 6206, 7028, 6228, 7650, 7608, 3175, 7481, 8024,  891,\n",
      "        1963, 3189, 2382, 3926, 3909, 7650, 7608, 8024, 1914, 1912, 1139, 6817,\n",
      "        1220,  511,  680, 3634, 1398, 3198, 2642, 5442, 6820, 6206, 3800, 2692,\n",
      "        6848, 2885,  671, 2157, 3633, 6226, 1278, 7368, 6402, 3780, 8024, 6821,\n",
      "        3416, 2798, 5543, 2533, 1168, 5679, 1962, 4638, 3780, 4545, 3126, 3362,\n",
      "         511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 1063, 2259, 2207, 2111, 4706, 4714,  679,  977, 4699, 2582,  720,\n",
      "        1215, 8043, 1063, 2259, 2207, 1036, 4706, 4714, 4699, 2582,  720, 1215,\n",
      "        1343, 3389,  671,  678, 6228, 1213, 8024, 4692,  833,  679,  833, 2235,\n",
      "        1045,  679, 3633,  511, 6206, 2831, 5165, 8024, 2207, 1377,  809, 4763,\n",
      "        3633, 8024, 7370,  749, 1350, 3198, 3780, 4545, 2207, 1036, 1912, 4706,\n",
      "        4567, 1912, 8024, 2642, 5442, 7444, 6206, 1914, 1486, 6418,  683, 2157,\n",
      "        2456, 6379, 8024, 1469, 1278, 4495,  924, 2898, 3765, 6858, 8024, 2642,\n",
      "        5442, 6820, 7444, 6206, 7028, 6228, 7650, 7608, 3175, 7481, 8024,  891,\n",
      "        1963, 3189, 2382, 3926, 3909, 7650, 7608, 8024, 1914, 1912, 1139, 6817,\n",
      "        1220,  511,  680, 3634, 1398, 3198, 2642, 5442, 6820, 6206, 3800, 2692,\n",
      "        6848, 2885,  671, 2157, 3633, 6226, 1278, 7368, 6402, 3780, 8024, 6821,\n",
      "        3416, 2798, 5543, 2533, 1168, 5679, 1962, 4638, 3780, 4545, 3126, 3362,\n",
      "         511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103, 2111, 2094, 5307, 2382, 1928, 4563, 1353, 1908, 1468, 1726,  752,\n",
      "        8043, 2111, 2094, 5307, 2382, 1928, 4563, 8024, 1353, 4633, 1468, 1726,\n",
      "         752, 8024, 3241,  677, 3300, 3198, 2802, 2736, 8024, 1343, 1278, 7368,\n",
      "         798, 5301, 3466, 3389, 6814, 7965, 2094, 8024, 6432, 3221, 5593, 3416,\n",
      "         860, 5503, 1920, 8024, 2456, 6379,  976, 2797, 3318, 8024, 1400, 3341,\n",
      "         738, 3766,  976, 8024, 1728,  711, 6432,  976, 2797, 3318,  679, 1962,\n",
      "        8024, 3418, 2945,  872, 4638, 4567, 2658, 6382, 6835, 8024, 2111, 2094,\n",
      "        2642, 5593, 3416,  860, 5503, 1920, 8024, 5307, 2382, 1928, 4578, 8024,\n",
      "        3300, 1377, 5543, 3221, 7965, 4977, 4142, 2471, 3341, 4638, 8024, 3300,\n",
      "        1377, 5543, 3221,  702, 4868, 5307, 4563,  511, 2456, 6379, 1343, 1278,\n",
      "        7368, 5455, 7965, 1590, 4906, 1908, 6402, 8024, 2864,  702, 7965, 4977,\n",
      "        9162,  976,  702, 5307, 5554, 1914, 3249, 1239,  798, 5301, 3466, 3389,\n",
      "        8024, 6402, 3171, 1400, 2190, 4568, 3780, 4545,  511, 1914, 3623, 2622,\n",
      "        8024, 4881, 7608, 6789, 6793, 2802, 1140, 4638, 7608, 4289,  511,  809,\n",
      "         677, 3221, 2190,  100, 2111, 2094, 5307, 2382, 1928, 4563, 8024, 1353,\n",
      "        4633, 1468, 1726,  752,  100, 6821,  702, 7309, 7579, 4638, 2456, 6379,\n",
      "        8024, 3309, 3307, 2190, 2644, 3300, 2376, 1221, 8024, 4867, 2644,  978,\n",
      "        2434, 8013,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2111, 2094, 5307, 2382, 1928, 4563, 1353, 1908, 1468, 1726,  752,\n",
      "        8043, 2111, 2094, 5307, 2382, 1928, 4563, 8024, 1353, 4633, 1468, 1726,\n",
      "         752, 8024, 3241,  677, 3300, 3198, 2802, 2736, 8024, 1343, 1278, 7368,\n",
      "         798, 5301, 3466, 3389, 6814, 7965, 2094, 8024, 6432, 3221, 5593, 3416,\n",
      "         860, 5503, 1920, 8024, 2456, 6379,  976, 2797, 3318, 8024, 1400, 3341,\n",
      "         738, 3766,  976, 8024, 1728,  711, 6432,  976, 2797, 3318,  679, 1962,\n",
      "        8024, 3418, 2945,  872, 4638, 4567, 2658, 6382, 6835, 8024, 2111, 2094,\n",
      "        2642, 5593, 3416,  860, 5503, 1920, 8024, 5307, 2382, 1928, 4578, 8024,\n",
      "        3300, 1377, 5543, 3221, 7965, 4977, 4142, 2471, 3341, 4638, 8024, 3300,\n",
      "        1377, 5543, 3221,  702, 4868, 5307, 4563,  511, 2456, 6379, 1343, 1278,\n",
      "        7368, 5455, 7965, 1590, 4906, 1908, 6402, 8024, 2864,  702, 7965, 4977,\n",
      "        9162,  976,  702, 5307, 5554, 1914, 3249, 1239,  798, 5301, 3466, 3389,\n",
      "        8024, 6402, 3171, 1400, 2190, 4568, 3780, 4545,  511, 1914, 3623, 2622,\n",
      "        8024, 4881, 7608, 6789, 6793, 2802, 1140, 4638, 7608, 4289,  511,  809,\n",
      "         677, 3221, 2190,  100, 2111, 2094, 5307, 2382, 1928, 4563, 8024, 1353,\n",
      "        4633, 1468, 1726,  752,  100, 6821,  702, 7309, 7579, 4638, 2456, 6379,\n",
      "        8024, 3309, 3307, 2190, 2644, 3300, 2376, 1221, 8024, 4867, 2644,  978,\n",
      "        2434, 8013,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103, 2797, 6639, 1366, 4567, 1469, 2405, 1036, 2593, 4562, 3300,  784,\n",
      "         720, 1277, 1166, 8043, 2797, 6639, 1366, 4567, 1469, 2405, 1036, 2593,\n",
      "        4562, 1277, 1166, 8043, 2797, 6639, 1366, 4567, 1469, 2405, 1036, 2593,\n",
      "        4562, 6963, 3221, 4567, 3681, 2697, 3381, 5636,  886, 4638, 8024, 6963,\n",
      "        3221, 2593, 2595,  837, 3381, 2595, 4565, 4567, 8024, 2797, 6639, 1366,\n",
      "        4567, 3221, 6858, 6814, 7607, 3773, 8024, 4958, 3698, 8024, 1552, 3890,\n",
      "        8024, 2170, 2773, 8024, 2141, 3177, 2697, 3381, 4638, 8024, 3221, 1461,\n",
      "        1429, 6887,  837, 3381, 2595, 4565, 4567, 8024, 2797, 6639, 1366, 4567,\n",
      "         712, 6206, 6134, 4385,  711, 2797, 2552, 8024, 6639, 2552, 8024, 1366,\n",
      "        5579, 5111, 5606, 4638, 4557, 4562,  511, 3780, 4545, 4638, 6413, 8024,\n",
      "        2797, 6639, 1366, 4567, 1469, 2405, 1036, 2593, 6402, 4906, 6963, 3221,\n",
      "        2834, 4567, 3681, 3780, 4545, 8024, 6963, 1377,  809, 4500, 1164, 2349,\n",
      "        7504, 3360, 3780, 4545,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2797, 6639, 1366, 4567, 1469, 2405, 1036, 2593, 4562, 3300,  784,\n",
      "         720, 1277, 1166, 8043, 2797, 6639, 1366, 4567, 1469, 2405, 1036, 2593,\n",
      "        4562, 1277, 1166, 8043, 2797, 6639, 1366, 4567, 1469, 2405, 1036, 2593,\n",
      "        4562, 6963, 3221, 4567, 3681, 2697, 3381, 5636,  886, 4638, 8024, 6963,\n",
      "        3221, 2593, 2595,  837, 3381, 2595, 4565, 4567, 8024, 2797, 6639, 1366,\n",
      "        4567, 3221, 6858, 6814, 7607, 3773, 8024, 4958, 3698, 8024, 1552, 3890,\n",
      "        8024, 2170, 2773, 8024, 2141, 3177, 2697, 3381, 4638, 8024, 3221, 1461,\n",
      "        1429, 6887,  837, 3381, 2595, 4565, 4567, 8024, 2797, 6639, 1366, 4567,\n",
      "         712, 6206, 6134, 4385,  711, 2797, 2552, 8024, 6639, 2552, 8024, 1366,\n",
      "        5579, 5111, 5606, 4638, 4557, 4562,  511, 3780, 4545, 4638, 6413, 8024,\n",
      "        2797, 6639, 1366, 4567, 1469, 2405, 1036, 2593, 6402, 4906, 6963, 3221,\n",
      "        2834, 4567, 3681, 3780, 4545, 8024, 6963, 1377,  809, 4500, 1164, 2349,\n",
      "        7504, 3360, 3780, 4545,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 17/9000 [00:01<10:48, 13.86it/s, loss=3.3116119]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 1044, 4495, 3381, 5682,  860,  679, 3633, 2382, 2582,  720, 3780,\n",
      "        4545, 8043, 3766, 3300, 4568, 4307, 1355, 4567, 3198, 7313, 1350, 1333,\n",
      "        1728, 1377, 5543, 3221, 1921, 4495, 4638, 4567, 2658, 1146, 3358, 8038,\n",
      "        6821,  702, 2418, 6421, 3221, 1044, 1921, 4638, 8024, 2682, 1343, 2957,\n",
      "        3221, 2523, 7410, 4638, 8013, 1377,  809, 1168,  683, 7305, 4638, 4511,\n",
      "        2595,  683, 4906, 1278, 7368, 1343, 3466, 3389,  678, 4638,  679, 6206,\n",
      "        6814,  754, 4638, 2857, 2552, 8013, 2900, 2193, 2692, 6224, 8038, 2456,\n",
      "        6379, 2644, 4638, 1044, 4495, 1168, 1278, 7368, 1343, 3466, 3389,  678,\n",
      "        8024, 3418, 2945, 3466, 3389, 5310, 3362, 6822, 6121, 3780, 4545, 8013,\n",
      "        1147, 2555, 7390,  912, 3302, 5790, 8024, 1963, 3362, 3302, 5790, 6435,\n",
      "        6905, 1278, 1671, 8013, 1398, 3198, 6206,  924, 2898,  671,  702, 5679,\n",
      "        1962, 4638, 2552, 2578, 8024, 4916, 3353, 4638, 2552, 2578, 2190, 4565,\n",
      "        4567, 4638, 3780, 4545, 3221, 2523, 3300, 2376, 1221, 4638, 8013, 6716,\n",
      "         860,  978, 2434, 8024, 3193, 3189, 3300,  702, 1962, 2140, 2140, 8013,\n",
      "         101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 1044, 4495, 3381, 5682,  860,  679, 3633, 2382, 2582,  720, 3780,\n",
      "        4545, 8043, 3766, 3300, 4568, 4307, 1355, 4567, 3198, 7313, 1350, 1333,\n",
      "        1728, 1377, 5543, 3221, 1921, 4495, 4638, 4567, 2658, 1146, 3358, 8038,\n",
      "        6821,  702, 2418, 6421, 3221, 1044, 1921, 4638, 8024, 2682, 1343, 2957,\n",
      "        3221, 2523, 7410, 4638, 8013, 1377,  809, 1168,  683, 7305, 4638, 4511,\n",
      "        2595,  683, 4906, 1278, 7368, 1343, 3466, 3389,  678, 4638,  679, 6206,\n",
      "        6814,  754, 4638, 2857, 2552, 8013, 2900, 2193, 2692, 6224, 8038, 2456,\n",
      "        6379, 2644, 4638, 1044, 4495, 1168, 1278, 7368, 1343, 3466, 3389,  678,\n",
      "        8024, 3418, 2945, 3466, 3389, 5310, 3362, 6822, 6121, 3780, 4545, 8013,\n",
      "        1147, 2555, 7390,  912, 3302, 5790, 8024, 1963, 3362, 3302, 5790, 6435,\n",
      "        6905, 1278, 1671, 8013, 1398, 3198, 6206,  924, 2898,  671,  702, 5679,\n",
      "        1962, 4638, 2552, 2578, 8024, 4916, 3353, 4638, 2552, 2578, 2190, 4565,\n",
      "        4567, 4638, 3780, 4545, 3221, 2523, 3300, 2376, 1221, 4638, 8013, 6716,\n",
      "         860,  978, 2434, 8024, 3193, 3189, 3300,  702, 1962, 2140, 2140, 8013,\n",
      "         101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103,  125, 2259, 4638, 2207, 1036,  833, 1139, 4385, 4495, 7270, 4578,\n",
      "        1408, 8043, 2797, 5495, 4578,  117, 5558, 1068, 5688, 4578,  117, 5520,\n",
      "        6956, 4578,  117, 5439, 1526, 1582,  117,  123, 1921,  117, 1333, 1728,\n",
      "        3018,  679, 3926, 3504,  117, 6821,  697, 1921, 2697, 1088,  749,  117,\n",
      "        1673, 2349,  738, 4578,  117, 3295, 5307, 4638, 3131, 3780, 2658, 1105,\n",
      "        1469, 3126, 3362, 8038, 2496, 1765, 1278, 7368, 6432, 3766,  752, 1036,\n",
      "         117, 1377, 3221,  800, 1526, 2533, 1325, 2154,  117, 1962, 6496, 2523,\n",
      "        4578, 4638, 3416, 2094,  119, 2582,  720, 1215,  106, 3309, 3307, 1278,\n",
      "        4495, 5314, 2769, 2456, 6379,  117, 3221,  679, 3221, 4495, 7270, 4578,\n",
      "         117, 3300, 4157, 2586, 3221, 1166, 4638, 3688, 4567,  117, 2644, 1962,\n",
      "        8039, 1724, 2259, 4638, 6413, 3221,  833, 1086, 3613, 1139, 4385, 4495,\n",
      "        7270, 4578, 4638, 8024, 6821, 3221, 2881, 3300, 3633, 2382, 4638, 4385,\n",
      "        6496, 4638,  511, 1377,  809, 6407,  671,  678, 3312, 4478, 5114, 5299,\n",
      "        3175, 8038, 3312, 4478, 5106,  124, 1046, 8024, 4343, 5489, 8145, 1046,\n",
      "        8024, 2002, 3723,  510, 6044, 6057, 1392, 6639, 7030,  511, 1169, 3791,\n",
      "        8038, 4500, 4343, 5489, 4215, 5114, 8024, 2521, 4225, 3198, 6444, 6822,\n",
      "        3312, 4478, 5106,  510, 2002, 3723,  510, 6044, 6057, 8024, 1086, 4215,\n",
      "        4924, 1217, 3778, 1315, 2768, 8024, 3680, 3189,  122, 8025,  123, 1177,\n",
      "         511, 1216, 4500, 8038, 4865, 3969, 6858, 5317, 3833, 6117,  511, 4495,\n",
      "        7270, 4578, 2190, 2111, 2094, 4638, 1314, 2154, 3683, 6772, 1920, 8024,\n",
      "        2456, 6379, 4266, 3678, 2372, 2111, 2094, 1168,  683, 4906, 1908, 6402,\n",
      "        8024, 1762, 1278, 4495, 2900, 2193,  678, 3131, 3780,  511, 3189, 2382,\n",
      "         704, 3221, 1377,  809, 5314,  680, 2111, 2094, 6639, 1916, 1914, 4638,\n",
      "        1068, 2552, 1469, 4212, 3160, 8024, 1914, 4692, 7028, 1071, 7650, 7608,\n",
      "        7309, 7579, 8024, 3309, 3307, 2111, 2094, 1377,  809, 2226, 2571, 2434,\n",
      "        1908, 8013,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103,  125, 2259, 4638, 2207, 1036,  833, 1139, 4385, 4495, 7270, 4578,\n",
      "        1408, 8043, 2797, 5495, 4578,  117, 5558, 1068, 5688, 4578,  117, 5520,\n",
      "        6956, 4578,  117, 5439, 1526, 1582,  117,  123, 1921,  117, 1333, 1728,\n",
      "        3018,  679, 3926, 3504,  117, 6821,  697, 1921, 2697, 1088,  749,  117,\n",
      "        1673, 2349,  738, 4578,  117, 3295, 5307, 4638, 3131, 3780, 2658, 1105,\n",
      "        1469, 3126, 3362, 8038, 2496, 1765, 1278, 7368, 6432, 3766,  752, 1036,\n",
      "         117, 1377, 3221,  800, 1526, 2533, 1325, 2154,  117, 1962, 6496, 2523,\n",
      "        4578, 4638, 3416, 2094,  119, 2582,  720, 1215,  106, 3309, 3307, 1278,\n",
      "        4495, 5314, 2769, 2456, 6379,  117, 3221,  679, 3221, 4495, 7270, 4578,\n",
      "         117, 3300, 4157, 2586, 3221, 1166, 4638, 3688, 4567,  117, 2644, 1962,\n",
      "        8039, 1724, 2259, 4638, 6413, 3221,  833, 1086, 3613, 1139, 4385, 4495,\n",
      "        7270, 4578, 4638, 8024, 6821, 3221, 2881, 3300, 3633, 2382, 4638, 4385,\n",
      "        6496, 4638,  511, 1377,  809, 6407,  671,  678, 3312, 4478, 5114, 5299,\n",
      "        3175, 8038, 3312, 4478, 5106,  124, 1046, 8024, 4343, 5489, 8145, 1046,\n",
      "        8024, 2002, 3723,  510, 6044, 6057, 1392, 6639, 7030,  511, 1169, 3791,\n",
      "        8038, 4500, 4343, 5489, 4215, 5114, 8024, 2521, 4225, 3198, 6444, 6822,\n",
      "        3312, 4478, 5106,  510, 2002, 3723,  510, 6044, 6057, 8024, 1086, 4215,\n",
      "        4924, 1217, 3778, 1315, 2768, 8024, 3680, 3189,  122, 8025,  123, 1177,\n",
      "         511, 1216, 4500, 8038, 4865, 3969, 6858, 5317, 3833, 6117,  511, 4495,\n",
      "        7270, 4578, 2190, 2111, 2094, 4638, 1314, 2154, 3683, 6772, 1920, 8024,\n",
      "        2456, 6379, 4266, 3678, 2372, 2111, 2094, 1168,  683, 4906, 1908, 6402,\n",
      "        8024, 1762, 1278, 4495, 2900, 2193,  678, 3131, 3780,  511, 3189, 2382,\n",
      "         704, 3221, 1377,  809, 5314,  680, 2111, 2094, 6639, 1916, 1914, 4638,\n",
      "        1068, 2552, 1469, 4212, 3160, 8024, 1914, 4692, 7028, 1071, 7650, 7608,\n",
      "        7309, 7579, 8024, 3309, 3307, 2111, 2094, 1377,  809, 2226, 2571, 2434,\n",
      "        1908, 8013,  101], device='cuda:0')\n",
      "private_positions =  tensor([  1,  31, 161, 166, 212, 214], device='cuda:0')\n",
      "input_ids =  tensor([ 103,  736,  702, 1288, 3299, 2140, 2140,  671, 1921, 2861,  676, 3613,\n",
      "        1920,  912, 3221, 1391, 1914,  749, 1408, 8043,  679, 4761, 6887, 2582,\n",
      "         720, 1726,  752, 8024, 2111, 2094, 3297, 6818, 2600, 3221,  679, 1420,\n",
      "        6413, 8024, 1526, 7317,  679,  828, 8024, 1343, 1278, 7368,  738, 3466,\n",
      "        3389,  738, 3766, 4500, 8024, 6435, 7309,  736,  702, 1288, 3299, 2140,\n",
      "        2140,  671, 1921, 2861,  676, 3613, 1920,  912, 3221, 1391, 1914,  749,\n",
      "        1408,  872, 4638, 6821, 4905, 2658, 1105, 1377, 5543, 3221, 3867, 1265,\n",
      "         679, 5679, 8024, 2456, 6379,  679, 6206, 1391, 3779, 5594,  722, 1501,\n",
      "        8024, 1377,  809, 4500,  924, 1469,  709, 1217, 1121, 3780, 4545, 8024,\n",
      "        2772, 4500, 5850, 1301, 5104, 4143, 4225, 1400, 1343, 1900, 4203, 3302,\n",
      "        8024, 3126, 3362, 3683, 6772, 1962,  511, 8024,  872, 1962, 8024, 3418,\n",
      "        2945,  872, 4638, 1360, 6835, 8024, 5440, 5991, 3221, 5375, 7159, 2772,\n",
      "        5442, 5375,  726, 2544, 7030, 1039, 5162, 2471, 6629, 4638, 8024, 1377,\n",
      "         809, 1265, 7741,  671,  678, 2544, 7030, 1039, 5162, 4692, 4692, 8024,\n",
      "        1366, 3302, 3177, 2209, 2434, 8024, 7824, 5498, 3779, 8024, 1914, 5335,\n",
      "        5162, 6407, 6407, 8024, 2714, 2714,  833, 3121, 1587, 4638, 8024, 4867,\n",
      "         872, 3193, 3189, 2434, 1908,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103,  736,  702, 1288, 3299, 2140, 2140,  671, 1921, 2861,  676, 3613,\n",
      "        1920,  912, 3221, 1391, 1914,  749, 1408, 8043,  679, 4761, 6887, 2582,\n",
      "         720, 1726,  752, 8024, 2111, 2094, 3297, 6818, 2600, 3221,  679, 1420,\n",
      "        6413, 8024, 1526, 7317,  679,  828, 8024, 1343, 1278, 7368,  738, 3466,\n",
      "        3389,  738, 3766, 4500, 8024, 6435, 7309,  736,  702, 1288, 3299, 2140,\n",
      "        2140,  671, 1921, 2861,  676, 3613, 1920,  912, 3221, 1391, 1914,  749,\n",
      "        1408,  872, 4638, 6821, 4905, 2658, 1105, 1377, 5543, 3221, 3867, 1265,\n",
      "         679, 5679, 8024, 2456, 6379,  679, 6206, 1391, 3779, 5594,  722, 1501,\n",
      "        8024, 1377,  809, 4500,  924, 1469,  709, 1217, 1121, 3780, 4545, 8024,\n",
      "        2772, 4500, 5850, 1301, 5104, 4143, 4225, 1400, 1343, 1900, 4203, 3302,\n",
      "        8024, 3126, 3362, 3683, 6772, 1962,  511, 8024,  872, 1962, 8024, 3418,\n",
      "        2945,  872, 4638, 1360, 6835, 8024, 5440, 5991, 3221, 5375, 7159, 2772,\n",
      "        5442, 5375,  726, 2544, 7030, 1039, 5162, 2471, 6629, 4638, 8024, 1377,\n",
      "         809, 1265, 7741,  671,  678, 2544, 7030, 1039, 5162, 4692, 4692, 8024,\n",
      "        1366, 3302, 3177, 2209, 2434, 8024, 7824, 5498, 3779, 8024, 1914, 5335,\n",
      "        5162, 6407, 6407, 8024, 2714, 2714,  833, 3121, 1587, 4638, 8024, 4867,\n",
      "         872, 3193, 3189, 2434, 1908,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 19/9000 [00:01<11:27, 13.05it/s, loss=2.9805856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 1495, 1644,  862, 3198, 2798, 5543, 1962, 8043, 2207, 2111,  123,\n",
      "        2259, 1288, 8024,  671,  702, 1914, 3299, 1184, 3466, 3389, 3221,  845,\n",
      "        3300, 1596, 2622, 2595, 4638, 3118, 3698, 5052, 4142,  872, 4638, 6821,\n",
      "        4905, 2658, 1105, 1377, 5543, 3221, 7599, 2170, 2697, 1088, 1495, 1644,\n",
      "        8024, 7599, 2170, 1495, 1644,  100, 8024, 4567, 6395, 1399,  511, 2697,\n",
      "        1358, 7599, 2170, 2792, 5636, 4638, 1495, 1644,  511, 3315, 6395,  809,\n",
      "        1495, 1644, 7574,  868, 8024, 4588, 4921, 5682, 4635, 8024, 7965, 3837,\n",
      "        3926, 3873, 8024, 5649, 3909, 5273, 4635, 8024, 5726, 5946, 1495, 1644,\n",
      "        1898, 7028, 8024, 1928, 4578, 6716, 4178, 8024, 4493, 1156, 1596, 2593,\n",
      "         711, 4294, 2519,  511, 1377,  809, 4500,  676, 2871, 3739, 1217, 7360,\n",
      "        3698, 1265, 4588, 4638, 5790, 4289, 3780, 4545, 8024, 6863, 2768, 2207,\n",
      "        1036, 1461, 1429, 5143, 5320, 4638, 1728, 5162, 6772, 1914, 8024, 1963,\n",
      "        3362, 2111, 2094, 6158, 1316, 4802, 6402,  711, 2207, 1036, 1461, 1429,\n",
      "        5143, 5320,  749, 8024, 2157, 7270, 7444, 6206, 6981, 1394, 1278, 4495,\n",
      "        4916, 3353, 3780, 4545, 8024, 6981, 1394, 5499, 5517, 1121, 1327, 8024,\n",
      "        2400, 1075, 2768, 5679, 1962, 4638, 1310, 4495,  739, 2679,  511, 2111,\n",
      "        2094, 7444, 6206, 1394, 4415, 7650, 7608, 8024, 6912, 1048, 1173, 4080,\n",
      "        2170, 1107, 7608, 4289,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 1495, 1644,  862, 3198, 2798, 5543, 1962, 8043, 2207, 2111,  123,\n",
      "        2259, 1288, 8024,  671,  702, 1914, 3299, 1184, 3466, 3389, 3221,  845,\n",
      "        3300, 1596, 2622, 2595, 4638, 3118, 3698, 5052, 4142,  872, 4638, 6821,\n",
      "        4905, 2658, 1105, 1377, 5543, 3221, 7599, 2170, 2697, 1088, 1495, 1644,\n",
      "        8024, 7599, 2170, 1495, 1644,  100, 8024, 4567, 6395, 1399,  511, 2697,\n",
      "        1358, 7599, 2170, 2792, 5636, 4638, 1495, 1644,  511, 3315, 6395,  809,\n",
      "        1495, 1644, 7574,  868, 8024, 4588, 4921, 5682, 4635, 8024, 7965, 3837,\n",
      "        3926, 3873, 8024, 5649, 3909, 5273, 4635, 8024, 5726, 5946, 1495, 1644,\n",
      "        1898, 7028, 8024, 1928, 4578, 6716, 4178, 8024, 4493, 1156, 1596, 2593,\n",
      "         711, 4294, 2519,  511, 1377,  809, 4500,  676, 2871, 3739, 1217, 7360,\n",
      "        3698, 1265, 4588, 4638, 5790, 4289, 3780, 4545, 8024, 6863, 2768, 2207,\n",
      "        1036, 1461, 1429, 5143, 5320, 4638, 1728, 5162, 6772, 1914, 8024, 1963,\n",
      "        3362, 2111, 2094, 6158, 1316, 4802, 6402,  711, 2207, 1036, 1461, 1429,\n",
      "        5143, 5320,  749, 8024, 2157, 7270, 7444, 6206, 6981, 1394, 1278, 4495,\n",
      "        4916, 3353, 3780, 4545, 8024, 6981, 1394, 5499, 5517, 1121, 1327, 8024,\n",
      "        2400, 1075, 2768, 5679, 1962, 4638, 1310, 4495,  739, 2679,  511, 2111,\n",
      "        2094, 7444, 6206, 1394, 4415, 7650, 7608, 8024, 6912, 1048, 1173, 4080,\n",
      "        2170, 1107, 7608, 4289,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([11], device='cuda:0')\n",
      "input_ids =  tensor([ 103,  711,  784,  720, 2207, 2111, 1920,  912, 7000, 5634, 1456, 8043,\n",
      "        6422, 5301, 4567, 2658, 1350, 1486, 6418, 4680, 4638,  131, 1920,  912,\n",
      "        3300, 6772, 3849, 4638, 7000, 5634, 1456, 4680, 1184,  671, 5663, 2658,\n",
      "        1105,  131, 7608, 3617, 1469, 2207,  912, 6963, 3633, 2382,  117,  124,\n",
      "         118,  125, 1921,  671, 3613, 1920,  912, 6774, 1221, 3466, 3389,  131,\n",
      "        1071, 2124,  131, 1600,  702, 2207, 1036,  673, 3215, 5763, 5018,  671,\n",
      "        3613, 7309, 7579, 6133, 1041,  131, 2207, 1036, 3221, 3678,  745, 1585,\n",
      "        1075,  872, 1962, 8013, 2140, 2140, 1920,  912,  704, 2372, 3300, 7000,\n",
      "        5634, 4638, 3698, 1456, 8024, 5440, 5991, 3300, 3867, 1265,  679, 5679,\n",
      "        4638, 4385, 6496, 8024, 1377, 5543, 3221, 1419, 6028, 4635, 6574, 4638,\n",
      "        7608, 4289, 1391, 1914,  749, 8024, 6821,  763, 6028, 4635, 6574, 1377,\n",
      "         704, 1469, 5517, 7027, 4638, 5517, 7000, 8024, 6821, 3416, 2218, 7360,\n",
      "         856,  749, 5517, 3890, 4638, 7000, 2428, 8024,  886, 6028, 4635, 6574,\n",
      "         679, 5543, 1041, 1146, 1765, 3867, 1265, 1429, 3119, 8024, 1086, 1217,\n",
      "         677, 5499, 5579, 1079, 5301, 5826, 4638, 1146, 6237,  807, 6468, 8024,\n",
      "        6863, 2768, 2140, 2140, 4638, 1920,  912, 2523, 5634,  511, 2456, 6379,\n",
      "        1377, 2199, 1959, 5106, 6844, 2496, 1103, 6444, 3909,  671, 4157,  511,\n",
      "        3678,  745, 1585, 1075, 1968, 1968, 1914, 1391, 5922, 5831,  680, 3717,\n",
      "        3362, 8024, 1914, 1600, 3717, 8024, 6844, 2496, 5489,  510, 6028,  510,\n",
      "        7824, 8024, 1121, 2208, 7770, 5544, 7608, 4289, 4638, 3029, 1057, 8024,\n",
      "         886, 3678,  745, 5852, 1075, 1059, 7481,  684, 3211, 1429, 3119, 8024,\n",
      "        1398, 3198, 1377,  809, 3302, 4500, 1968, 1488, 4263,  511,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103,  711,  784,  720, 2207, 2111, 1920,  912, 7000, 5634, 1456, 8043,\n",
      "        6422, 5301, 4567, 2658, 1350, 1486, 6418, 4680, 4638,  131, 1920,  912,\n",
      "        3300, 6772, 3849, 4638, 7000, 5634, 1456, 4680, 1184,  671, 5663, 2658,\n",
      "        1105,  131, 7608, 3617, 1469, 2207,  912, 6963, 3633, 2382,  117,  124,\n",
      "         118,  125, 1921,  671, 3613, 1920,  912, 6774, 1221, 3466, 3389,  131,\n",
      "        1071, 2124,  131, 1600,  702, 2207, 1036,  673, 3215, 5763, 5018,  671,\n",
      "        3613, 7309, 7579, 6133, 1041,  131, 2207, 1036, 3221, 3678,  745, 1585,\n",
      "        1075,  872, 1962, 8013, 2140, 2140, 1920,  912,  704, 2372, 3300, 7000,\n",
      "        5634, 4638, 3698, 1456, 8024, 5440, 5991, 3300, 3867, 1265,  679, 5679,\n",
      "        4638, 4385, 6496, 8024, 1377, 5543, 3221, 1419, 6028, 4635, 6574, 4638,\n",
      "        7608, 4289, 1391, 1914,  749, 8024, 6821,  763, 6028, 4635, 6574, 1377,\n",
      "         704, 1469, 5517, 7027, 4638, 5517, 7000, 8024, 6821, 3416, 2218, 7360,\n",
      "         856,  749, 5517, 3890, 4638, 7000, 2428, 8024,  886, 6028, 4635, 6574,\n",
      "         679, 5543, 1041, 1146, 1765, 3867, 1265, 1429, 3119, 8024, 1086, 1217,\n",
      "         677, 5499, 5579, 1079, 5301, 5826, 4638, 1146, 6237,  807, 6468, 8024,\n",
      "        6863, 2768, 2140, 2140, 4638, 1920,  912, 2523, 5634,  511, 2456, 6379,\n",
      "        1377, 2199, 1959, 5106, 6844, 2496, 1103, 6444, 3909,  671, 4157,  511,\n",
      "        3678,  745, 1585, 1075, 1968, 1968, 1914, 1391, 5922, 5831,  680, 3717,\n",
      "        3362, 8024, 1914, 1600, 3717, 8024, 6844, 2496, 5489,  510, 6028,  510,\n",
      "        7824, 8024, 1121, 2208, 7770, 5544, 7608, 4289, 4638, 3029, 1057, 8024,\n",
      "         886, 3678,  745, 5852, 1075, 1059, 7481,  684, 3211, 1429, 3119, 8024,\n",
      "        1398, 3198, 1377,  809, 3302, 4500, 1968, 1488, 4263,  511,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([47, 49], device='cuda:0')\n",
      "input_ids =  tensor([ 103, 2111, 2094, 1139, 4385, 2793, 3425,  860, 4142, 7410, 1358, 6421,\n",
      "        2582, 3416, 3780, 4545, 1962, 8043, 2769, 2157, 4638, 2111, 2094, 3221,\n",
      "        4511, 2140, 2140, 8024,  129, 2259, 8024,  671, 2458, 1993, 8024, 1624,\n",
      "        2094, 4706, 3300, 4157, 4578, 8024, 2175, 6230, 1168, 8024, 1495, 1644,\n",
      "        3683, 6772, 1196, 4164, 8024, 1369, 1912, 8024, 1962, 1008,  856, 4173,\n",
      "         671, 4684, 6963, 3766, 6842, 8024, 6435, 7309, 8038, 2111, 2094, 1139,\n",
      "        4385, 2793, 3425,  860, 4142, 7410, 1358, 6421, 2582, 3416, 3780, 4545,\n",
      "        1962,  511, 3780, 4545, 4638, 6413, 7674, 1044, 1377, 3418, 2945, 2111,\n",
      "        2094, 4568, 4307, 5314,  750, 2190, 4568, 3867, 4142, 5790, 8024, 1369,\n",
      "        1912, 6820, 1377, 6822, 6121, 2229, 6956, 3780, 4545, 8024, 1259, 2886,\n",
      "        2793, 3425,  860, 7391, 4973, 1103, 3819, 8024, 2793, 3425,  860, 1079,\n",
      "        5790, 4289, 3800, 2198, 8024, 4080, 1045, 3780, 4545, 5023, 8024, 1498,\n",
      "        4578, 4638, 2658, 1105,  678,  738, 1377, 5314, 2111, 2094, 4500, 4157,\n",
      "        7252, 4578, 5790, 8024, 2111, 2094, 2898, 5330, 1355, 4178, 1156, 1350,\n",
      "        3198, 2418, 4500, 6842, 4173, 5790, 8024, 3313, 6631, 6814, 8218,  119,\n",
      "         126, 3029, 3694, 2428, 4638, 1377,  809, 4289, 4415, 7360, 3946, 8024,\n",
      "         809,  677, 6963, 3221, 3683, 6772, 2382, 4500, 4638, 3780, 4545, 3175,\n",
      "        3791, 8024,  852, 3221, 1963, 3362, 2111, 2094, 2793, 3425,  860, 4142,\n",
      "        1353, 1353, 1908, 1908, 1355, 4495, 4638, 6413, 8024, 2456, 6379, 3221,\n",
      "        1377,  809, 2226, 3193, 2797, 3318, 4638, 8024, 4567, 2658, 1962, 6760,\n",
      "        1400, 2456, 6379, 2372, 2111, 2094, 6844, 2496, 6817, 1220, 8024, 2990,\n",
      "        7770, 1048, 4554, 1213, 8024,  809, 7344, 3632, 1086, 3613, 1908, 1355,\n",
      "         511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2111, 2094, 1139, 4385, 2793, 3425,  860, 4142, 7410, 1358, 6421,\n",
      "        2582, 3416, 3780, 4545, 1962, 8043, 2769, 2157, 4638, 2111, 2094, 3221,\n",
      "        4511, 2140, 2140, 8024,  129, 2259, 8024,  671, 2458, 1993, 8024, 1624,\n",
      "        2094, 4706, 3300, 4157, 4578, 8024, 2175, 6230, 1168, 8024, 1495, 1644,\n",
      "        3683, 6772, 1196, 4164, 8024, 1369, 1912, 8024, 1962, 1008,  856, 4173,\n",
      "         671, 4684, 6963, 3766, 6842, 8024, 6435, 7309, 8038, 2111, 2094, 1139,\n",
      "        4385, 2793, 3425,  860, 4142, 7410, 1358, 6421, 2582, 3416, 3780, 4545,\n",
      "        1962,  511, 3780, 4545, 4638, 6413, 7674, 1044, 1377, 3418, 2945, 2111,\n",
      "        2094, 4568, 4307, 5314,  750, 2190, 4568, 3867, 4142, 5790, 8024, 1369,\n",
      "        1912, 6820, 1377, 6822, 6121, 2229, 6956, 3780, 4545, 8024, 1259, 2886,\n",
      "        2793, 3425,  860, 7391, 4973, 1103, 3819, 8024, 2793, 3425,  860, 1079,\n",
      "        5790, 4289, 3800, 2198, 8024, 4080, 1045, 3780, 4545, 5023, 8024, 1498,\n",
      "        4578, 4638, 2658, 1105,  678,  738, 1377, 5314, 2111, 2094, 4500, 4157,\n",
      "        7252, 4578, 5790, 8024, 2111, 2094, 2898, 5330, 1355, 4178, 1156, 1350,\n",
      "        3198, 2418, 4500, 6842, 4173, 5790, 8024, 3313, 6631, 6814, 8218,  119,\n",
      "         126, 3029, 3694, 2428, 4638, 1377,  809, 4289, 4415, 7360, 3946, 8024,\n",
      "         809,  677, 6963, 3221, 3683, 6772, 2382, 4500, 4638, 3780, 4545, 3175,\n",
      "        3791, 8024,  852, 3221, 1963, 3362, 2111, 2094, 2793, 3425,  860, 4142,\n",
      "        1353, 1353, 1908, 1908, 1355, 4495, 4638, 6413, 8024, 2456, 6379, 3221,\n",
      "        1377,  809, 2226, 3193, 2797, 3318, 4638, 8024, 4567, 2658, 1962, 6760,\n",
      "        1400, 2456, 6379, 2372, 2111, 2094, 6844, 2496, 6817, 1220, 8024, 2990,\n",
      "        7770, 1048, 4554, 1213, 8024,  809, 7344, 3632, 1086, 3613, 1908, 1355,\n",
      "         511,  101], device='cuda:0')\n",
      "private_positions =  tensor([ 28, 178, 180], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 23/9000 [00:01<11:28, 13.05it/s, loss=3.1657641]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 2207, 1036, 2793, 3425,  860, 4142, 4563, 6421, 2582, 3416, 3780,\n",
      "        3126, 3362, 1962, 8043, 2769, 2157, 1957, 2140, 8024,  791, 2399,  122,\n",
      "        2259, 8024,  671, 2458, 1993, 8024, 6432, 6413, 3198, 6230, 2533, 1624,\n",
      "        2094, 4563, 8024, 2175, 6230, 1168, 8024, 1495, 1644, 3683, 6772, 1196,\n",
      "        4164, 8024, 5445,  684, 8024,  671, 4684, 6963, 3300, 4157, 1355, 4173,\n",
      "        8024, 6435, 7309, 8038, 2207, 1036, 2793, 3425,  860, 4142, 4563, 6421,\n",
      "        2582, 3416, 3780, 3126, 3362, 1962,  511, 3780, 4545, 4638, 6413, 7674,\n",
      "        1044, 1377, 3418, 2945, 2111, 2094, 4568, 4307, 5314,  750, 2190, 4568,\n",
      "        3867, 4142, 5790, 8024,  738, 1377, 2229, 6956, 1103, 3819, 2772, 3221,\n",
      "        2229, 6956, 1613, 5790, 8024, 2793, 3425,  860, 1079,  738, 1377, 3800,\n",
      "        2198, 2190, 4568, 5790, 4289, 8024, 4545, 3126, 6963, 3221,  679, 7231,\n",
      "        4638, 8024,  738, 1377,  809, 3418, 2945, 2111, 2094, 4638, 2658, 1105,\n",
      "        5314, 4157, 7252, 4578, 5790, 8024, 2215, 1071, 3221, 1624, 2094, 4563,\n",
      "        4578, 1196, 4164, 4638, 3198,  952, 8024, 1377, 2376, 1221, 5353, 6237,\n",
      "        4578, 5736, 8024, 1369, 1912, 1963, 3362,  845, 3300, 1355, 4173, 4638,\n",
      "        2658, 1105, 4638, 6413, 8024, 6929,  720,  738, 1377, 3302, 4500,  671,\n",
      "         763, 6842, 4173, 5790, 8024, 7770, 4173, 4638, 6413, 6820, 3221, 2456,\n",
      "        6379, 6206, 2226, 3193, 2218, 1278, 4638, 8024, 7370,  749, 6821,  763,\n",
      "        5790, 4289, 3780, 4545, 4638, 3175, 3791,  722, 1912, 8024, 1963, 3362,\n",
      "        2111, 2094, 2600, 3221, 1353, 1908, 1355, 4495, 4142, 4568, 4638, 6413,\n",
      "        8024, 2157, 7270,  738, 1377, 1762, 1278, 4495, 4638, 6224,  671,  678,\n",
      "        6848, 2885, 2797, 3318, 6822, 6121, 3780, 4545, 4638, 8024, 3780, 4545,\n",
      "        3309, 7313,  712, 6206, 6206, 5314, 2111, 2094,  976, 1962,  924, 3265,\n",
      "        2339,  868, 8024, 6912, 1048, 4708, 1117, 1217, 1196, 4568, 4307,  511,\n",
      "         101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2207, 1036, 2793, 3425,  860, 4142, 4563, 6421, 2582, 3416, 3780,\n",
      "        3126, 3362, 1962, 8043, 2769, 2157, 1957, 2140, 8024,  791, 2399,  122,\n",
      "        2259, 8024,  671, 2458, 1993, 8024, 6432, 6413, 3198, 6230, 2533, 1624,\n",
      "        2094, 4563, 8024, 2175, 6230, 1168, 8024, 1495, 1644, 3683, 6772, 1196,\n",
      "        4164, 8024, 5445,  684, 8024,  671, 4684, 6963, 3300, 4157, 1355, 4173,\n",
      "        8024, 6435, 7309, 8038, 2207, 1036, 2793, 3425,  860, 4142, 4563, 6421,\n",
      "        2582, 3416, 3780, 3126, 3362, 1962,  511, 3780, 4545, 4638, 6413, 7674,\n",
      "        1044, 1377, 3418, 2945, 2111, 2094, 4568, 4307, 5314,  750, 2190, 4568,\n",
      "        3867, 4142, 5790, 8024,  738, 1377, 2229, 6956, 1103, 3819, 2772, 3221,\n",
      "        2229, 6956, 1613, 5790, 8024, 2793, 3425,  860, 1079,  738, 1377, 3800,\n",
      "        2198, 2190, 4568, 5790, 4289, 8024, 4545, 3126, 6963, 3221,  679, 7231,\n",
      "        4638, 8024,  738, 1377,  809, 3418, 2945, 2111, 2094, 4638, 2658, 1105,\n",
      "        5314, 4157, 7252, 4578, 5790, 8024, 2215, 1071, 3221, 1624, 2094, 4563,\n",
      "        4578, 1196, 4164, 4638, 3198,  952, 8024, 1377, 2376, 1221, 5353, 6237,\n",
      "        4578, 5736, 8024, 1369, 1912, 1963, 3362,  845, 3300, 1355, 4173, 4638,\n",
      "        2658, 1105, 4638, 6413, 8024, 6929,  720,  738, 1377, 3302, 4500,  671,\n",
      "         763, 6842, 4173, 5790, 8024, 7770, 4173, 4638, 6413, 6820, 3221, 2456,\n",
      "        6379, 6206, 2226, 3193, 2218, 1278, 4638, 8024, 7370,  749, 6821,  763,\n",
      "        5790, 4289, 3780, 4545, 4638, 3175, 3791,  722, 1912, 8024, 1963, 3362,\n",
      "        2111, 2094, 2600, 3221, 1353, 1908, 1355, 4495, 4142, 4568, 4638, 6413,\n",
      "        8024, 2157, 7270,  738, 1377, 1762, 1278, 4495, 4638, 6224,  671,  678,\n",
      "        6848, 2885, 2797, 3318, 6822, 6121, 3780, 4545, 4638, 8024, 3780, 4545,\n",
      "        3309, 7313,  712, 6206, 6206, 5314, 2111, 2094,  976, 1962,  924, 3265,\n",
      "        2339,  868, 8024, 6912, 1048, 4708, 1117, 1217, 1196, 4568, 4307,  511,\n",
      "         101], device='cuda:0')\n",
      "private_positions =  tensor([23], device='cuda:0')\n",
      "input_ids =  tensor([ 103, 2207, 2111,  833, 2533, 2207, 5499,  706, 3698, 3221,  784,  720,\n",
      "        1333, 1728, 8043, 6821, 1126, 1921, 5439, 3352, 6432, 2769, 5125, 4868,\n",
      "         679, 1962, 8024, 2512, 1510,  749,  677, 4408, 4307, 2578, 8024, 1071,\n",
      "        2141, 2769,  738,  679, 2682, 4638, 8024, 3241,  677, 2600, 3221, 4717,\n",
      "         679, 4708, 8024, 3300, 3198,  952, 2697, 6230, 2552, 2707, 2707, 8024,\n",
      "         679, 1922, 5653, 3302, 8024, 1963, 3362,  698, 7028,  749, 2523, 2857,\n",
      "        2552, 2512, 1510, 6716,  860, 1469, 2339,  868, 8024, 6435, 7309, 2207,\n",
      "        2111,  833, 2533, 2207, 5499,  706, 3698, 3221,  784,  720, 1333, 1728,\n",
      "        1036, 4997, 4548, 3698, 1377, 7023, 4500, 1296, 5283, 4638,  704, 5790,\n",
      "        4548, 3698, 6150, 4545, 5553, 4548, 6150, 3791, 3780, 4545, 1377, 3780,\n",
      "        4545, 1392, 4905, 5592, 5500, 3765, 4548, 3698, 1469, 5553, 4548,  119,\n",
      "         704, 5790, 4548, 3698, 6150, 5553, 4548, 6150, 4545, 3791,  117, 5543,\n",
      "        6813, 6862, 6629, 1168, 3946, 7345, 3141, 2170,  117, 4415, 3698, 4495,\n",
      "        5491,  722, 1216, 3126,  117,  914, 6822, 6117, 3890, 2542, 4384,  117,\n",
      "        3121, 1587, 2229, 6956, 5491, 5489, 8020, 5025, 5606, 8021, 3173, 7357,\n",
      "         807, 6468,  117,  914, 6822, 4548, 4384, 1366, 1453, 1741, 5491, 5489,\n",
      "         680, 5025, 5606, 1872, 7270,  117, 1217, 6862, 1079, 4384, 1366, 4638,\n",
      "        7308, 1394,  117,  809, 6809, 1168, 3780, 2689, 4680, 4638,  119,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2207, 2111,  833, 2533, 2207, 5499,  706, 3698, 3221,  784,  720,\n",
      "        1333, 1728, 8043, 6821, 1126, 1921, 5439, 3352, 6432, 2769, 5125, 4868,\n",
      "         679, 1962, 8024, 2512, 1510,  749,  677, 4408, 4307, 2578, 8024, 1071,\n",
      "        2141, 2769,  738,  679, 2682, 4638, 8024, 3241,  677, 2600, 3221, 4717,\n",
      "         679, 4708, 8024, 3300, 3198,  952, 2697, 6230, 2552, 2707, 2707, 8024,\n",
      "         679, 1922, 5653, 3302, 8024, 1963, 3362,  698, 7028,  749, 2523, 2857,\n",
      "        2552, 2512, 1510, 6716,  860, 1469, 2339,  868, 8024, 6435, 7309, 2207,\n",
      "        2111,  833, 2533, 2207, 5499,  706, 3698, 3221,  784,  720, 1333, 1728,\n",
      "        1036, 4997, 4548, 3698, 1377, 7023, 4500, 1296, 5283, 4638,  704, 5790,\n",
      "        4548, 3698, 6150, 4545, 5553, 4548, 6150, 3791, 3780, 4545, 1377, 3780,\n",
      "        4545, 1392, 4905, 5592, 5500, 3765, 4548, 3698, 1469, 5553, 4548,  119,\n",
      "         704, 5790, 4548, 3698, 6150, 5553, 4548, 6150, 4545, 3791,  117, 5543,\n",
      "        6813, 6862, 6629, 1168, 3946, 7345, 3141, 2170,  117, 4415, 3698, 4495,\n",
      "        5491,  722, 1216, 3126,  117,  914, 6822, 6117, 3890, 2542, 4384,  117,\n",
      "        3121, 1587, 2229, 6956, 5491, 5489, 8020, 5025, 5606, 8021, 3173, 7357,\n",
      "         807, 6468,  117,  914, 6822, 4548, 4384, 1366, 1453, 1741, 5491, 5489,\n",
      "         680, 5025, 5606, 1872, 7270,  117, 1217, 6862, 1079, 4384, 1366, 4638,\n",
      "        7308, 1394,  117,  809, 6809, 1168, 3780, 2689, 4680, 4638,  119,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103, 1036, 4997,  704, 5455, 4142, 3837, 5555, 6421, 2582,  720, 3416,\n",
      "        1278, 3780, 8043, 2769, 2157, 4638, 2111, 2094, 3221, 4511, 2140, 2140,\n",
      "        8024,  130, 2259, 8024, 6772, 6818, 1126, 1921, 8024, 2111, 2094, 1440,\n",
      "        6401, 2769, 5455, 3321, 3300, 4157, 4563, 8024, 1369, 1912, 8024, 3300,\n",
      "        7942, 5682, 4638, 5455, 2241, 3837, 1139, 8024, 1369, 1912, 8024, 7608,\n",
      "        3617,  738,  679, 1962, 8024, 1624, 2094,  738,  679, 5653, 3302, 8024,\n",
      "        6435, 7309, 8038, 1036, 4997,  704, 5455, 4142, 3837, 5555, 6421, 2582,\n",
      "         720, 3416, 1278, 3780,  511, 3780, 4545, 4638, 6413, 6206, 3418, 2945,\n",
      "        2111, 2094, 4568, 4307, 5314,  750, 2190, 4568, 3867, 4142, 5790, 8024,\n",
      "        1377,  809, 2229, 6956, 5790, 4289, 3780, 4545, 8024, 1377,  809, 6848,\n",
      "        2885, 3867, 4142, 5102, 1798, 4638, 4017, 5455, 1177, 8024, 1963, 3362,\n",
      "        5455, 4578, 4638, 2658, 1105, 3683, 6772,  698, 7028, 4638, 6413, 1377,\n",
      "        6844, 2496, 5314,  750,  671,  763, 7252, 4578, 5790, 8024, 2111, 2094,\n",
      "        6206, 3221,  845, 3300, 1355, 4173, 2157, 7270, 1377,  809, 5314, 2111,\n",
      "        2094, 5314,  750,  671,  763, 3300, 6842, 4173, 4638, 5790, 4289, 2772,\n",
      "        5442, 7716,  677, 6843, 2111, 2094, 1343, 1278, 7368, 8024, 1963, 3362,\n",
      "         872, 4638, 2111, 2094, 1139, 4385,  749, 5455, 5606, 4959, 2096, 4638,\n",
      "        7309, 7579, 8024, 7444, 6206, 1350, 3198, 4638, 1343, 1278, 7368, 6822,\n",
      "        6121, 2797, 3318, 1278, 3780, 8024, 2398, 3198, 3800, 2692, 7650, 7608,\n",
      "        3926, 3909, 8024, 3780, 4545, 3309, 7313,  809, 3837, 7608,  711,  712,\n",
      "         511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 1036, 4997,  704, 5455, 4142, 3837, 5555, 6421, 2582,  720, 3416,\n",
      "        1278, 3780, 8043, 2769, 2157, 4638, 2111, 2094, 3221, 4511, 2140, 2140,\n",
      "        8024,  130, 2259, 8024, 6772, 6818, 1126, 1921, 8024, 2111, 2094, 1440,\n",
      "        6401, 2769, 5455, 3321, 3300, 4157, 4563, 8024, 1369, 1912, 8024, 3300,\n",
      "        7942, 5682, 4638, 5455, 2241, 3837, 1139, 8024, 1369, 1912, 8024, 7608,\n",
      "        3617,  738,  679, 1962, 8024, 1624, 2094,  738,  679, 5653, 3302, 8024,\n",
      "        6435, 7309, 8038, 1036, 4997,  704, 5455, 4142, 3837, 5555, 6421, 2582,\n",
      "         720, 3416, 1278, 3780,  511, 3780, 4545, 4638, 6413, 6206, 3418, 2945,\n",
      "        2111, 2094, 4568, 4307, 5314,  750, 2190, 4568, 3867, 4142, 5790, 8024,\n",
      "        1377,  809, 2229, 6956, 5790, 4289, 3780, 4545, 8024, 1377,  809, 6848,\n",
      "        2885, 3867, 4142, 5102, 1798, 4638, 4017, 5455, 1177, 8024, 1963, 3362,\n",
      "        5455, 4578, 4638, 2658, 1105, 3683, 6772,  698, 7028, 4638, 6413, 1377,\n",
      "        6844, 2496, 5314,  750,  671,  763, 7252, 4578, 5790, 8024, 2111, 2094,\n",
      "        6206, 3221,  845, 3300, 1355, 4173, 2157, 7270, 1377,  809, 5314, 2111,\n",
      "        2094, 5314,  750,  671,  763, 3300, 6842, 4173, 4638, 5790, 4289, 2772,\n",
      "        5442, 7716,  677, 6843, 2111, 2094, 1343, 1278, 7368, 8024, 1963, 3362,\n",
      "         872, 4638, 2111, 2094, 1139, 4385,  749, 5455, 5606, 4959, 2096, 4638,\n",
      "        7309, 7579, 8024, 7444, 6206, 1350, 3198, 4638, 1343, 1278, 7368, 6822,\n",
      "        6121, 2797, 3318, 1278, 3780, 8024, 2398, 3198, 3800, 2692, 7650, 7608,\n",
      "        3926, 3909, 8024, 3780, 4545, 3309, 7313,  809, 3837, 7608,  711,  712,\n",
      "         511,  101], device='cuda:0')\n",
      "private_positions =  tensor([25], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 25/9000 [00:02<10:56, 13.68it/s, loss=3.5631337]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 1159, 4495, 1036, 1391, 1959, 5106,  677, 4125, 1408, 8043, 2769,\n",
      "        2157, 2140, 2140, 2247,  754, 3193,  772, 2111, 2094, 8024,  671, 2458,\n",
      "        1993, 2769, 2218, 2523, 2857, 2552, 2111, 2094, 2658, 1105, 8024, 3297,\n",
      "        6818, 2111, 2094, 1139, 4385,  749, 6821,  763,  671, 5143, 1154, 4638,\n",
      "        2658, 1105, 8024, 2769,  738, 2523, 2857, 2552, 8024, 2154, 2586, 2111,\n",
      "        2094, 1359, 2533, 3291,  698, 7028, 8024, 6435, 7309, 1159, 4495, 1036,\n",
      "        1391, 1959, 5106,  677, 4125, 1408, 1959, 5106, 1585, 1075, 4638, 2140,\n",
      "        2140, 6206, 1762,  697, 3613, 1585, 1959,  722, 7313, 1585, 4157, 3946,\n",
      "        2458, 3717, 8024, 3924, 1217, 4157, 1959,  845, 5868, 5843, 5131, 8024,\n",
      "        3921, 1394, 1585, 1075, 4638, 2140, 2140, 8024, 1968, 1968,  738, 6206,\n",
      "        6912, 1048, 1391,  763, 3211,  677, 4125, 4638, 7608, 4289,  511, 8024,\n",
      "        1044, 1921, 2595, 5513, 4655, 6783, 2228, 5052, 6825, 2970, 1905, 3453,\n",
      "        7349, 2792, 5636, 5513, 4916, 3717, 3221, 2207, 1036, 3789, 2228, 1912,\n",
      "        4906, 2382, 6224, 4638, 3789, 2228, 5143, 5320, 4535, 2501,  117, 4507,\n",
      "         754, 6818, 2399, 3341, 5522, 1036,  144, 6631, 3466, 3389, 4638, 3249,\n",
      "        1350,  117, 5522, 1036, 5513, 4916, 3717, 6402, 3171, 4372, 1920, 1920,\n",
      "        1872, 1217,  511, 2456, 6379, 1168, 1920, 1278, 7368, 6822, 6121, 2797,\n",
      "        3318, 3780, 4545, 8024, 7028, 2428, 5513, 4916, 3717, 1963,  679, 1350,\n",
      "        3198, 2797, 3318, 3780, 4545,  117, 1377, 2193, 5636, 1353, 1908, 2228,\n",
      "        6662, 2697, 3381, 1469, 5513, 1216, 5543, 6139, 4998,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103, 1159, 4495, 1036, 1391, 1959, 5106,  677, 4125, 1408, 8043, 2769,\n",
      "        2157, 2140, 2140, 2247,  754, 3193,  772, 2111, 2094, 8024,  671, 2458,\n",
      "        1993, 2769, 2218, 2523, 2857, 2552, 2111, 2094, 2658, 1105, 8024, 3297,\n",
      "        6818, 2111, 2094, 1139, 4385,  749, 6821,  763,  671, 5143, 1154, 4638,\n",
      "        2658, 1105, 8024, 2769,  738, 2523, 2857, 2552, 8024, 2154, 2586, 2111,\n",
      "        2094, 1359, 2533, 3291,  698, 7028, 8024, 6435, 7309, 1159, 4495, 1036,\n",
      "        1391, 1959, 5106,  677, 4125, 1408, 1959, 5106, 1585, 1075, 4638, 2140,\n",
      "        2140, 6206, 1762,  697, 3613, 1585, 1959,  722, 7313, 1585, 4157, 3946,\n",
      "        2458, 3717, 8024, 3924, 1217, 4157, 1959,  845, 5868, 5843, 5131, 8024,\n",
      "        3921, 1394, 1585, 1075, 4638, 2140, 2140, 8024, 1968, 1968,  738, 6206,\n",
      "        6912, 1048, 1391,  763, 3211,  677, 4125, 4638, 7608, 4289,  511, 8024,\n",
      "        1044, 1921, 2595, 5513, 4655, 6783, 2228, 5052, 6825, 2970, 1905, 3453,\n",
      "        7349, 2792, 5636, 5513, 4916, 3717, 3221, 2207, 1036, 3789, 2228, 1912,\n",
      "        4906, 2382, 6224, 4638, 3789, 2228, 5143, 5320, 4535, 2501,  117, 4507,\n",
      "         754, 6818, 2399, 3341, 5522, 1036,  144, 6631, 3466, 3389, 4638, 3249,\n",
      "        1350,  117, 5522, 1036, 5513, 4916, 3717, 6402, 3171, 4372, 1920, 1920,\n",
      "        1872, 1217,  511, 2456, 6379, 1168, 1920, 1278, 7368, 6822, 6121, 2797,\n",
      "        3318, 3780, 4545, 8024, 7028, 2428, 5513, 4916, 3717, 1963,  679, 1350,\n",
      "        3198, 2797, 3318, 3780, 4545,  117, 1377, 2193, 5636, 1353, 1908, 2228,\n",
      "        6662, 2697, 3381, 1469, 5513, 1216, 5543, 6139, 4998,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103, 2207, 1036, 5517, 5592, 6956, 2853, 1220, 2582,  720, 1726,  752,\n",
      "        8043, 1036, 2094, 8024,  126, 2259, 8024, 3219, 3189, 1355, 4385, 5517,\n",
      "        5592, 6956,  679, 5632,  712, 4638, 2853, 1220, 8024,  679, 3209, 1333,\n",
      "        1728, 8013,  679, 2512, 1510, 1391, 1469, 4717, 8024, 4381, 8024, 4692,\n",
      "        3416, 2094,  679, 4563, 8013,  852, 3221, 6435, 1440,  741, 2769, 2582,\n",
      "         720, 1726,  752, 8043, 1728,  711, 2600, 3221, 2853, 1220, 8024, 3300,\n",
      "        4157, 6496, 2802, 1629,  849, 4638, 2853, 1220, 8024,  852, 2400,  679,\n",
      "        2802, 1629, 8013, 3307,  741, 2612, 1908, 6468, 6468, 8013, 8013, 2140,\n",
      "        1968,  872, 1962, 8024, 1008, 2111, 2094, 6821, 4905, 2658, 1105, 8024,\n",
      "        3300, 1377, 5543, 3221, 5517, 5499, 4570, 2908, 4638, 1333, 1728, 2193,\n",
      "        5636, 4638, 8024,  852, 3221, 1963, 3362, 2140, 2140, 3766, 3300, 3209,\n",
      "        3227, 4638, 5592, 4578, 4568, 4307, 4638, 6413, 8024, 1139, 4385, 5592,\n",
      "        6956, 5491, 5489, 2853, 1220, 6772, 7574, 5246, 4638, 6413,  511, 3297,\n",
      "        1962, 3221, 5543, 1916, 2372, 2111, 2094, 1343, 1278, 7368, 4692,  671,\n",
      "         678, 2961, 7370, 2853, 1220, 4568, 4638, 1377, 5543, 2595, 4685, 2190,\n",
      "        1920,  511, 6821,  702,  671, 5663, 7444, 6206, 2372, 2111, 2094, 1343,\n",
      "        1036, 4997, 1278, 7368, 4638, 4868, 5307, 1079, 4906, 4692,  671,  678,\n",
      "        8024, 7444, 6206,  976,  671,  678, 7565, 5554, 4828, 1066, 2920,  809,\n",
      "        1350, 5554, 4510, 1745, 4638, 3466, 3844, 8024, 2961, 7370,  671,  678,\n",
      "        1071,  800, 7565, 5554, 5143, 5320, 4638, 4565, 4567, 8024, 6863, 2768,\n",
      "         749, 2111, 2094, 6821, 3416, 4638, 5592, 6956, 2853, 1220, 1963, 3362,\n",
      "        3766, 3300,  784,  720, 6821, 3416, 4638, 7309, 7579, 4638, 6413, 8024,\n",
      "        2418, 6421, 2218, 3221, 5440, 5991, 2853, 1220, 4568, 4638,  511,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2207, 1036, 5517, 5592, 6956, 2853, 1220, 2582,  720, 1726,  752,\n",
      "        8043, 1036, 2094, 8024,  126, 2259, 8024, 3219, 3189, 1355, 4385, 5517,\n",
      "        5592, 6956,  679, 5632,  712, 4638, 2853, 1220, 8024,  679, 3209, 1333,\n",
      "        1728, 8013,  679, 2512, 1510, 1391, 1469, 4717, 8024, 4381, 8024, 4692,\n",
      "        3416, 2094,  679, 4563, 8013,  852, 3221, 6435, 1440,  741, 2769, 2582,\n",
      "         720, 1726,  752, 8043, 1728,  711, 2600, 3221, 2853, 1220, 8024, 3300,\n",
      "        4157, 6496, 2802, 1629,  849, 4638, 2853, 1220, 8024,  852, 2400,  679,\n",
      "        2802, 1629, 8013, 3307,  741, 2612, 1908, 6468, 6468, 8013, 8013, 2140,\n",
      "        1968,  872, 1962, 8024, 1008, 2111, 2094, 6821, 4905, 2658, 1105, 8024,\n",
      "        3300, 1377, 5543, 3221, 5517, 5499, 4570, 2908, 4638, 1333, 1728, 2193,\n",
      "        5636, 4638, 8024,  852, 3221, 1963, 3362, 2140, 2140, 3766, 3300, 3209,\n",
      "        3227, 4638, 5592, 4578, 4568, 4307, 4638, 6413, 8024, 1139, 4385, 5592,\n",
      "        6956, 5491, 5489, 2853, 1220, 6772, 7574, 5246, 4638, 6413,  511, 3297,\n",
      "        1962, 3221, 5543, 1916, 2372, 2111, 2094, 1343, 1278, 7368, 4692,  671,\n",
      "         678, 2961, 7370, 2853, 1220, 4568, 4638, 1377, 5543, 2595, 4685, 2190,\n",
      "        1920,  511, 6821,  702,  671, 5663, 7444, 6206, 2372, 2111, 2094, 1343,\n",
      "        1036, 4997, 1278, 7368, 4638, 4868, 5307, 1079, 4906, 4692,  671,  678,\n",
      "        8024, 7444, 6206,  976,  671,  678, 7565, 5554, 4828, 1066, 2920,  809,\n",
      "        1350, 5554, 4510, 1745, 4638, 3466, 3844, 8024, 2961, 7370,  671,  678,\n",
      "        1071,  800, 7565, 5554, 5143, 5320, 4638, 4565, 4567, 8024, 6863, 2768,\n",
      "         749, 2111, 2094, 6821, 3416, 4638, 5592, 6956, 2853, 1220, 1963, 3362,\n",
      "        3766, 3300,  784,  720, 6821, 3416, 4638, 7309, 7579, 4638, 6413, 8024,\n",
      "        2418, 6421, 2218, 3221, 5440, 5991, 2853, 1220, 4568, 4638,  511,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([16], device='cuda:0')\n",
      "input_ids =  tensor([ 103, 7481, 4611, 1673, 2349, 3639, 1403, 1525,  671,  904, 8043, 2769,\n",
      "        1420, 1968, 1968, 5643, 5643, 1962, 1008, 2533,  749, 7481, 4385, 1762,\n",
      "        1673, 2349, 1469, 4706, 4714, 1086, 3613, 1139, 4385,  749,  678, 2769,\n",
      "        4385, 1762, 2923, 1962, 1936,  738,  679, 4761, 3236, 4955, 4994, 3221,\n",
      "         784,  720, 1333, 1728, 2533, 2533,  749, 7481, 4611, 1673, 2349,  833,\n",
      "        3639, 1403, 1525,  671,  904, 8043, 7481, 4611, 1673, 4638,  678, 1795,\n",
      "        3175, 1403, 3766,  698, 3419, 4638, 1743, 7444, 6206, 3300, 3418, 2945,\n",
      "         702,  782, 4638, 6716,  860, 2658, 1105, 1469, 6571, 6117, 4567, 1728,\n",
      "        5162, 3341, 6848, 2885, 4638,  511, 2471, 1355, 7481, 4611, 4638, 1333,\n",
      "        1728, 3300, 2523, 1914, 4905,  679, 7481, 4611, 4638, 4568, 4307,  671,\n",
      "        5663, 3221, 1673, 6235,  678, 4706, 4714, 4709,  679, 2458, 2772, 2482,\n",
      "        3837, 1366,  700, 1927, 1456,  700, 1927,  671,  904, 2697, 2135, 5023,\n",
      "         511, 7481, 6956, 4868, 5307, 6901, 1168, 4567, 3681, 2697, 3381,  809,\n",
      "        1400,  833, 2471, 3341, 7481, 6956, 4868, 5307, 2471, 1355, 7481, 4611,\n",
      "         511, 5455, 3321, 6956,  855, 4638, 4142, 4568,  833,  837, 3381, 1168,\n",
      "        7481, 6956, 4868, 5307, 2471, 3341, 7481, 4611,  511,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103, 7481, 4611, 1673, 2349, 3639, 1403, 1525,  671,  904, 8043, 2769,\n",
      "        1420, 1968, 1968, 5643, 5643, 1962, 1008, 2533,  749, 7481, 4385, 1762,\n",
      "        1673, 2349, 1469, 4706, 4714, 1086, 3613, 1139, 4385,  749,  678, 2769,\n",
      "        4385, 1762, 2923, 1962, 1936,  738,  679, 4761, 3236, 4955, 4994, 3221,\n",
      "         784,  720, 1333, 1728, 2533, 2533,  749, 7481, 4611, 1673, 2349,  833,\n",
      "        3639, 1403, 1525,  671,  904, 8043, 7481, 4611, 1673, 4638,  678, 1795,\n",
      "        3175, 1403, 3766,  698, 3419, 4638, 1743, 7444, 6206, 3300, 3418, 2945,\n",
      "         702,  782, 4638, 6716,  860, 2658, 1105, 1469, 6571, 6117, 4567, 1728,\n",
      "        5162, 3341, 6848, 2885, 4638,  511, 2471, 1355, 7481, 4611, 4638, 1333,\n",
      "        1728, 3300, 2523, 1914, 4905,  679, 7481, 4611, 4638, 4568, 4307,  671,\n",
      "        5663, 3221, 1673, 6235,  678, 4706, 4714, 4709,  679, 2458, 2772, 2482,\n",
      "        3837, 1366,  700, 1927, 1456,  700, 1927,  671,  904, 2697, 2135, 5023,\n",
      "         511, 7481, 6956, 4868, 5307, 6901, 1168, 4567, 3681, 2697, 3381,  809,\n",
      "        1400,  833, 2471, 3341, 7481, 6956, 4868, 5307, 2471, 1355, 7481, 4611,\n",
      "         511, 5455, 3321, 6956,  855, 4638, 4142, 4568,  833,  837, 3381, 1168,\n",
      "        7481, 6956, 4868, 5307, 2471, 3341, 7481, 4611,  511,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 29/9000 [00:02<10:16, 14.56it/s, loss=3.3587580]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 3466, 3389, 2544, 7030, 1039, 5162, 3633, 2382, 2869, 3688, 4568,\n",
      "        1178, 1045, 3300, 3766, 3300, 4500, 8043,  798, 5301, 3466, 3389, 2544,\n",
      "        7030, 1039, 5162, 3633, 2382, 8024, 2869, 3688, 4568, 1178, 1045, 3300,\n",
      "        4500, 1408, 8043, 2111, 2094,  736, 2259,  749, 8024, 2869, 3688, 4568,\n",
      "        3300,  671,  702, 3299, 8024, 3300,  784,  720, 1962, 4638, 2456, 6379,\n",
      "        1408, 8043, 2769, 2682,  791, 1921, 2372,  800, 1343, 3092, 7490, 8024,\n",
      "        1178, 2398, 1928, 4197, 1400,  743,  702, 2384, 2094, 2869, 3688, 4568,\n",
      "        1377, 5543,  833, 6656, 2111, 2094, 4193, 5991, 6656, 5125, 4868, 6814,\n",
      "        2428, 5165, 2476, 3300, 1068, 5143, 8013, 6820, 3221, 2372, 2111, 2094,\n",
      "        1343,  976,  702, 2552, 4415, 1486, 6418, 8024, 5543, 6375, 2111, 2094,\n",
      "        3138, 2458, 2552, 2796, 8013, 1963, 3362, 2111, 2094, 4568, 4307,  679,\n",
      "         698, 7028, 8024, 1377,  809,  985, 6407, 4708, 1914, 1068, 2552, 6225,\n",
      "        3800, 2111, 2094, 8024, 5447, 2552, 5463, 1420, 2111, 2094, 4638, 2552,\n",
      "        1898, 8024,  679, 6206, 1600, 3166, 1961, 8024,  738, 1377,  809, 4500,\n",
      "        4495, 2002, 3092, 2229, 6956, 8024, 1914, 1391,  763, 7946, 5698, 7937,\n",
      "         722, 5102, 4638,  691, 6205, 8013,  809,  677, 3221, 2190,  100,  798,\n",
      "        5301, 3466, 3389, 2544, 7030, 1039, 5162, 3633, 2382, 8024, 2869, 3688,\n",
      "        4568, 1178, 1045, 3300, 4500, 1408,  100, 6821,  702, 7309, 7579, 4638,\n",
      "        2456, 6379, 8024, 3309, 3307, 2190, 2644, 3300, 2376, 1221, 8024, 4867,\n",
      "        2644,  978, 2434, 8013,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 3466, 3389, 2544, 7030, 1039, 5162, 3633, 2382, 2869, 3688, 4568,\n",
      "        1178, 1045, 3300, 3766, 3300, 4500, 8043,  798, 5301, 3466, 3389, 2544,\n",
      "        7030, 1039, 5162, 3633, 2382, 8024, 2869, 3688, 4568, 1178, 1045, 3300,\n",
      "        4500, 1408, 8043, 2111, 2094,  736, 2259,  749, 8024, 2869, 3688, 4568,\n",
      "        3300,  671,  702, 3299, 8024, 3300,  784,  720, 1962, 4638, 2456, 6379,\n",
      "        1408, 8043, 2769, 2682,  791, 1921, 2372,  800, 1343, 3092, 7490, 8024,\n",
      "        1178, 2398, 1928, 4197, 1400,  743,  702, 2384, 2094, 2869, 3688, 4568,\n",
      "        1377, 5543,  833, 6656, 2111, 2094, 4193, 5991, 6656, 5125, 4868, 6814,\n",
      "        2428, 5165, 2476, 3300, 1068, 5143, 8013, 6820, 3221, 2372, 2111, 2094,\n",
      "        1343,  976,  702, 2552, 4415, 1486, 6418, 8024, 5543, 6375, 2111, 2094,\n",
      "        3138, 2458, 2552, 2796, 8013, 1963, 3362, 2111, 2094, 4568, 4307,  679,\n",
      "         698, 7028, 8024, 1377,  809,  985, 6407, 4708, 1914, 1068, 2552, 6225,\n",
      "        3800, 2111, 2094, 8024, 5447, 2552, 5463, 1420, 2111, 2094, 4638, 2552,\n",
      "        1898, 8024,  679, 6206, 1600, 3166, 1961, 8024,  738, 1377,  809, 4500,\n",
      "        4495, 2002, 3092, 2229, 6956, 8024, 1914, 1391,  763, 7946, 5698, 7937,\n",
      "         722, 5102, 4638,  691, 6205, 8013,  809,  677, 3221, 2190,  100,  798,\n",
      "        5301, 3466, 3389, 2544, 7030, 1039, 5162, 3633, 2382, 8024, 2869, 3688,\n",
      "        4568, 1178, 1045, 3300, 4500, 1408,  100, 6821,  702, 7309, 7579, 4638,\n",
      "        2456, 6379, 8024, 3309, 3307, 2190, 2644, 3300, 2376, 1221, 8024, 4867,\n",
      "        2644,  978, 2434, 8013,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([  103,  5498,  1216,  3466,  3389,  4822,  2595,  4840,  7000,  6998,\n",
      "          122,  2582,   720,  3780,  4545,  8043,   129,  2259,  1036,  4997,\n",
      "         5498,  4567,  1063,  7555,  3466,  3389,  1059,  7346,  8024,  5498,\n",
      "         1216,  3466,  3389,  4822,  2595,  4840,  7000,  6998, 10134,  3633,\n",
      "         2382,  3490,  3221,  8164,   118,  8269,  3221,  2582,   720,  1726,\n",
      "          752,  2900,  2193,  2692,  6224,  8038,  6821,   702,  5314,  2111,\n",
      "         2094,  6133,  6133,  7159,  2218,  1377,   809,   749,  8024,  1059,\n",
      "         7346,  8024,  6821,   702,  7444,  6206,  2802,  4554,  5728,  8024,\n",
      "         3766,  2834,   860,  2159,  3211,  6158,  2697,  3381,  4638,   511,\n",
      "         8024,  6863,  2768,  2207,  1036,  5498,  4567,  4638,  1728,  5162,\n",
      "         6772,  1914,  8024,  1963,  3362,  2111,  2094,  6158,  1316,  4802,\n",
      "         6402,   711,  2207,  1036,  5498,  4567,   749,  8024,  2157,  7270,\n",
      "         7444,  6206,  6981,  1394,  1278,  4495,  4989,  1315,  3780,  4545,\n",
      "         8024,  6981,  1394,  5499,  5517,  1121,  1327,  8024,  2400,  1075,\n",
      "         2768,  5679,  1962,  4638,  1310,  4495,   739,  2679,   511,  2111,\n",
      "         2094,  7444,  6206,  1394,  4415,  7650,  7608,  8024,  6912,  1048,\n",
      "         1173,  4080,  2170,  1107,  7608,  4289,   511,   101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([  103,  5498,  1216,  3466,  3389,  4822,  2595,  4840,  7000,  6998,\n",
      "          122,  2582,   720,  3780,  4545,  8043,   129,  2259,  1036,  4997,\n",
      "         5498,  4567,  1063,  7555,  3466,  3389,  1059,  7346,  8024,  5498,\n",
      "         1216,  3466,  3389,  4822,  2595,  4840,  7000,  6998, 10134,  3633,\n",
      "         2382,  3490,  3221,  8164,   118,  8269,  3221,  2582,   720,  1726,\n",
      "          752,  2900,  2193,  2692,  6224,  8038,  6821,   702,  5314,  2111,\n",
      "         2094,  6133,  6133,  7159,  2218,  1377,   809,   749,  8024,  1059,\n",
      "         7346,  8024,  6821,   702,  7444,  6206,  2802,  4554,  5728,  8024,\n",
      "         3766,  2834,   860,  2159,  3211,  6158,  2697,  3381,  4638,   511,\n",
      "         8024,  6863,  2768,  2207,  1036,  5498,  4567,  4638,  1728,  5162,\n",
      "         6772,  1914,  8024,  1963,  3362,  2111,  2094,  6158,  1316,  4802,\n",
      "         6402,   711,  2207,  1036,  5498,  4567,   749,  8024,  2157,  7270,\n",
      "         7444,  6206,  6981,  1394,  1278,  4495,  4989,  1315,  3780,  4545,\n",
      "         8024,  6981,  1394,  5499,  5517,  1121,  1327,  8024,  2400,  1075,\n",
      "         2768,  5679,  1962,  4638,  1310,  4495,   739,  2679,   511,  2111,\n",
      "         2094,  7444,  6206,  1394,  4415,  7650,  7608,  8024,  6912,  1048,\n",
      "         1173,  4080,  2170,  1107,  7608,  4289,   511,   101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([10, 16, 38, 43, 45], device='cuda:0')\n",
      "input_ids =  tensor([ 103, 2207, 1036, 3300, 2853, 7599, 4568, 4307,  117, 1961, 1377,  809,\n",
      "        2802, 7344, 4554, 7151, 1408, 1961,  136, 2207, 1036, 3300, 2853, 7599,\n",
      "        4568, 4307,  117, 1961, 1377,  809, 2802, 7344, 4554, 7151, 1408, 1961,\n",
      "         136, 4385, 1762,  671, 2259,  749,  119, 1061,  702, 3299,  809, 1184,\n",
      "        4638, 4554, 5728, 6963, 2802,  749,  117, 1061,  702, 1288, 3299, 2853,\n",
      "        7599,  119, 5554, 4510, 1745, 5554, 9162, 6963, 3633, 2382,  119, 7159,\n",
      "        3633, 2382,  117,  852, 3221, 3300,  671, 4157,  856,  117, 1071,  800,\n",
      "        4638, 3633, 2382,  119,  872, 1962, 8024, 2456, 6379, 4916, 3353, 4638,\n",
      "        6133, 7159,  511, 1762, 1278, 4495, 4638, 2900, 2193,  678, 2418, 4500,\n",
      "        4685, 2418, 4638, 7159, 1177,  511, 3297, 1962, 1044,  679, 6206, 3800,\n",
      "        2198, 7344, 4554, 7151,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2207, 1036, 3300, 2853, 7599, 4568, 4307,  117, 1961, 1377,  809,\n",
      "        2802, 7344, 4554, 7151, 1408, 1961,  136, 2207, 1036, 3300, 2853, 7599,\n",
      "        4568, 4307,  117, 1961, 1377,  809, 2802, 7344, 4554, 7151, 1408, 1961,\n",
      "         136, 4385, 1762,  671, 2259,  749,  119, 1061,  702, 3299,  809, 1184,\n",
      "        4638, 4554, 5728, 6963, 2802,  749,  117, 1061,  702, 1288, 3299, 2853,\n",
      "        7599,  119, 5554, 4510, 1745, 5554, 9162, 6963, 3633, 2382,  119, 7159,\n",
      "        3633, 2382,  117,  852, 3221, 3300,  671, 4157,  856,  117, 1071,  800,\n",
      "        4638, 3633, 2382,  119,  872, 1962, 8024, 2456, 6379, 4916, 3353, 4638,\n",
      "        6133, 7159,  511, 1762, 1278, 4495, 4638, 2900, 2193,  678, 2418, 4500,\n",
      "        4685, 2418, 4638, 7159, 1177,  511, 3297, 1962, 1044,  679, 6206, 3800,\n",
      "        2198, 7344, 4554, 7151,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103, 2140, 2140, 2207, 3198,  908, 6206, 3864, 3209, 4770, 4649, 5502,\n",
      "         833, 1359, 1962, 3221, 1408, 8043, 1420,  782, 2157, 6432, 2140, 2140,\n",
      "        2207, 3198,  908, 6206, 5314, 1961, 3864, 3209, 4770, 4638,  679, 4197,\n",
      "         809, 1400, 4649, 5502,  833, 4563, 4638, 3221,  679, 3221, 4696, 4638,\n",
      "        1557, 6206,  679, 6206, 5314, 2140, 2140, 2175, 3209, 4770, 1557, 1278,\n",
      "        7368, 6432, 3221,  679, 5543, 4500, 2140, 2140, 4385, 1762, 3300, 5273,\n",
      "        2230, 5500, 4638, 4385, 6496, 4638, 8024, 6206,  679, 6206, 3864, 3209,\n",
      "        4770, 3301, 1351, 8024, 2140, 2140, 4385, 1762, 5273, 2230, 5500, 1377,\n",
      "        5543,  833, 3221, 1728,  711,  872,  812, 5314, 2140, 2140, 3819, 4638,\n",
      "        1922, 1249,  749,  511, 4385, 1762, 5273, 2230, 5500, 1377,  809, 3026,\n",
      "        4157, 7937, 3779, 8024, 1369, 1912, 2456, 6379,  872,  812,  679, 6206,\n",
      "        3680, 3613, 2140, 2140,  912,  912, 1400, 6963, 1170, 3819, 8024, 3297,\n",
      "        1400, 3221, 4500, 3946, 3717, 2199, 2230, 2230, 1103, 2397, 1112, 8024,\n",
      "        3680, 3613, 6963, 4500, 2357, 1170, 3819, 2159, 3211, 2199, 4649, 5502,\n",
      "        4638,  924, 2844, 2231, 1170, 3819, 2957,  511, 1369, 1912, 3209, 4770,\n",
      "        3297, 1962, 3221,  679, 6206, 4500,  511,  809,  677, 3221, 2190,  100,\n",
      "        1420,  782, 2157, 6432, 2140, 2140, 2207, 3198,  908, 6206, 5314, 1961,\n",
      "        3864, 3209, 4770, 4638,  679, 4197,  809, 1400, 4649, 5502,  679, 1962,\n",
      "         100, 6821,  702, 7309, 7579, 4638, 2456, 6379, 8024, 3309, 3307, 2190,\n",
      "        2644, 3300, 2376, 1221, 8024, 4867, 2644,  978, 2434, 8013,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2140, 2140, 2207, 3198,  908, 6206, 3864, 3209, 4770, 4649, 5502,\n",
      "         833, 1359, 1962, 3221, 1408, 8043, 1420,  782, 2157, 6432, 2140, 2140,\n",
      "        2207, 3198,  908, 6206, 5314, 1961, 3864, 3209, 4770, 4638,  679, 4197,\n",
      "         809, 1400, 4649, 5502,  833, 4563, 4638, 3221,  679, 3221, 4696, 4638,\n",
      "        1557, 6206,  679, 6206, 5314, 2140, 2140, 2175, 3209, 4770, 1557, 1278,\n",
      "        7368, 6432, 3221,  679, 5543, 4500, 2140, 2140, 4385, 1762, 3300, 5273,\n",
      "        2230, 5500, 4638, 4385, 6496, 4638, 8024, 6206,  679, 6206, 3864, 3209,\n",
      "        4770, 3301, 1351, 8024, 2140, 2140, 4385, 1762, 5273, 2230, 5500, 1377,\n",
      "        5543,  833, 3221, 1728,  711,  872,  812, 5314, 2140, 2140, 3819, 4638,\n",
      "        1922, 1249,  749,  511, 4385, 1762, 5273, 2230, 5500, 1377,  809, 3026,\n",
      "        4157, 7937, 3779, 8024, 1369, 1912, 2456, 6379,  872,  812,  679, 6206,\n",
      "        3680, 3613, 2140, 2140,  912,  912, 1400, 6963, 1170, 3819, 8024, 3297,\n",
      "        1400, 3221, 4500, 3946, 3717, 2199, 2230, 2230, 1103, 2397, 1112, 8024,\n",
      "        3680, 3613, 6963, 4500, 2357, 1170, 3819, 2159, 3211, 2199, 4649, 5502,\n",
      "        4638,  924, 2844, 2231, 1170, 3819, 2957,  511, 1369, 1912, 3209, 4770,\n",
      "        3297, 1962, 3221,  679, 6206, 4500,  511,  809,  677, 3221, 2190,  100,\n",
      "        1420,  782, 2157, 6432, 2140, 2140, 2207, 3198,  908, 6206, 5314, 1961,\n",
      "        3864, 3209, 4770, 4638,  679, 4197,  809, 1400, 4649, 5502,  679, 1962,\n",
      "         100, 6821,  702, 7309, 7579, 4638, 2456, 6379, 8024, 3309, 3307, 2190,\n",
      "        2644, 3300, 2376, 1221, 8024, 4867, 2644,  978, 2434, 8013,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 33/9000 [00:02<09:39, 15.47it/s, loss=2.6727870]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 1063, 2259, 2207, 2111, 3801, 4157,  679, 6858, 2582,  720, 3780,\n",
      "        4545, 8043, 1139, 4495, 2218, 3300, 3837, 3801,  872, 1962,  117, 2405,\n",
      "        1036, 3801, 5593,  679, 6858, 3211, 2471, 6629, 3837, 3801, 5023, 4568,\n",
      "        4307,  119, 1377,  809, 1044, 7023, 1357,  924, 2127, 4545, 3791, 8024,\n",
      "        2229, 6956, 4017, 2834, 4495, 5162, 4017, 4706, 3890, 8024, 1968, 1968,\n",
      "        1377,  809, 1762, 2140, 2140, 4638, 1079, 4706, 6235, 1905,  976, 2902,\n",
      "        3040, 8024, 4500, 2797, 2900, 5592, 2518,  678, 2902, 8024, 3123, 2458,\n",
      "        8024, 1086, 2902, 8024, 6825, 5330, 1282, 3613, 8024, 4197, 1400, 8024,\n",
      "         794, 1079, 4706, 6235, 2518, 7965, 2629, 8024, 4507,  677, 2518,  678,\n",
      "        2902, 3040, 8024,  738, 3221, 1282, 3613, 6821,  702, 3126, 3362, 6820,\n",
      "         679, 7231,  511, 8024, 1728, 2193, 5636, 2207, 1036, 3801, 6887, 1843,\n",
      "        1853, 4638, 1728, 5162, 1914, 4905, 1914, 3416, 8024, 3780, 4545, 1184,\n",
      "        2553, 7557,  749, 6237, 1071, 4567, 1728, 8024, 2141, 3177, 2190, 4568,\n",
      "        3780, 4545, 1333, 1156,  511, 5445,  684, 4495, 3833,  704, 4638, 2844,\n",
      "        4415, 2974, 3177, 2553,  679, 1377, 2208,  511, 2456, 6379, 2398, 2382,\n",
      "        1914, 1600, 3717, 4638, 8024, 1391, 2168, 1419, 5335, 4495, 5162, 4638,\n",
      "        5922, 5831, 1469, 3717, 3362, 4638,  511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 1063, 2259, 2207, 2111, 3801, 4157,  679, 6858, 2582,  720, 3780,\n",
      "        4545, 8043, 1139, 4495, 2218, 3300, 3837, 3801,  872, 1962,  117, 2405,\n",
      "        1036, 3801, 5593,  679, 6858, 3211, 2471, 6629, 3837, 3801, 5023, 4568,\n",
      "        4307,  119, 1377,  809, 1044, 7023, 1357,  924, 2127, 4545, 3791, 8024,\n",
      "        2229, 6956, 4017, 2834, 4495, 5162, 4017, 4706, 3890, 8024, 1968, 1968,\n",
      "        1377,  809, 1762, 2140, 2140, 4638, 1079, 4706, 6235, 1905,  976, 2902,\n",
      "        3040, 8024, 4500, 2797, 2900, 5592, 2518,  678, 2902, 8024, 3123, 2458,\n",
      "        8024, 1086, 2902, 8024, 6825, 5330, 1282, 3613, 8024, 4197, 1400, 8024,\n",
      "         794, 1079, 4706, 6235, 2518, 7965, 2629, 8024, 4507,  677, 2518,  678,\n",
      "        2902, 3040, 8024,  738, 3221, 1282, 3613, 6821,  702, 3126, 3362, 6820,\n",
      "         679, 7231,  511, 8024, 1728, 2193, 5636, 2207, 1036, 3801, 6887, 1843,\n",
      "        1853, 4638, 1728, 5162, 1914, 4905, 1914, 3416, 8024, 3780, 4545, 1184,\n",
      "        2553, 7557,  749, 6237, 1071, 4567, 1728, 8024, 2141, 3177, 2190, 4568,\n",
      "        3780, 4545, 1333, 1156,  511, 5445,  684, 4495, 3833,  704, 4638, 2844,\n",
      "        4415, 2974, 3177, 2553,  679, 1377, 2208,  511, 2456, 6379, 2398, 2382,\n",
      "        1914, 1600, 3717, 4638, 8024, 1391, 2168, 1419, 5335, 4495, 5162, 4638,\n",
      "        5922, 5831, 1469, 3717, 3362, 4638,  511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103, 2140, 2140,  123,  702, 3299, 1495, 1644,  125, 1921, 1963,  862,\n",
      "        1278, 3780, 8043, 2140, 2140,  123,  702, 3299, 8024, 1495,  125, 1921,\n",
      "        8024, 3219, 1921, 2697, 6230, 3300, 4588, 8024,  976,  749,  125, 3613,\n",
      "        7443, 1265, 8024, 1391,  749, 4767, 5934, 7578, 5108, 8024,  791, 1921,\n",
      "        1391,  749,  697, 3613, 4636, 1495, 2123, 7578, 5108, 8024, 2582,  720,\n",
      "        1215, 6820, 3221,  679, 1962,  779, 4263, 4638, 1486, 6418, 5442, 2644,\n",
      "        1962, 8024,  872, 2157, 2111, 2094, 1495, 3766, 1962, 8024,  712, 6206,\n",
      "        1728,  711, 2111, 2094, 1624, 2094, 3300, 4588, 2471, 3341, 4638, 1495,\n",
      "        8024,  679, 6206, 1922, 6814, 2569, 2552,  511, 6084, 1394,  872, 2157,\n",
      "        2111, 2094, 4680, 1184, 4638, 2658, 1105, 3341, 4692, 8024, 2456, 6379,\n",
      "        5314, 2111, 2094, 1391,  677, 6835, 5790, 4289, 4638, 1398, 3198,  757,\n",
      "        4685, 6981, 1394, 6387, 1914, 3867, 4142, 5790, 8024, 3683, 1963, 6432,\n",
      "        5790, 3867, 4142, 1366, 3302, 3890,  511,  809,  677, 3221, 2190,  100,\n",
      "        2140, 2140,  123,  702, 3299, 1495, 1644,  125, 1921, 1963,  862, 1278,\n",
      "        3780, 8043,  100, 6821,  702, 7309, 7579, 4638, 2456, 6379, 8024, 3309,\n",
      "        3307, 2190, 2644, 3300, 2376, 1221, 8024, 4867, 2644,  978, 2434, 8013,\n",
      "         101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2140, 2140,  123,  702, 3299, 1495, 1644,  125, 1921, 1963,  862,\n",
      "        1278, 3780, 8043, 2140, 2140,  123,  702, 3299, 8024, 1495,  125, 1921,\n",
      "        8024, 3219, 1921, 2697, 6230, 3300, 4588, 8024,  976,  749,  125, 3613,\n",
      "        7443, 1265, 8024, 1391,  749, 4767, 5934, 7578, 5108, 8024,  791, 1921,\n",
      "        1391,  749,  697, 3613, 4636, 1495, 2123, 7578, 5108, 8024, 2582,  720,\n",
      "        1215, 6820, 3221,  679, 1962,  779, 4263, 4638, 1486, 6418, 5442, 2644,\n",
      "        1962, 8024,  872, 2157, 2111, 2094, 1495, 3766, 1962, 8024,  712, 6206,\n",
      "        1728,  711, 2111, 2094, 1624, 2094, 3300, 4588, 2471, 3341, 4638, 1495,\n",
      "        8024,  679, 6206, 1922, 6814, 2569, 2552,  511, 6084, 1394,  872, 2157,\n",
      "        2111, 2094, 4680, 1184, 4638, 2658, 1105, 3341, 4692, 8024, 2456, 6379,\n",
      "        5314, 2111, 2094, 1391,  677, 6835, 5790, 4289, 4638, 1398, 3198,  757,\n",
      "        4685, 6981, 1394, 6387, 1914, 3867, 4142, 5790, 8024, 3683, 1963, 6432,\n",
      "        5790, 3867, 4142, 1366, 3302, 3890,  511,  809,  677, 3221, 2190,  100,\n",
      "        2140, 2140,  123,  702, 3299, 1495, 1644,  125, 1921, 1963,  862, 1278,\n",
      "        3780, 8043,  100, 6821,  702, 7309, 7579, 4638, 2456, 6379, 8024, 3309,\n",
      "        3307, 2190, 2644, 3300, 2376, 1221, 8024, 4867, 2644,  978, 2434, 8013,\n",
      "         101], device='cuda:0')\n",
      "private_positions =  tensor([  3,   8,  17,  22,  34, 158, 163], device='cuda:0')\n",
      "input_ids =  tensor([ 103, 5137, 4624, 3221, 1963,  862, 1355, 4495, 4638, 8043, 2207, 1036,\n",
      "        1912, 4906, 6963, 5543, 4692,  784,  720, 4567, 8024, 1525,  763, 4568,\n",
      "        4307, 2247,  754, 2207, 1036, 1079, 4906, 1450, 8024, 6435, 7309, 5137,\n",
      "        4624, 3221, 1963,  862, 1355, 4495, 4638, 2644, 1962, 8024, 4624, 2471,\n",
      "        6629, 4638, 4568, 4307, 1469, 1333, 1728, 2218, 3221, 3300, 4696, 5826,\n",
      "        2697, 3381, 2471, 6629, 4638, 8024, 1377,  809, 1912, 4500, 6809, 1046,\n",
      "        2123,  745, 5601, 8024, 4814, 6978, 3864, 2851, 3780, 4545, 8024, 4624,\n",
      "         698, 7028, 4638, 3198,  952, 6206, 1366, 3302,  823, 3289, 2434, 1539,\n",
      "        1366, 3302, 4638, 5790, 4289, 3780, 4545, 8024, 3780, 4545, 4624, 4567,\n",
      "         671, 2137, 6206, 3633, 6226, 4638,  886, 4500, 5790, 4289, 1469, 1780,\n",
      "        2898, 3780, 4545, 2798, 5543, 3780, 2689, 8024, 6912, 1048, 2970, 6239,\n",
      "        2372, 5826, 4638, 4289, 1501, 8024, 3187, 3126, 3198, 1343, 1278, 7368,\n",
      "        4649, 5502, 4906, 2218, 6402, 3780, 4545,  511, 8024, 2207, 2111, 2094,\n",
      "        6716,  860, 2850, 2834, 1213, 3683, 6772, 2345, 8024, 2792,  809, 2523,\n",
      "        2159, 3211, 1139, 4385, 5549, 5052, 4535, 2501, 4638, 8024, 2190,  754,\n",
      "        2157, 7270, 3301, 1351,  812, 3341, 6432, 8024,  679, 6206, 2552, 2593,\n",
      "        8024, 2418, 6421, 1350, 3198, 2372, 2111, 2094, 1168,  683, 4906, 1278,\n",
      "        7368, 2970, 1358, 3466, 3389, 1469, 3131, 3780, 8024, 5445,  684, 3800,\n",
      "        2692, 5314, 2111, 2094, 6822, 6121, 2382, 6226, 3466, 3389, 8024, 2400,\n",
      "         684, 1762, 1278, 4495, 4638, 2900, 2193,  678, 2190, 4568,  678, 5790,\n",
      "         511,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103, 5137, 4624, 3221, 1963,  862, 1355, 4495, 4638, 8043, 2207, 1036,\n",
      "        1912, 4906, 6963, 5543, 4692,  784,  720, 4567, 8024, 1525,  763, 4568,\n",
      "        4307, 2247,  754, 2207, 1036, 1079, 4906, 1450, 8024, 6435, 7309, 5137,\n",
      "        4624, 3221, 1963,  862, 1355, 4495, 4638, 2644, 1962, 8024, 4624, 2471,\n",
      "        6629, 4638, 4568, 4307, 1469, 1333, 1728, 2218, 3221, 3300, 4696, 5826,\n",
      "        2697, 3381, 2471, 6629, 4638, 8024, 1377,  809, 1912, 4500, 6809, 1046,\n",
      "        2123,  745, 5601, 8024, 4814, 6978, 3864, 2851, 3780, 4545, 8024, 4624,\n",
      "         698, 7028, 4638, 3198,  952, 6206, 1366, 3302,  823, 3289, 2434, 1539,\n",
      "        1366, 3302, 4638, 5790, 4289, 3780, 4545, 8024, 3780, 4545, 4624, 4567,\n",
      "         671, 2137, 6206, 3633, 6226, 4638,  886, 4500, 5790, 4289, 1469, 1780,\n",
      "        2898, 3780, 4545, 2798, 5543, 3780, 2689, 8024, 6912, 1048, 2970, 6239,\n",
      "        2372, 5826, 4638, 4289, 1501, 8024, 3187, 3126, 3198, 1343, 1278, 7368,\n",
      "        4649, 5502, 4906, 2218, 6402, 3780, 4545,  511, 8024, 2207, 2111, 2094,\n",
      "        6716,  860, 2850, 2834, 1213, 3683, 6772, 2345, 8024, 2792,  809, 2523,\n",
      "        2159, 3211, 1139, 4385, 5549, 5052, 4535, 2501, 4638, 8024, 2190,  754,\n",
      "        2157, 7270, 3301, 1351,  812, 3341, 6432, 8024,  679, 6206, 2552, 2593,\n",
      "        8024, 2418, 6421, 1350, 3198, 2372, 2111, 2094, 1168,  683, 4906, 1278,\n",
      "        7368, 2970, 1358, 3466, 3389, 1469, 3131, 3780, 8024, 5445,  684, 3800,\n",
      "        2692, 5314, 2111, 2094, 6822, 6121, 2382, 6226, 3466, 3389, 8024, 2400,\n",
      "         684, 1762, 1278, 4495, 4638, 2900, 2193,  678, 2190, 4568,  678, 5790,\n",
      "         511,  101], device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 35/9000 [00:02<09:47, 15.27it/s, loss=2.9400237]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103, 1278, 7368, 2582,  720, 3780, 3255, 1213,  856,  678, 6821,  702,\n",
      "        4567,  136, 2207, 2111, 2094, 2347, 5307,  758, 2259,  749, 8024, 2697,\n",
      "        6230, 3300,  763, 2460, 2382, 8024,  679, 1008, 3633, 2382, 4638, 2111,\n",
      "        2094, 8024, 2600, 3221, 4717, 6230, 8024, 1353, 2418, 6826, 7162, 8024,\n",
      "        3221,  679, 3221, 3255, 1213,  856,  678, 8043, 4385, 1762, 2682, 4761,\n",
      "        6887, 8024, 1278, 7368, 2582,  720, 3780, 3255, 1213,  856,  678, 6821,\n",
      "         702, 4567,  136, 3301, 1351, 8024, 3418, 2945,  872, 4638, 1360, 6835,\n",
      "        8024, 1036, 4997, 3255, 1213,  856,  678, 7444, 6206, 3300,  757, 4685,\n",
      "        6981, 1394, 6817, 4500, 1278, 2110,  510, 4852,  833,  510, 3136, 2193,\n",
      "        1469, 5466,  689, 4294, 6378, 5023, 2974, 3177, 8024, 2902, 2399, 7977,\n",
      "        1920, 2207, 1469, 3255, 1213,  856,  678, 4638,  698, 7028, 4923, 2428,\n",
      "        2190, 2642, 5442, 2141, 3177, 4294, 6378, 8024,  886, 1071, 6809, 1168,\n",
      "        2226, 1377, 5543, 7770, 4638, 3255, 1213, 3717, 2398,  511,  872, 6821,\n",
      "        4905, 2658, 1105, 2456, 6379, 2644, 1377,  809, 1343, 3633, 6226, 1278,\n",
      "        7368,  976,  798, 5301, 3466, 3389, 3780, 4545, 8024, 2456, 6379, 2644,\n",
      "        2398, 3198, 1914, 5314, 2111, 2094, 4381, 6387, 1914, 2458, 1355, 3255,\n",
      "        1213, 4638, 3952, 2767, 8024, 3309, 3307, 2769, 4638, 6237, 7025, 5543,\n",
      "        2376, 1221, 1168,  872,  511, 7370,  749, 1350, 3198, 3780, 4545, 3255,\n",
      "        1213,  856,  678, 1912, 8024, 2642, 5442, 3301, 1351, 4415, 2418, 1993,\n",
      "        5303,  924, 2898, 4916, 3353, 4638, 2552, 2578, 1343, 4684, 7481, 4565,\n",
      "        4567, 8024, 1372, 3300, 6821, 3416, 2798, 5543,  808, 2533, 2642, 5442,\n",
      "        1350, 3198, 2190, 4568, 3780, 4545, 8024, 1398, 3198, 6206, 1914, 4692,\n",
      "        7028, 5632, 6716, 7650, 7608, 2844, 4415, 8024, 1914, 6225, 3800, 5632,\n",
      "        6716, 4638, 4568, 4307, 1359, 1220, 8024, 6371,  711, 6821, 3416,  671,\n",
      "        2137, 5543, 2199, 3255, 1213,  856,  678, 3068, 6624,  511,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103, 1278, 7368, 2582,  720, 3780, 3255, 1213,  856,  678, 6821,  702,\n",
      "        4567,  136, 2207, 2111, 2094, 2347, 5307,  758, 2259,  749, 8024, 2697,\n",
      "        6230, 3300,  763, 2460, 2382, 8024,  679, 1008, 3633, 2382, 4638, 2111,\n",
      "        2094, 8024, 2600, 3221, 4717, 6230, 8024, 1353, 2418, 6826, 7162, 8024,\n",
      "        3221,  679, 3221, 3255, 1213,  856,  678, 8043, 4385, 1762, 2682, 4761,\n",
      "        6887, 8024, 1278, 7368, 2582,  720, 3780, 3255, 1213,  856,  678, 6821,\n",
      "         702, 4567,  136, 3301, 1351, 8024, 3418, 2945,  872, 4638, 1360, 6835,\n",
      "        8024, 1036, 4997, 3255, 1213,  856,  678, 7444, 6206, 3300,  757, 4685,\n",
      "        6981, 1394, 6817, 4500, 1278, 2110,  510, 4852,  833,  510, 3136, 2193,\n",
      "        1469, 5466,  689, 4294, 6378, 5023, 2974, 3177, 8024, 2902, 2399, 7977,\n",
      "        1920, 2207, 1469, 3255, 1213,  856,  678, 4638,  698, 7028, 4923, 2428,\n",
      "        2190, 2642, 5442, 2141, 3177, 4294, 6378, 8024,  886, 1071, 6809, 1168,\n",
      "        2226, 1377, 5543, 7770, 4638, 3255, 1213, 3717, 2398,  511,  872, 6821,\n",
      "        4905, 2658, 1105, 2456, 6379, 2644, 1377,  809, 1343, 3633, 6226, 1278,\n",
      "        7368,  976,  798, 5301, 3466, 3389, 3780, 4545, 8024, 2456, 6379, 2644,\n",
      "        2398, 3198, 1914, 5314, 2111, 2094, 4381, 6387, 1914, 2458, 1355, 3255,\n",
      "        1213, 4638, 3952, 2767, 8024, 3309, 3307, 2769, 4638, 6237, 7025, 5543,\n",
      "        2376, 1221, 1168,  872,  511, 7370,  749, 1350, 3198, 3780, 4545, 3255,\n",
      "        1213,  856,  678, 1912, 8024, 2642, 5442, 3301, 1351, 4415, 2418, 1993,\n",
      "        5303,  924, 2898, 4916, 3353, 4638, 2552, 2578, 1343, 4684, 7481, 4565,\n",
      "        4567, 8024, 1372, 3300, 6821, 3416, 2798, 5543,  808, 2533, 2642, 5442,\n",
      "        1350, 3198, 2190, 4568, 3780, 4545, 8024, 1398, 3198, 6206, 1914, 4692,\n",
      "        7028, 5632, 6716, 7650, 7608, 2844, 4415, 8024, 1914, 6225, 3800, 5632,\n",
      "        6716, 4638, 4568, 4307, 1359, 1220, 8024, 6371,  711, 6821, 3416,  671,\n",
      "        2137, 5543, 2199, 3255, 1213,  856,  678, 3068, 6624,  511,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "input_ids =  tensor([ 103, 2140, 2140, 1724,  702, 3299,  749, 8024,  794, 1139, 4495, 1168,\n",
      "        4385, 1762, 8043, 2140, 2140, 1724,  702, 3299,  749, 8024,  794, 7360,\n",
      "        4495, 1168, 4385, 1762, 8024,  671, 4684, 3766, 4717, 6814, 1920, 6230,\n",
      "        8024, 4385, 1762,  738, 3221,  697,  702, 2207, 3198, 7008,  671, 1726,\n",
      "        8024,  794, 3241,  677,  676, 4157, 1914,  722, 1400, 8024, 6435, 1920,\n",
      "        1923, 2376, 2376, 2564, 4692,  671, 4692,  800,  671, 4684, 7008, 4638,\n",
      "        7574, 5246, 2582,  720, 1726,  752, 1450, 8043, 2769, 2586,  800, 4717,\n",
      "         679, 1962, 2397, 2817, 4495, 7270, 1355, 5509, 8024, 6468, 6468, 1920,\n",
      "        1923,  749, 3418, 2945, 2644, 4638, 1360, 6835, 8024, 5440, 5991, 2111,\n",
      "        2094, 4638, 6821,  763, 4568, 4307, 6656, 1959, 7030,  679, 6639, 1469,\n",
      "        5592, 6956,  679, 6844, 6963, 3300, 1068, 5143, 4638,  511, 2644, 2398,\n",
      "        3198, 4522, 2692, 5314, 2111, 2094, 5592, 6956, 7344, 2170, 8024, 2972,\n",
      "        2897, 5592, 6956, 8024, 4717, 1184, 5314, 2111, 2094, 1585,  671, 3613,\n",
      "        1959, 8024, 2111, 2094, 1959, 3717,  679, 6639, 2644, 1377,  809, 3921,\n",
      "        1469, 1585, 1075, 8024, 1724,  702, 3299,  738, 1377,  809, 4635, 1921,\n",
      "        2990,  897, 6774, 7608,  749,  511, 2456, 6379, 6206, 2902, 7444, 1585,\n",
      "        1075, 8024,  809, 3678,  745,  711, 1825, 4794, 8024, 2553, 6206, 4638,\n",
      "        3198,  952, 1377,  809, 5314, 2140, 2140, 3302, 7608, 4660, 4495, 5826,\n",
      "        3341, 6444, 3146, 5517, 5499, 4638, 1216, 5543,  511,  101],\n",
      "       device='cuda:0')\n",
      "label_ids =  tensor([ 103, 2140, 2140, 1724,  702, 3299,  749, 8024,  794, 1139, 4495, 1168,\n",
      "        4385, 1762, 8043, 2140, 2140, 1724,  702, 3299,  749, 8024,  794, 7360,\n",
      "        4495, 1168, 4385, 1762, 8024,  671, 4684, 3766, 4717, 6814, 1920, 6230,\n",
      "        8024, 4385, 1762,  738, 3221,  697,  702, 2207, 3198, 7008,  671, 1726,\n",
      "        8024,  794, 3241,  677,  676, 4157, 1914,  722, 1400, 8024, 6435, 1920,\n",
      "        1923, 2376, 2376, 2564, 4692,  671, 4692,  800,  671, 4684, 7008, 4638,\n",
      "        7574, 5246, 2582,  720, 1726,  752, 1450, 8043, 2769, 2586,  800, 4717,\n",
      "         679, 1962, 2397, 2817, 4495, 7270, 1355, 5509, 8024, 6468, 6468, 1920,\n",
      "        1923,  749, 3418, 2945, 2644, 4638, 1360, 6835, 8024, 5440, 5991, 2111,\n",
      "        2094, 4638, 6821,  763, 4568, 4307, 6656, 1959, 7030,  679, 6639, 1469,\n",
      "        5592, 6956,  679, 6844, 6963, 3300, 1068, 5143, 4638,  511, 2644, 2398,\n",
      "        3198, 4522, 2692, 5314, 2111, 2094, 5592, 6956, 7344, 2170, 8024, 2972,\n",
      "        2897, 5592, 6956, 8024, 4717, 1184, 5314, 2111, 2094, 1585,  671, 3613,\n",
      "        1959, 8024, 2111, 2094, 1959, 3717,  679, 6639, 2644, 1377,  809, 3921,\n",
      "        1469, 1585, 1075, 8024, 1724,  702, 3299,  738, 1377,  809, 4635, 1921,\n",
      "        2990,  897, 6774, 7608,  749,  511, 2456, 6379, 6206, 2902, 7444, 1585,\n",
      "        1075, 8024,  809, 3678,  745,  711, 1825, 4794, 8024, 2553, 6206, 4638,\n",
      "        3198,  952, 1377,  809, 5314, 2140, 2140, 3302, 7608, 4660, 4495, 5826,\n",
      "        3341, 6444, 3146, 5517, 5499, 4638, 1216, 5543,  511,  101],\n",
      "       device='cuda:0')\n",
      "private_positions =  tensor([], device='cuda:0', dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-1:   0%|          | 36/9000 [00:02<11:30, 12.99it/s, loss=2.9400237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids =  tensor([ 103,  122, 2259,  130,  702, 3299, 1920,  912, 3198, 1526, 3221, 6768,\n",
      "        2544,  912, 4908, 2582,  720, 1215, 8043, 6435, 7309,  117, 2207, 1957,\n",
      "         122, 2259,  130,  702, 3299,  117, 1762, 1920,  912, 3198, 1962, 1526,\n",
      "         117, 3221, 6768, 2544,  912, 4908,  117, 6421, 2582, 3416, 3780, 4545,\n",
      "        1450,  136, 1961, 2398, 2382, 1391,  763, 5922, 5831, 7313, 7392, 1391,\n",
      "        8024, 6820, 3300, 6007,  510, 3717, 7659,  510, 3739,  510, 7672, 1928,\n",
      "         510, 4156, 2372, 7824,  510, 2207, 5101, 3739, 8024,  671, 5663, 7650,\n",
      "        7608,  738, 2218, 6821,  763, 8024, 7370,  749, 1914, 1600, 3717, 8024,\n",
      "        6820, 3300, 1166, 4638, 3175, 3791, 1408, 8043, 6468, 6468, 8013,  872,\n",
      "        1962, 8024,  671, 2259, 1914, 2140, 2140,  912, 4908, 3680, 3613, 1920,\n",
      "         912, 6963, 1526, 8024, 1377, 5543, 3221, 7270, 4574, 4555,  749,  117,\n",
      "         679,  833, 6432, 6413,  117, 3680, 3613, 2861, 5107, 5107, 2218, 1526,\n",
      "         117, 1377, 5543, 3221, 1728,  711, 4563, 1416,  119, 3680, 3613, 4563,\n",
      "         749, 5632, 2346, 1348, 2828, 1920,  912, 2728, 1726, 1343,  117, 2193,\n",
      "        5636, 1920,  912, 6632, 3341, 6632, 2397,  117, 1377, 5543, 3680, 3613,\n",
      "        2861, 5107, 5107, 6963,  833, 5497, 7305, 1139, 6117,  511, 1963, 3362,\n",
      "        6820, 1762, 5314, 2111, 2094, 6133, 7159,  117,  679, 6206, 6133,  749,\n",
      "         119, 7159,  833, 1469, 7608, 4289,  704, 4638, 5544, 5505, 3921, 1394,\n",
      "         117, 2501, 2768, 7159, 4637,  117, 2471, 6629,  912, 4908,  119, 1914,\n",
      "        5314, 2111, 2094, 1391, 5922, 5831,  510, 3717, 3362,  119, 5922, 5831,\n",
      "         679, 6206, 6814, 3779, 4181, 1169,  117, 3717, 4194,  671,  678,  117,\n",
      "        1176, 4810, 2218, 1377,  809,  749,  119,  101], device='cuda:0')\n",
      "label_ids =  tensor([ 103,  122, 2259,  130,  702, 3299, 1920,  912, 3198, 1526, 3221, 6768,\n",
      "        2544,  912, 4908, 2582,  720, 1215, 8043, 6435, 7309,  117, 2207, 1957,\n",
      "         122, 2259,  130,  702, 3299,  117, 1762, 1920,  912, 3198, 1962, 1526,\n",
      "         117, 3221, 6768, 2544,  912, 4908,  117, 6421, 2582, 3416, 3780, 4545,\n",
      "        1450,  136, 1961, 2398, 2382, 1391,  763, 5922, 5831, 7313, 7392, 1391,\n",
      "        8024, 6820, 3300, 6007,  510, 3717, 7659,  510, 3739,  510, 7672, 1928,\n",
      "         510, 4156, 2372, 7824,  510, 2207, 5101, 3739, 8024,  671, 5663, 7650,\n",
      "        7608,  738, 2218, 6821,  763, 8024, 7370,  749, 1914, 1600, 3717, 8024,\n",
      "        6820, 3300, 1166, 4638, 3175, 3791, 1408, 8043, 6468, 6468, 8013,  872,\n",
      "        1962, 8024,  671, 2259, 1914, 2140, 2140,  912, 4908, 3680, 3613, 1920,\n",
      "         912, 6963, 1526, 8024, 1377, 5543, 3221, 7270, 4574, 4555,  749,  117,\n",
      "         679,  833, 6432, 6413,  117, 3680, 3613, 2861, 5107, 5107, 2218, 1526,\n",
      "         117, 1377, 5543, 3221, 1728,  711, 4563, 1416,  119, 3680, 3613, 4563,\n",
      "         749, 5632, 2346, 1348, 2828, 1920,  912, 2728, 1726, 1343,  117, 2193,\n",
      "        5636, 1920,  912, 6632, 3341, 6632, 2397,  117, 1377, 5543, 3680, 3613,\n",
      "        2861, 5107, 5107, 6963,  833, 5497, 7305, 1139, 6117,  511, 1963, 3362,\n",
      "        6820, 1762, 5314, 2111, 2094, 6133, 7159,  117,  679, 6206, 6133,  749,\n",
      "         119, 7159,  833, 1469, 7608, 4289,  704, 4638, 5544, 5505, 3921, 1394,\n",
      "         117, 2501, 2768, 7159, 4637,  117, 2471, 6629,  912, 4908,  119, 1914,\n",
      "        5314, 2111, 2094, 1391, 5922, 5831,  510, 3717, 3362,  119, 5922, 5831,\n",
      "         679, 6206, 6814, 3779, 4181, 1169,  117, 3717, 4194,  671,  678,  117,\n",
      "        1176, 4810, 2218, 1377,  809,  749,  119,  101], device='cuda:0')\n",
      "private_positions =  tensor([ 1,  3, 24, 26], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\VSCode\\Experiment_Thesis\\DP\\SDP_TrainOptim_CFT\\tmp_train.ipynb 单元格 8\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/DP/SDP_TrainOptim_CFT/tmp_train.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mprivate_positions = \u001b[39m\u001b[39m'\u001b[39m, private_positions)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/DP/SDP_TrainOptim_CFT/tmp_train.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#  forward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/DP/SDP_TrainOptim_CFT/tmp_train.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39;49minput_ids, labels\u001b[39m=\u001b[39;49mlabel_ids, private_positions\u001b[39m=\u001b[39;49mprivate_positions, sigma\u001b[39m=\u001b[39;49msigma)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/DP/SDP_TrainOptim_CFT/tmp_train.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss, logits \u001b[39m=\u001b[39m outputs[:\u001b[39m2\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/DP/SDP_TrainOptim_CFT/tmp_train.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mif\u001b[39;00m gradient_accumulation \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\VSCode\\Experiment_Thesis\\DP\\SDP_TrainOptim_CFT\\gpt2\\modeling_gpt2.py:1354\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, private_positions, sigma)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1345\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1346\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m return_dict \u001b[39m=\u001b[39m (\n\u001b[0;32m   1351\u001b[0m     return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m   1352\u001b[0m )\n\u001b[1;32m-> 1354\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m   1355\u001b[0m     input_ids,\n\u001b[0;32m   1356\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1357\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1358\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1359\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1360\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1361\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1362\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1363\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1364\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1365\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1366\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1367\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1368\u001b[0m )\n\u001b[0;32m   1369\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1371\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\VSCode\\Experiment_Thesis\\DP\\SDP_TrainOptim_CFT\\gpt2\\modeling_gpt2.py:1154\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m   1145\u001b[0m         create_custom_forward(block),\n\u001b[0;32m   1146\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1151\u001b[0m         encoder_attention_mask,\n\u001b[0;32m   1152\u001b[0m     )\n\u001b[0;32m   1153\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1154\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[0;32m   1155\u001b[0m         hidden_states,\n\u001b[0;32m   1156\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m   1157\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1158\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m   1159\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1160\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1161\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1162\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1163\u001b[0m     )\n\u001b[0;32m   1165\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1166\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\VSCode\\Experiment_Thesis\\DP\\SDP_TrainOptim_CFT\\gpt2\\modeling_gpt2.py:641\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    636\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m    637\u001b[0m         outputs \u001b[39m+\u001b[39m cross_attn_outputs[\u001b[39m2\u001b[39m:]\n\u001b[0;32m    638\u001b[0m     )  \u001b[39m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[0;32m    640\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m--> 641\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln_2(hidden_states)\n\u001b[0;32m    642\u001b[0m feed_forward_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    643\u001b[0m \u001b[39m# residual connection\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlayer_norm(\n\u001b[0;32m    191\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2511\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[0;32m   2512\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2513\u001b[0m         layer_norm, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, normalized_shape, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps\n\u001b[0;32m   2514\u001b[0m     )\n\u001b[1;32m-> 2515\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mlayer_norm(\u001b[39minput\u001b[39;49m, normalized_shape, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "early_stopping = EarlyStopping(output_dir)\n",
    "train_step_per_epoch = len(train_dataloader)\n",
    "valid_step_per_epoch = len(valid_dataloader)\n",
    "for epoch in range(epochs):\n",
    "    logger.info('epoch {}'.format(epoch + 1))\n",
    "    now = datetime.now()\n",
    "    logger.info('time: {}'.format(now))\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_dataloader)\n",
    "    all_train_loss = 0.0\n",
    "    train_pbar.set_description('epoch-' + str(epoch + 1))\n",
    "    \n",
    "    for step, (input, label, private_positions) in enumerate(train_pbar):\n",
    "        input_ids = torch.tensor(label).long().to(device)\n",
    "        label_ids = torch.tensor(input).long().to(device)\n",
    "        private_positions = torch.tensor(private_positions, dtype=torch.long).to(device)\n",
    "\n",
    "        #  forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=label_ids, private_positions=private_positions, sigma=sigma)\n",
    "        loss, logits = outputs[:2]\n",
    "        \n",
    "        if gradient_accumulation > 1:\n",
    "            loss = loss / gradient_accumulation\n",
    "            \n",
    "        #  loss backward\n",
    "        # if fp16:\n",
    "        #     with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #         scaled_loss.backward()\n",
    "        #         torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), max_grad_norm)\n",
    "        # else:\n",
    "        #     loss.backward()\n",
    "        #     torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        loss.backward()\n",
    "        loss = loss.detach()\n",
    "        all_train_loss += loss\n",
    "        \n",
    "        writer.add_scalar('loss/train_step_loss', scalar_value=loss * gradient_accumulation, global_step=epoch * train_step_per_epoch+step)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        #  optimizer step\n",
    "        if (step + 1) % gradient_accumulation == 0:\n",
    "            running_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        if (step + 1) % log_step == 0:\n",
    "            logger.info('now time: {}:{}. Step {} of epoch {}, loss {}'.format(\n",
    "                datetime.now().hour,\n",
    "                datetime.now().minute,\n",
    "                (step + 1) // gradient_accumulation,\n",
    "                epoch + 1,\n",
    "                running_loss / log_step))\n",
    "            running_loss = 0\n",
    "        \n",
    "        train_pbar.set_postfix({'loss': '{:.7f}'.format(loss*gradient_accumulation)})\n",
    "        \n",
    "    logger.info('train step = {}'.format(step))\n",
    "    all_train_loss = all_train_loss / (step + 1)\n",
    "\n",
    "    writer.add_scalar('loss/train_epoch_loss', scalar_value=all_train_loss * gradient_accumulation, global_step=epoch + 1)\n",
    "    logger.info('saving model for epoch {}'.format(epoch + 1))\n",
    "    if not os.path.exists(output_dir + 'model_epoch{}'.format(epoch + 1)):\n",
    "        os.mkdir(output_dir + 'model_epoch{}'.format(epoch + 1))\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    model_to_save.save_pretrained(output_dir + 'model_epoch{}'.format(epoch + 1))\n",
    "\n",
    "    logger.info('epoch {} finished, train loss = {:.10f}'.format(epoch + 1, all_train_loss * gradient_accumulation))\n",
    "\n",
    "    then = datetime.now()\n",
    "    logger.info('time: {}'.format(then))\n",
    "    logger.info('time for one epoch: {}'.format(then - now))\n",
    "    \n",
    "    logger.info('start validate')\n",
    "    model.eval()\n",
    "    all_valid_loss = 0.0\n",
    "    valid_pbar = tqdm(valid_dataloader)\n",
    "    valid_pbar.set_description('valid ' + str(epoch + 1))\n",
    "    for step, (input, label) in enumerate(valid_pbar):\n",
    "        input_ids = torch.tensor(label).long().to(device)\n",
    "        label_ids = torch.tensor(input).long().to(device)\n",
    "\n",
    "        #  forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=label_ids)\n",
    "        loss = outputs[0].detach()\n",
    "        writer.add_scalar('loss/valid_step_loss', scalar_value=loss, global_step=epoch * valid_step_per_epoch + step)\n",
    "        all_valid_loss += loss\n",
    "        valid_pbar.set_postfix({'loss': '{:.7f}'.format(loss)})\n",
    "    \n",
    "    logger.info('valid step = {}'.format(step))\n",
    "    all_valid_loss = all_valid_loss / (step + 1)\n",
    "    writer.add_scalar('loss/valid_epoch_loss', scalar_value=all_valid_loss, global_step=epoch+1)\n",
    "    logger.info('valid finished, valid loss = {:.10f}'.format(all_valid_loss))\n",
    "    early_stopping(all_valid_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        logger.info(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "writer.close()    \n",
    "\n",
    "logger.info('training finished')\n",
    "if not os.path.exists(output_dir + 'final_model'):\n",
    "    os.mkdir(output_dir + 'final_model')\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir + 'final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a3cd800b0a689aaaf7f80ffde17840503226750eb3edba7eb3c5a252600cb17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
