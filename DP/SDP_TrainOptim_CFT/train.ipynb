{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2.modeling_gpt2 import GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers import BertTokenizer, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"Util to make training reproducible\"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    if os.getenv(\"CUBLAS_WORKSPACE_CONFIG\") is not None:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def worker_init(worked_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def set_logger(path):\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    handler = logging.FileHandler(path + \"/train_log.txt\")\n",
    "    logger.setLevel(level=logging.INFO)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(filename)s - %(funcName)s - %(lineno)s - %(levelname)s\\n%(message)s\",\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    console = logging.StreamHandler()\n",
    "    console.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.addHandler(console)\n",
    "\n",
    "\n",
    "class Chinese_Medical_DS(Dataset):\n",
    "    def __init__(self, path, tokenizer, max_len=1024):\n",
    "        self.path = path\n",
    "        sentence = []\n",
    "        self.private_positions_list = []\n",
    "        \n",
    "        self.total_private_tokens = 0\n",
    "        self.total_tokens = 0\n",
    "        self.private_tokens_per_sentence = []\n",
    "        \n",
    "        with open(self.path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                sen_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(line.strip()))\n",
    "                full_sen = []\n",
    "                \n",
    "                full_sen.append(tokenizer.convert_tokens_to_ids('[MASK]'))\n",
    "                full_sen.extend(sen_ids)\n",
    "                full_sen.append(tokenizer.convert_tokens_to_ids('[CLS]'))\n",
    "                private_positions = [i for i, token_id in enumerate(full_sen) if tokenizer.decode([token_id]).isdigit()]\n",
    "                self.private_positions_list.append(private_positions)\n",
    "                if len(full_sen) <= max_len:\n",
    "                    sentence.append(full_sen)\n",
    "                \n",
    "                num_private_tokens = len(private_positions)\n",
    "                self.total_private_tokens += num_private_tokens\n",
    "                self.total_tokens += len(full_sen)\n",
    "                self.private_tokens_per_sentence.append(num_private_tokens)\n",
    "                \n",
    "        self.data = sentence\n",
    "        \n",
    "        # 计算平均每句话中的隐私token数\n",
    "        average_private_tokens_per_sentence = sum(self.private_tokens_per_sentence) / len(self.private_tokens_per_sentence)\n",
    "\n",
    "        # 计算总的隐私token占总token的比例\n",
    "        private_token_ratio = self.total_private_tokens / self.total_tokens\n",
    "\n",
    "        # 计算隐私token个数的均值和方差\n",
    "        private_token_mean = np.mean(self.private_tokens_per_sentence)\n",
    "        private_token_variance = np.var(self.private_tokens_per_sentence)\n",
    "\n",
    "        # 打印统计信息\n",
    "        print(f\"Average private tokens per sentence: {average_private_tokens_per_sentence:.2f}\")\n",
    "        print(f\"Private token ratio: {private_token_ratio:.4f}\")\n",
    "        print(f\"Private token count mean: {private_token_mean:.2f}\")\n",
    "        print(f\"Private token count variance: {private_token_variance:.2f}\")\n",
    "        \n",
    "    # need to overload\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # need to overload\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.data[idx]\n",
    "        target = input\n",
    "        private_positions = self.private_positions_list[idx]\n",
    "        return input, target, private_positions\n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, save_path, patience=2, verbose=True, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            save_path : 模型保存文件夹\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.save_path = save_path\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        model_to_save.save_pretrained(self.save_path + 'best_model')\n",
    "        \n",
    "        # path = os.path.join(self.save_path, \"best_network.pth\")\n",
    "        # torch.save(model.state_dict(), path)  # 这里会存储迄今最优模型的参数\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "tok_path = '..\\\\..\\\\Raw_GPT2\\\\vocab.txt'\n",
    "pretrain_model_path = \"..\\\\..\\\\Raw_GPT2\\\\\"\n",
    "output_dir = \"model\\\\\"\n",
    "\n",
    "epochs = 50\n",
    "warmup_steps = 1000\n",
    "lr = 1e-5\n",
    "gradient_accumulation = 18\n",
    "max_grad_norm = 1.0\n",
    "log_step = 10000\n",
    "set_logger(output_dir)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel::init\n",
      "config =  GPT2Config {\n",
      "  \"_name_or_path\": \"..\\\\..\\\\Raw_GPT2\\\\\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"output_past\": true,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 320\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 14:59:10 - 945538542.py - <module> - 4 - INFO\n",
      "using device:cuda\n",
      "2023-04-01 14:59:10 - 945538542.py - <module> - 7 - INFO\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(21128, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer(vocab_file=tok_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(pretrain_model_path)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "logger.info('using device:{}'.format(device))\n",
    "model.train()\n",
    "model.to(device)\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average private tokens per sentence: 1.22\n",
      "Private token ratio: 0.0055\n",
      "Private token count mean: 1.22\n",
      "Private token count variance: 4.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 14:59:39 - 3687209076.py - <module> - 5 - INFO\n",
      "len(train_dataloader), len(valid_dataloader) = 9000, 1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average private tokens per sentence: 1.22\n",
      "Private token ratio: 0.0055\n",
      "Private token count mean: 1.22\n",
      "Private token count variance: 5.27\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Chinese_Medical_DS(\"..\\\\..\\\\Data\\\\tiny_train.txt\", tokenizer)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, worker_init_fn=worker_init)\n",
    "valid_dataset = Chinese_Medical_DS(\"..\\\\..\\\\Data\\\\tiny_valid.txt\", tokenizer)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, worker_init_fn=worker_init)\n",
    "logger.info(\"len(train_dataloader), len(valid_dataloader) = {}, {}\".format(len(train_dataloader), len(valid_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
    "                                                          num_training_steps=len(train_dataloader))\n",
    "tb_path = output_dir + \"/tb\"\n",
    "if not os.path.exists(tb_path):\n",
    "    os.mkdir(tb_path)\n",
    "writer = SummaryWriter(tb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1e-05, 0.810546875)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_log = len(train_dataloader) * np.log(len(train_dataloader))\n",
    "delta = 1.0 / train_num_log if 1.0 / train_num_log < 1e-5 else 1e-5\n",
    "epsilon = 0.5\n",
    "sigma = 0.810546875\n",
    "epsilon, delta, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 14:59:39 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 1\n",
      "2023-04-01 14:59:39 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 14:59:39.306014\n",
      "epoch-1: 100%|██████████| 9000/9000 [08:35<00:00, 17.44it/s, loss=2.8596079]\n",
      "2023-04-01 15:08:15 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 15:08:15 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 1\n",
      "2023-04-01 15:08:15 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 1 finished, train loss = 2.6342368126\n",
      "2023-04-01 15:08:15 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 15:08:15.651124\n",
      "2023-04-01 15:08:15 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:36.345110\n",
      "2023-04-01 15:08:15 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 1: 100%|██████████| 1500/1500 [00:30<00:00, 48.64it/s, loss=2.7352777]\n",
      "2023-04-01 15:08:46 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 15:08:46 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.4039840698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 2.403984).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 15:08:46 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 2\n",
      "2023-04-01 15:08:46 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 15:08:46.871122\n",
      "epoch-2: 100%|██████████| 9000/9000 [08:12<00:00, 18.27it/s, loss=2.6344121]\n",
      "2023-04-01 15:16:59 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 15:16:59 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 2\n",
      "2023-04-01 15:16:59 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 2 finished, train loss = 2.3726568222\n",
      "2023-04-01 15:16:59 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 15:16:59.762772\n",
      "2023-04-01 15:16:59 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:12.891650\n",
      "2023-04-01 15:16:59 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 2: 100%|██████████| 1500/1500 [00:32<00:00, 45.91it/s, loss=2.7022147]\n",
      "2023-04-01 15:17:32 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 15:17:32 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.2438614368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.403984 --> 2.243861).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 15:17:32 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 3\n",
      "2023-04-01 15:17:32 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 15:17:32.864411\n",
      "epoch-3: 100%|██████████| 9000/9000 [08:07<00:00, 18.44it/s, loss=2.5887065]\n",
      "2023-04-01 15:25:40 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 15:25:40 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 3\n",
      "2023-04-01 15:25:41 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 3 finished, train loss = 2.2246961594\n",
      "2023-04-01 15:25:41 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 15:25:41.220413\n",
      "2023-04-01 15:25:41 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:08.356002\n",
      "2023-04-01 15:25:41 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 3: 100%|██████████| 1500/1500 [00:30<00:00, 48.75it/s, loss=2.6823409]\n",
      "2023-04-01 15:26:11 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 15:26:11 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.1468384266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.243861 --> 2.146838).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 15:26:12 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 4\n",
      "2023-04-01 15:26:12 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 15:26:12.415411\n",
      "epoch-4: 100%|██████████| 9000/9000 [08:01<00:00, 18.69it/s, loss=2.5263071]\n",
      "2023-04-01 15:34:13 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 15:34:13 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 4\n",
      "2023-04-01 15:34:14 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 4 finished, train loss = 2.1333994865\n",
      "2023-04-01 15:34:14 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 15:34:14.358410\n",
      "2023-04-01 15:34:14 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:01.942999\n",
      "2023-04-01 15:34:14 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 4: 100%|██████████| 1500/1500 [00:30<00:00, 48.62it/s, loss=2.6741590]\n",
      "2023-04-01 15:34:45 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 15:34:45 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0955147743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.146838 --> 2.095515).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 15:34:45 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 5\n",
      "2023-04-01 15:34:45 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 15:34:45.609410\n",
      "epoch-5: 100%|██████████| 9000/9000 [08:02<00:00, 18.67it/s, loss=2.4577608]\n",
      "2023-04-01 15:42:47 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 15:42:47 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 5\n",
      "2023-04-01 15:42:48 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 5 finished, train loss = 2.0733227730\n",
      "2023-04-01 15:42:48 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 15:42:48.125409\n",
      "2023-04-01 15:42:48 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:02.515999\n",
      "2023-04-01 15:42:48 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 5: 100%|██████████| 1500/1500 [00:32<00:00, 46.34it/s, loss=2.6615982]\n",
      "2023-04-01 15:43:20 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 15:43:20 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0610613823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.095515 --> 2.061061).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 15:43:20 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 6\n",
      "2023-04-01 15:43:20 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 15:43:20.895522\n",
      "epoch-6: 100%|██████████| 9000/9000 [08:06<00:00, 18.51it/s, loss=2.4105928]\n",
      "2023-04-01 15:51:27 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 15:51:27 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 6\n",
      "2023-04-01 15:51:27 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 6 finished, train loss = 2.0291473866\n",
      "2023-04-01 15:51:27 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 15:51:27.559426\n",
      "2023-04-01 15:51:27 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:06.663904\n",
      "2023-04-01 15:51:27 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 6: 100%|██████████| 1500/1500 [00:30<00:00, 48.56it/s, loss=2.6563699]\n",
      "2023-04-01 15:51:58 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 15:51:58 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0376565456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.061061 --> 2.037657).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 15:51:58 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 7\n",
      "2023-04-01 15:51:58 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 15:51:58.861428\n",
      "epoch-7: 100%|██████████| 9000/9000 [08:08<00:00, 18.43it/s, loss=2.4290924]\n",
      "2023-04-01 16:00:07 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 16:00:07 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 7\n",
      "2023-04-01 16:00:07 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 7 finished, train loss = 1.9952791929\n",
      "2023-04-01 16:00:07 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 16:00:07.578934\n",
      "2023-04-01 16:00:07 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:08.717506\n",
      "2023-04-01 16:00:07 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 7: 100%|██████████| 1500/1500 [00:30<00:00, 48.42it/s, loss=2.6437562]\n",
      "2023-04-01 16:00:38 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 16:00:38 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0201663971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.037657 --> 2.020166).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 16:00:38 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 8\n",
      "2023-04-01 16:00:38 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 16:00:38.963931\n",
      "epoch-8: 100%|██████████| 9000/9000 [08:05<00:00, 18.54it/s, loss=2.3547471]\n",
      "2023-04-01 16:08:44 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 16:08:44 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 8\n",
      "2023-04-01 16:08:44 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 8 finished, train loss = 1.9671690464\n",
      "2023-04-01 16:08:44 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 16:08:44.688931\n",
      "2023-04-01 16:08:44 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:05.725000\n",
      "2023-04-01 16:08:44 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 8: 100%|██████████| 1500/1500 [00:30<00:00, 48.47it/s, loss=2.6440938]\n",
      "2023-04-01 16:09:15 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 16:09:15 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0069541931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.020166 --> 2.006954).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 16:09:16 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 9\n",
      "2023-04-01 16:09:16 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 16:09:16.038932\n",
      "epoch-9: 100%|██████████| 9000/9000 [08:13<00:00, 18.25it/s, loss=2.3619170]\n",
      "2023-04-01 16:17:29 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 16:17:29 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 9\n",
      "2023-04-01 16:17:29 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 9 finished, train loss = 1.9438589811\n",
      "2023-04-01 16:17:29 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 16:17:29.500624\n",
      "2023-04-01 16:17:29 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:13.461692\n",
      "2023-04-01 16:17:29 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 9: 100%|██████████| 1500/1500 [00:34<00:00, 43.79it/s, loss=2.6358354]\n",
      "2023-04-01 16:18:03 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 16:18:03 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9951997995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.006954 --> 1.995200).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 16:18:04 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 10\n",
      "2023-04-01 16:18:04 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 16:18:04.163348\n",
      "epoch-10: 100%|██████████| 9000/9000 [08:12<00:00, 18.28it/s, loss=2.3369248]\n",
      "2023-04-01 16:26:16 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 16:26:16 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 10\n",
      "2023-04-01 16:26:17 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 10 finished, train loss = 1.9243437052\n",
      "2023-04-01 16:26:17 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 16:26:17.006410\n",
      "2023-04-01 16:26:17 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:12.843062\n",
      "2023-04-01 16:26:17 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 10: 100%|██████████| 1500/1500 [00:32<00:00, 45.76it/s, loss=2.6370871]\n",
      "2023-04-01 16:26:49 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 16:26:49 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9862942696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.995200 --> 1.986294).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 16:26:50 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 11\n",
      "2023-04-01 16:26:50 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 16:26:50.207284\n",
      "epoch-11: 100%|██████████| 9000/9000 [08:15<00:00, 18.17it/s, loss=2.2538579]\n",
      "2023-04-01 16:35:05 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 16:35:05 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 11\n",
      "2023-04-01 16:35:05 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 11 finished, train loss = 1.9068467617\n",
      "2023-04-01 16:35:05 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 16:35:05.960288\n",
      "2023-04-01 16:35:05 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:15.753004\n",
      "2023-04-01 16:35:05 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 11: 100%|██████████| 1500/1500 [00:32<00:00, 46.74it/s, loss=2.6383166]\n",
      "2023-04-01 16:35:38 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 16:35:38 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9796000719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.986294 --> 1.979600).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 16:35:38 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 12\n",
      "2023-04-01 16:35:38 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 16:35:38.464289\n",
      "epoch-12: 100%|██████████| 9000/9000 [08:05<00:00, 18.54it/s, loss=2.2727230]\n",
      "2023-04-01 16:43:43 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 16:43:43 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 12\n",
      "2023-04-01 16:43:44 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 12 finished, train loss = 1.8934389353\n",
      "2023-04-01 16:43:44 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 16:43:44.302287\n",
      "2023-04-01 16:43:44 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:05.837998\n",
      "2023-04-01 16:43:44 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 12: 100%|██████████| 1500/1500 [00:30<00:00, 48.53it/s, loss=2.6364110]\n",
      "2023-04-01 16:44:15 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 16:44:15 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9747456312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.979600 --> 1.974746).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 16:44:15 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 13\n",
      "2023-04-01 16:44:15 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 16:44:15.609287\n",
      "epoch-13: 100%|██████████| 9000/9000 [08:08<00:00, 18.42it/s, loss=2.2721488]\n",
      "2023-04-01 16:52:24 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 16:52:24 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 13\n",
      "2023-04-01 16:52:24 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 13 finished, train loss = 1.8809707165\n",
      "2023-04-01 16:52:24 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 16:52:24.709334\n",
      "2023-04-01 16:52:24 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:09.100047\n",
      "2023-04-01 16:52:24 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 13: 100%|██████████| 1500/1500 [00:33<00:00, 45.33it/s, loss=2.6474183]\n",
      "2023-04-01 16:52:57 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 16:52:57 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9695674181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.974746 --> 1.969567).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 16:52:58 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 14\n",
      "2023-04-01 16:52:58 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 16:52:58.206429\n",
      "epoch-14: 100%|██████████| 9000/9000 [08:13<00:00, 18.22it/s, loss=2.2760606]\n",
      "2023-04-01 17:01:12 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 17:01:12 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 14\n",
      "2023-04-01 17:01:12 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 14 finished, train loss = 1.8707462549\n",
      "2023-04-01 17:01:12 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 17:01:12.464016\n",
      "2023-04-01 17:01:12 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:14.257587\n",
      "2023-04-01 17:01:12 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 14: 100%|██████████| 1500/1500 [00:32<00:00, 46.74it/s, loss=2.6493819]\n",
      "2023-04-01 17:01:44 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 17:01:44 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9662088156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.969567 --> 1.966209).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 17:01:44 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 15\n",
      "2023-04-01 17:01:44 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 17:01:44.988018\n",
      "epoch-15: 100%|██████████| 9000/9000 [08:13<00:00, 18.23it/s, loss=2.3298962]\n",
      "2023-04-01 17:09:58 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 17:09:58 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 15\n",
      "2023-04-01 17:09:59 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 15 finished, train loss = 1.8631006479\n",
      "2023-04-01 17:09:59 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 17:09:59.009145\n",
      "2023-04-01 17:09:59 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:14.021127\n",
      "2023-04-01 17:09:59 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 15: 100%|██████████| 1500/1500 [00:31<00:00, 46.98it/s, loss=2.6523092]\n",
      "2023-04-01 17:10:30 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 17:10:30 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9635126591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.966209 --> 1.963513).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 17:10:31 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 16\n",
      "2023-04-01 17:10:31 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 17:10:31.371170\n",
      "epoch-16: 100%|██████████| 9000/9000 [08:13<00:00, 18.25it/s, loss=2.2385042]\n",
      "2023-04-01 17:18:44 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 17:18:44 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 16\n",
      "2023-04-01 17:18:45 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 16 finished, train loss = 1.8564864397\n",
      "2023-04-01 17:18:45 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 17:18:45.035382\n",
      "2023-04-01 17:18:45 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:13.664212\n",
      "2023-04-01 17:18:45 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 16: 100%|██████████| 1500/1500 [00:31<00:00, 47.39it/s, loss=2.6567245]\n",
      "2023-04-01 17:19:16 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 17:19:16 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9613724947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.963513 --> 1.961372).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 17:19:17 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 17\n",
      "2023-04-01 17:19:17 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 17:19:17.105384\n",
      "epoch-17: 100%|██████████| 9000/9000 [08:06<00:00, 18.50it/s, loss=2.2690866]\n",
      "2023-04-01 17:27:23 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 17:27:23 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 17\n",
      "2023-04-01 17:27:23 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 17 finished, train loss = 1.8526811600\n",
      "2023-04-01 17:27:23 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 17:27:23.997777\n",
      "2023-04-01 17:27:23 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:06.892393\n",
      "2023-04-01 17:27:23 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 17: 100%|██████████| 1500/1500 [00:31<00:00, 48.37it/s, loss=2.6551199]\n",
      "2023-04-01 17:27:55 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 17:27:55 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9595637321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.961372 --> 1.959564).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 17:27:55 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 18\n",
      "2023-04-01 17:27:55 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 17:27:55.420777\n",
      "epoch-18: 100%|██████████| 9000/9000 [08:00<00:00, 18.72it/s, loss=2.2771008]\n",
      "2023-04-01 17:35:56 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 17:35:56 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 18\n",
      "2023-04-01 17:35:56 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 18 finished, train loss = 1.8495301008\n",
      "2023-04-01 17:35:56 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 17:35:56.518779\n",
      "2023-04-01 17:35:56 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:01.098002\n",
      "2023-04-01 17:35:56 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 18: 100%|██████████| 1500/1500 [00:30<00:00, 48.68it/s, loss=2.6621745]\n",
      "2023-04-01 17:36:27 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 17:36:27 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9582861662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.959564 --> 1.958286).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 17:36:27 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 19\n",
      "2023-04-01 17:36:27 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 17:36:27.729778\n",
      "epoch-19: 100%|██████████| 9000/9000 [08:00<00:00, 18.71it/s, loss=2.2766562]\n",
      "2023-04-01 17:44:28 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 17:44:28 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 19\n",
      "2023-04-01 17:44:29 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 19 finished, train loss = 1.8476686478\n",
      "2023-04-01 17:44:29 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 17:44:29.092851\n",
      "2023-04-01 17:44:29 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:01.363073\n",
      "2023-04-01 17:44:29 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 19: 100%|██████████| 1500/1500 [00:31<00:00, 48.00it/s, loss=2.6621597]\n",
      "2023-04-01 17:45:00 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 17:45:00 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9583109617\n",
      "2023-04-01 17:45:00 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 20\n",
      "2023-04-01 17:45:00 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 17:45:00.350851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-20: 100%|██████████| 9000/9000 [08:02<00:00, 18.64it/s, loss=2.2836251]\n",
      "2023-04-01 17:53:03 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 17:53:03 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 20\n",
      "2023-04-01 17:53:03 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 20 finished, train loss = 1.8477418423\n",
      "2023-04-01 17:53:03 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 17:53:03.677853\n",
      "2023-04-01 17:53:03 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:03.327002\n",
      "2023-04-01 17:53:03 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 20: 100%|██████████| 1500/1500 [00:30<00:00, 48.42it/s, loss=2.6576827]\n",
      "2023-04-01 17:53:34 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 17:53:34 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9584904909\n",
      "2023-04-01 17:53:34 - 1501083698.py - <module> - 99 - INFO\n",
      "Early stopping\n",
      "2023-04-01 17:53:34 - 1501083698.py - <module> - 104 - INFO\n",
      "training finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 2\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "early_stopping = EarlyStopping(output_dir)\n",
    "train_step_per_epoch = len(train_dataloader)\n",
    "valid_step_per_epoch = len(valid_dataloader)\n",
    "for epoch in range(epochs):\n",
    "    logger.info('epoch {}'.format(epoch + 1))\n",
    "    now = datetime.now()\n",
    "    logger.info('time: {}'.format(now))\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_dataloader)\n",
    "    all_train_loss = 0.0\n",
    "    train_pbar.set_description('epoch-' + str(epoch + 1))\n",
    "    \n",
    "    for step, (input, label, private_positions) in enumerate(train_pbar):\n",
    "        input_ids = torch.tensor(label).long().to(device)\n",
    "        label_ids = torch.tensor(input).long().to(device)\n",
    "        private_positions = torch.tensor(private_positions, dtype=torch.long).to(device)\n",
    "\n",
    "        #  forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=label_ids, private_positions=private_positions, sigma=sigma)\n",
    "        loss, logits = outputs[:2]\n",
    "        \n",
    "        if gradient_accumulation > 1:\n",
    "            loss = loss / gradient_accumulation\n",
    "            \n",
    "        #  loss backward\n",
    "        # if fp16:\n",
    "        #     with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #         scaled_loss.backward()\n",
    "        #         torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), max_grad_norm)\n",
    "        # else:\n",
    "        #     loss.backward()\n",
    "        #     torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        loss.backward()\n",
    "        loss = loss.detach()\n",
    "        all_train_loss += loss\n",
    "        \n",
    "        writer.add_scalar('loss/train_step_loss', scalar_value=loss * gradient_accumulation, global_step=epoch * train_step_per_epoch+step)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        #  optimizer step\n",
    "        if (step + 1) % gradient_accumulation == 0:\n",
    "            running_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        if (step + 1) % log_step == 0:\n",
    "            logger.info('now time: {}:{}. Step {} of epoch {}, loss {}'.format(\n",
    "                datetime.now().hour,\n",
    "                datetime.now().minute,\n",
    "                (step + 1) // gradient_accumulation,\n",
    "                epoch + 1,\n",
    "                running_loss / log_step))\n",
    "            running_loss = 0\n",
    "        \n",
    "        train_pbar.set_postfix({'loss': '{:.7f}'.format(loss*gradient_accumulation)})\n",
    "        \n",
    "    logger.info('train step = {}'.format(step))\n",
    "    all_train_loss = all_train_loss / (step + 1)\n",
    "\n",
    "    writer.add_scalar('loss/train_epoch_loss', scalar_value=all_train_loss * gradient_accumulation, global_step=epoch + 1)\n",
    "    logger.info('saving model for epoch {}'.format(epoch + 1))\n",
    "    if not os.path.exists(output_dir + 'model_epoch{}'.format(epoch + 1)):\n",
    "        os.mkdir(output_dir + 'model_epoch{}'.format(epoch + 1))\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    model_to_save.save_pretrained(output_dir + 'model_epoch{}'.format(epoch + 1))\n",
    "\n",
    "    logger.info('epoch {} finished, train loss = {:.10f}'.format(epoch + 1, all_train_loss * gradient_accumulation))\n",
    "\n",
    "    then = datetime.now()\n",
    "    logger.info('time: {}'.format(then))\n",
    "    logger.info('time for one epoch: {}'.format(then - now))\n",
    "    \n",
    "    logger.info('start validate')\n",
    "    model.eval()\n",
    "    all_valid_loss = 0.0\n",
    "    valid_pbar = tqdm(valid_dataloader)\n",
    "    valid_pbar.set_description('valid ' + str(epoch + 1))\n",
    "    for step, (input, label, private_positions) in enumerate(valid_pbar):\n",
    "        input_ids = torch.tensor(label).long().to(device)\n",
    "        label_ids = torch.tensor(input).long().to(device)\n",
    "        private_positions = torch.tensor(private_positions, dtype=torch.long).to(device)\n",
    "\n",
    "        #  forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=label_ids, private_positions=private_positions, sigma=sigma)\n",
    "        loss = outputs[0].detach()\n",
    "        writer.add_scalar('loss/valid_step_loss', scalar_value=loss, global_step=epoch * valid_step_per_epoch + step)\n",
    "        all_valid_loss += loss\n",
    "        valid_pbar.set_postfix({'loss': '{:.7f}'.format(loss)})\n",
    "    \n",
    "    logger.info('valid step = {}'.format(step))\n",
    "    all_valid_loss = all_valid_loss / (step + 1)\n",
    "    writer.add_scalar('loss/valid_epoch_loss', scalar_value=all_valid_loss, global_step=epoch+1)\n",
    "    logger.info('valid finished, valid loss = {:.10f}'.format(all_valid_loss))\n",
    "    early_stopping(all_valid_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        logger.info(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "writer.close()    \n",
    "\n",
    "logger.info('training finished')\n",
    "if not os.path.exists(output_dir + 'final_model'):\n",
    "    os.mkdir(output_dir + 'final_model')\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir + 'final_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a3cd800b0a689aaaf7f80ffde17840503226750eb3edba7eb3c5a252600cb17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
