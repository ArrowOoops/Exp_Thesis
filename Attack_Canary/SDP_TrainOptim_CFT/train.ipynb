{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2.modeling_gpt2 import GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers import BertTokenizer, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"Util to make training reproducible\"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    if os.getenv(\"CUBLAS_WORKSPACE_CONFIG\") is not None:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def worker_init(worked_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def set_logger(path):\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    handler = logging.FileHandler(path + \"/train_log.txt\")\n",
    "    logger.setLevel(level=logging.INFO)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(filename)s - %(funcName)s - %(lineno)s - %(levelname)s\\n%(message)s\",\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    console = logging.StreamHandler()\n",
    "    console.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.addHandler(console)\n",
    "\n",
    "\n",
    "class Chinese_Medical_DS(Dataset):\n",
    "    def __init__(self, path, tokenizer, max_len=1024):\n",
    "        self.path = path\n",
    "        sentence = []\n",
    "        self.private_positions_list = []\n",
    "        \n",
    "        self.total_private_tokens = 0\n",
    "        self.total_tokens = 0\n",
    "        self.private_tokens_per_sentence = []\n",
    "        \n",
    "        with open(self.path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                sen_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(line.strip()))\n",
    "                full_sen = []\n",
    "                \n",
    "                full_sen.append(tokenizer.convert_tokens_to_ids('[MASK]'))\n",
    "                full_sen.extend(sen_ids)\n",
    "                full_sen.append(tokenizer.convert_tokens_to_ids('[CLS]'))\n",
    "                private_positions = [i for i, token_id in enumerate(full_sen) if tokenizer.decode([token_id]).isdigit()]\n",
    "                self.private_positions_list.append(private_positions)\n",
    "                if len(full_sen) <= max_len:\n",
    "                    sentence.append(full_sen)\n",
    "                \n",
    "                num_private_tokens = len(private_positions)\n",
    "                self.total_private_tokens += num_private_tokens\n",
    "                self.total_tokens += len(full_sen)\n",
    "                self.private_tokens_per_sentence.append(num_private_tokens)\n",
    "                \n",
    "        self.data = sentence\n",
    "        \n",
    "        # 计算平均每句话中的隐私token数\n",
    "        average_private_tokens_per_sentence = sum(self.private_tokens_per_sentence) / len(self.private_tokens_per_sentence)\n",
    "\n",
    "        # 计算总的隐私token占总token的比例\n",
    "        private_token_ratio = self.total_private_tokens / self.total_tokens\n",
    "\n",
    "        # 计算隐私token个数的均值和方差\n",
    "        private_token_mean = np.mean(self.private_tokens_per_sentence)\n",
    "        private_token_variance = np.var(self.private_tokens_per_sentence)\n",
    "\n",
    "        # 打印统计信息\n",
    "        print(f\"Average private tokens per sentence: {average_private_tokens_per_sentence:.2f}\")\n",
    "        print(f\"Private token ratio: {private_token_ratio:.4f}\")\n",
    "        print(f\"Private token count mean: {private_token_mean:.2f}\")\n",
    "        print(f\"Private token count variance: {private_token_variance:.2f}\")\n",
    "        \n",
    "    # need to overload\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # need to overload\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.data[idx]\n",
    "        target = input\n",
    "        private_positions = self.private_positions_list[idx]\n",
    "        return input, target, private_positions\n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(self, save_path, patience=2, verbose=True, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            save_path : 模型保存文件夹\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.save_path = save_path\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        model_to_save.save_pretrained(self.save_path + 'best_model')\n",
    "        \n",
    "        # path = os.path.join(self.save_path, \"best_network.pth\")\n",
    "        # torch.save(model.state_dict(), path)  # 这里会存储迄今最优模型的参数\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "tok_path = '..\\\\..\\\\Raw_GPT2\\\\vocab.txt'\n",
    "pretrain_model_path = \"..\\\\..\\\\Raw_GPT2\\\\\"\n",
    "output_dir = \"model\\\\\"\n",
    "\n",
    "epochs = 50\n",
    "warmup_steps = 1000\n",
    "lr = 1e-5\n",
    "gradient_accumulation = 18\n",
    "max_grad_norm = 1.0\n",
    "log_step = 10000\n",
    "set_logger(output_dir)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel::init\n",
      "config =  GPT2Config {\n",
      "  \"_name_or_path\": \"..\\\\..\\\\Raw_GPT2\\\\\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"output_past\": true,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 320\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 19:09:57 - 945538542.py - <module> - 4 - INFO\n",
      "using device:cuda\n",
      "2023-04-01 19:09:57 - 945538542.py - <module> - 7 - INFO\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(21128, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer(vocab_file=tok_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(pretrain_model_path)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "logger.info('using device:{}'.format(device))\n",
    "model.train()\n",
    "model.to(device)\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average private tokens per sentence: 1.22\n",
      "Private token ratio: 0.0055\n",
      "Private token count mean: 1.22\n",
      "Private token count variance: 4.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 19:10:56 - 1768740697.py - <module> - 5 - INFO\n",
      "len(train_dataloader), len(valid_dataloader) = 9000, 1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average private tokens per sentence: 1.22\n",
      "Private token ratio: 0.0055\n",
      "Private token count mean: 1.22\n",
      "Private token count variance: 5.27\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Chinese_Medical_DS(\"..\\\\Data_With_Canary\\\\tiny_train.txt\", tokenizer)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, worker_init_fn=worker_init)\n",
    "valid_dataset = Chinese_Medical_DS(\"..\\\\Data_With_Canary\\\\tiny_valid.txt\", tokenizer)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, worker_init_fn=worker_init)\n",
    "logger.info(\"len(train_dataloader), len(valid_dataloader) = {}, {}\".format(len(train_dataloader), len(valid_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
    "                                                          num_training_steps=len(train_dataloader))\n",
    "tb_path = output_dir + \"/tb\"\n",
    "if not os.path.exists(tb_path):\n",
    "    os.mkdir(tb_path)\n",
    "writer = SummaryWriter(tb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1e-05, 0.810546875)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_log = len(train_dataloader) * np.log(len(train_dataloader))\n",
    "delta = 1.0 / train_num_log if 1.0 / train_num_log < 1e-5 else 1e-5\n",
    "epsilon = 0.5\n",
    "sigma = 0.810546875\n",
    "epsilon, delta, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 19:11:33 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 1\n",
      "2023-04-01 19:11:33 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 19:11:33.665602\n",
      "epoch-1: 100%|██████████| 9000/9000 [08:28<00:00, 17.72it/s, loss=2.8891165]\n",
      "2023-04-01 19:20:01 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 19:20:01 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 1\n",
      "2023-04-01 19:20:02 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 1 finished, train loss = 2.6338682175\n",
      "2023-04-01 19:20:02 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 19:20:02.054110\n",
      "2023-04-01 19:20:02 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:28.388508\n",
      "2023-04-01 19:20:02 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 1: 100%|██████████| 1500/1500 [00:33<00:00, 45.11it/s, loss=2.7356434]\n",
      "2023-04-01 19:20:35 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 19:20:35 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.4039025307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 2.403903).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 19:20:35 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 2\n",
      "2023-04-01 19:20:35 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 19:20:35.710905\n",
      "epoch-2: 100%|██████████| 9000/9000 [08:22<00:00, 17.93it/s, loss=2.6652870]\n",
      "2023-04-01 19:28:57 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 19:28:57 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 2\n",
      "2023-04-01 19:28:58 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 2 finished, train loss = 2.3730046749\n",
      "2023-04-01 19:28:58 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 19:28:58.130479\n",
      "2023-04-01 19:28:58 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:22.419574\n",
      "2023-04-01 19:28:58 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 2: 100%|██████████| 1500/1500 [00:31<00:00, 47.31it/s, loss=2.6948478]\n",
      "2023-04-01 19:29:29 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 19:29:29 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.2427144051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.403903 --> 2.242714).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 19:29:30 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 3\n",
      "2023-04-01 19:29:30 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 19:29:30.238533\n",
      "epoch-3: 100%|██████████| 9000/9000 [08:06<00:00, 18.50it/s, loss=2.5444379]\n",
      "2023-04-01 19:37:36 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 19:37:36 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 3\n",
      "2023-04-01 19:37:36 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 3 finished, train loss = 2.2254943848\n",
      "2023-04-01 19:37:36 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 19:37:36.996459\n",
      "2023-04-01 19:37:36 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:06.757926\n",
      "2023-04-01 19:37:36 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 3: 100%|██████████| 1500/1500 [00:31<00:00, 47.85it/s, loss=2.6843152]\n",
      "2023-04-01 19:38:08 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 19:38:08 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.1467971802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.242714 --> 2.146797).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 19:38:08 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 4\n",
      "2023-04-01 19:38:08 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 19:38:08.765694\n",
      "epoch-4: 100%|██████████| 9000/9000 [08:06<00:00, 18.50it/s, loss=2.4734716]\n",
      "2023-04-01 19:46:15 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 19:46:15 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 4\n",
      "2023-04-01 19:46:15 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 4 finished, train loss = 2.1333711147\n",
      "2023-04-01 19:46:15 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 19:46:15.686600\n",
      "2023-04-01 19:46:15 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:06.920906\n",
      "2023-04-01 19:46:15 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 4: 100%|██████████| 1500/1500 [00:31<00:00, 47.57it/s, loss=2.6628971]\n",
      "2023-04-01 19:46:47 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 19:46:47 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0957484245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.146797 --> 2.095748).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 19:46:47 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 5\n",
      "2023-04-01 19:46:47 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 19:46:47.617201\n",
      "epoch-5: 100%|██████████| 9000/9000 [08:05<00:00, 18.53it/s, loss=2.4102702]\n",
      "2023-04-01 19:54:53 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 19:54:53 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 5\n",
      "2023-04-01 19:54:53 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 5 finished, train loss = 2.0733387470\n",
      "2023-04-01 19:54:53 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 19:54:53.743605\n",
      "2023-04-01 19:54:53 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:06.126404\n",
      "2023-04-01 19:54:53 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 5: 100%|██████████| 1500/1500 [00:31<00:00, 47.40it/s, loss=2.6537900]\n",
      "2023-04-01 19:55:25 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 19:55:25 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0616388321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.095748 --> 2.061639).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 19:55:25 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 6\n",
      "2023-04-01 19:55:25 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 19:55:25.790013\n",
      "epoch-6: 100%|██████████| 9000/9000 [07:58<00:00, 18.80it/s, loss=2.4510117]\n",
      "2023-04-01 20:03:24 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 20:03:24 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 6\n",
      "2023-04-01 20:03:24 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 6 finished, train loss = 2.0295300484\n",
      "2023-04-01 20:03:24 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 20:03:24.955696\n",
      "2023-04-01 20:03:24 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:07:59.165683\n",
      "2023-04-01 20:03:24 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 6: 100%|██████████| 1500/1500 [00:30<00:00, 49.58it/s, loss=2.6595862]\n",
      "2023-04-01 20:03:55 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 20:03:55 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0383496284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.061639 --> 2.038350).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:03:55 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 7\n",
      "2023-04-01 20:03:55 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 20:03:55.611697\n",
      "epoch-7: 100%|██████████| 9000/9000 [07:55<00:00, 18.95it/s, loss=2.3808010]\n",
      "2023-04-01 20:11:50 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 20:11:50 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 7\n",
      "2023-04-01 20:11:51 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 7 finished, train loss = 1.9947050810\n",
      "2023-04-01 20:11:51 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 20:11:51.025694\n",
      "2023-04-01 20:11:51 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:07:55.413997\n",
      "2023-04-01 20:11:51 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 7: 100%|██████████| 1500/1500 [00:30<00:00, 49.18it/s, loss=2.6488523]\n",
      "2023-04-01 20:12:21 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 20:12:21 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0208544731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.038350 --> 2.020854).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:12:21 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 8\n",
      "2023-04-01 20:12:21 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 20:12:21.967695\n",
      "epoch-8: 100%|██████████| 9000/9000 [07:54<00:00, 18.95it/s, loss=2.3870430]\n",
      "2023-04-01 20:20:16 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 20:20:16 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 8\n",
      "2023-04-01 20:20:17 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 8 finished, train loss = 1.9670472145\n",
      "2023-04-01 20:20:17 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 20:20:17.208696\n",
      "2023-04-01 20:20:17 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:07:55.241001\n",
      "2023-04-01 20:20:17 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 8: 100%|██████████| 1500/1500 [00:30<00:00, 49.42it/s, loss=2.6449416]\n",
      "2023-04-01 20:20:47 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 20:20:47 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 2.0058350563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.020854 --> 2.005835).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:20:47 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 9\n",
      "2023-04-01 20:20:47 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 20:20:47.957697\n",
      "epoch-9: 100%|██████████| 9000/9000 [07:55<00:00, 18.93it/s, loss=2.3835890]\n",
      "2023-04-01 20:28:43 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 20:28:43 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 9\n",
      "2023-04-01 20:28:43 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 9 finished, train loss = 1.9439495802\n",
      "2023-04-01 20:28:43 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 20:28:43.688695\n",
      "2023-04-01 20:28:43 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:07:55.730998\n",
      "2023-04-01 20:28:43 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 9: 100%|██████████| 1500/1500 [00:30<00:00, 49.37it/s, loss=2.6519995]\n",
      "2023-04-01 20:29:14 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 20:29:14 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9964252710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.005835 --> 1.996425).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:29:14 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 10\n",
      "2023-04-01 20:29:14 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 20:29:14.495695\n",
      "epoch-10: 100%|██████████| 9000/9000 [07:55<00:00, 18.94it/s, loss=2.3429942]\n",
      "2023-04-01 20:37:09 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 20:37:09 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 10\n",
      "2023-04-01 20:37:10 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 10 finished, train loss = 1.9241091013\n",
      "2023-04-01 20:37:10 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 20:37:10.184695\n",
      "2023-04-01 20:37:10 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:07:55.689000\n",
      "2023-04-01 20:37:10 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 10: 100%|██████████| 1500/1500 [00:30<00:00, 49.14it/s, loss=2.6512003]\n",
      "2023-04-01 20:37:40 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 20:37:40 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9869954586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.996425 --> 1.986995).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:37:41 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 11\n",
      "2023-04-01 20:37:41 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 20:37:41.106696\n",
      "epoch-11: 100%|██████████| 9000/9000 [07:55<00:00, 18.93it/s, loss=2.3166363]\n",
      "2023-04-01 20:45:36 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 20:45:36 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 11\n",
      "2023-04-01 20:45:36 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 11 finished, train loss = 1.9068742990\n",
      "2023-04-01 20:45:36 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 20:45:36.944695\n",
      "2023-04-01 20:45:36 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:07:55.837999\n",
      "2023-04-01 20:45:36 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 11: 100%|██████████| 1500/1500 [00:30<00:00, 49.38it/s, loss=2.6446867]\n",
      "2023-04-01 20:46:07 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 20:46:07 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9800143242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.986995 --> 1.980014).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:46:07 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 12\n",
      "2023-04-01 20:46:07 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 20:46:07.716737\n",
      "epoch-12: 100%|██████████| 9000/9000 [07:55<00:00, 18.92it/s, loss=2.3014100]\n",
      "2023-04-01 20:54:03 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 20:54:03 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 12\n",
      "2023-04-01 20:54:03 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 12 finished, train loss = 1.8927189112\n",
      "2023-04-01 20:54:03 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 20:54:03.765736\n",
      "2023-04-01 20:54:03 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:07:56.048999\n",
      "2023-04-01 20:54:03 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 12: 100%|██████████| 1500/1500 [00:30<00:00, 49.13it/s, loss=2.6376595]\n",
      "2023-04-01 20:54:34 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 20:54:34 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9739099741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.980014 --> 1.973910).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 20:54:34 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 13\n",
      "2023-04-01 20:54:34 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 20:54:34.707737\n",
      "epoch-13: 100%|██████████| 9000/9000 [07:56<00:00, 18.89it/s, loss=2.3063149]\n",
      "2023-04-01 21:02:31 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 21:02:31 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 13\n",
      "2023-04-01 21:02:31 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 13 finished, train loss = 1.8808150291\n",
      "2023-04-01 21:02:31 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 21:02:31.620736\n",
      "2023-04-01 21:02:31 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:07:56.912999\n",
      "2023-04-01 21:02:31 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 13: 100%|██████████| 1500/1500 [00:30<00:00, 49.47it/s, loss=2.6389885]\n",
      "2023-04-01 21:03:01 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 21:03:01 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9695862532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.973910 --> 1.969586).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 21:03:02 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 14\n",
      "2023-04-01 21:03:02 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 21:03:02.342736\n",
      "epoch-14: 100%|██████████| 9000/9000 [07:55<00:00, 18.92it/s, loss=2.2826343]\n",
      "2023-04-01 21:10:58 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 21:10:58 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 14\n",
      "2023-04-01 21:10:58 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 14 finished, train loss = 1.8708097935\n",
      "2023-04-01 21:10:58 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 21:10:58.501738\n",
      "2023-04-01 21:10:58 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:07:56.159002\n",
      "2023-04-01 21:10:58 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 14: 100%|██████████| 1500/1500 [00:30<00:00, 49.14it/s, loss=2.6468775]\n",
      "2023-04-01 21:11:29 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 21:11:29 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9660209417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.969586 --> 1.966021).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 21:11:29 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 15\n",
      "2023-04-01 21:11:29 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 21:11:29.414736\n",
      "epoch-15: 100%|██████████| 9000/9000 [08:26<00:00, 17.77it/s, loss=2.2829337]\n",
      "2023-04-01 21:19:55 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 21:19:55 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 15\n",
      "2023-04-01 21:19:56 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 15 finished, train loss = 1.8634200096\n",
      "2023-04-01 21:19:56 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 21:19:56.201429\n",
      "2023-04-01 21:19:56 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:08:26.786693\n",
      "2023-04-01 21:19:56 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 15: 100%|██████████| 1500/1500 [00:32<00:00, 46.71it/s, loss=2.6436141]\n",
      "2023-04-01 21:20:28 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 21:20:28 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9632148743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.966021 --> 1.963215).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 21:20:28 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 16\n",
      "2023-04-01 21:20:28 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 21:20:28.764428\n",
      "epoch-16: 100%|██████████| 9000/9000 [09:31<00:00, 15.75it/s, loss=2.2885120]\n",
      "2023-04-01 21:30:00 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 21:30:00 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 16\n",
      "2023-04-01 21:30:00 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 16 finished, train loss = 1.8571434021\n",
      "2023-04-01 21:30:00 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 21:30:00.663430\n",
      "2023-04-01 21:30:00 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:09:31.899002\n",
      "2023-04-01 21:30:00 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 16: 100%|██████████| 1500/1500 [00:32<00:00, 46.21it/s, loss=2.6435807]\n",
      "2023-04-01 21:30:33 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 21:30:33 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9613745213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.963215 --> 1.961375).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 21:30:33 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 17\n",
      "2023-04-01 21:30:33 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 21:30:33.533430\n",
      "epoch-17: 100%|██████████| 9000/9000 [09:51<00:00, 15.21it/s, loss=2.3058000]\n",
      "2023-04-01 21:40:25 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 21:40:25 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 17\n",
      "2023-04-01 21:40:25 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 17 finished, train loss = 1.8524532318\n",
      "2023-04-01 21:40:25 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 21:40:25.902180\n",
      "2023-04-01 21:40:25 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:09:52.368750\n",
      "2023-04-01 21:40:25 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 17: 100%|██████████| 1500/1500 [00:42<00:00, 35.01it/s, loss=2.6549041]\n",
      "2023-04-01 21:41:08 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 21:41:08 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9597691298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.961375 --> 1.959769).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 21:41:09 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 18\n",
      "2023-04-01 21:41:09 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 21:41:09.248804\n",
      "epoch-18: 100%|██████████| 9000/9000 [10:18<00:00, 14.56it/s, loss=2.2248588]\n",
      "2023-04-01 21:51:27 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 21:51:27 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 18\n",
      "2023-04-01 21:51:28 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 18 finished, train loss = 1.8498368263\n",
      "2023-04-01 21:51:28 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 21:51:28.022978\n",
      "2023-04-01 21:51:28 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:10:18.774174\n",
      "2023-04-01 21:51:28 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 18: 100%|██████████| 1500/1500 [00:42<00:00, 34.99it/s, loss=2.6580944]\n",
      "2023-04-01 21:52:10 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 21:52:10 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9583472013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.959769 --> 1.958347).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 21:52:11 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 19\n",
      "2023-04-01 21:52:11 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 21:52:11.379533\n",
      "epoch-19: 100%|██████████| 9000/9000 [10:15<00:00, 14.61it/s, loss=2.3143201]\n",
      "2023-04-01 22:02:27 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 22:02:27 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 19\n",
      "2023-04-01 22:02:27 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 19 finished, train loss = 1.8479902744\n",
      "2023-04-01 22:02:27 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 22:02:27.638559\n",
      "2023-04-01 22:02:27 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:10:16.259026\n",
      "2023-04-01 22:02:27 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 19: 100%|██████████| 1500/1500 [00:53<00:00, 28.14it/s, loss=2.6542649]\n",
      "2023-04-01 22:03:20 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 22:03:20 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9583510160\n",
      "2023-04-01 22:03:20 - 1501083698.py - <module> - 6 - INFO\n",
      "epoch 20\n",
      "2023-04-01 22:03:20 - 1501083698.py - <module> - 8 - INFO\n",
      "time: 2023-04-01 22:03:20.959692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-20: 100%|██████████| 9000/9000 [11:22<00:00, 13.18it/s, loss=2.2997625]\n",
      "2023-04-01 22:14:43 - 1501083698.py - <module> - 60 - INFO\n",
      "train step = 8999\n",
      "2023-04-01 22:14:43 - 1501083698.py - <module> - 64 - INFO\n",
      "saving model for epoch 20\n",
      "2023-04-01 22:14:44 - 1501083698.py - <module> - 70 - INFO\n",
      "epoch 20 finished, train loss = 1.8477326632\n",
      "2023-04-01 22:14:44 - 1501083698.py - <module> - 73 - INFO\n",
      "time: 2023-04-01 22:14:44.053168\n",
      "2023-04-01 22:14:44 - 1501083698.py - <module> - 74 - INFO\n",
      "time for one epoch: 0:11:23.093476\n",
      "2023-04-01 22:14:44 - 1501083698.py - <module> - 76 - INFO\n",
      "start validate\n",
      "valid 20: 100%|██████████| 1500/1500 [00:52<00:00, 28.74it/s, loss=2.6515772]\n",
      "2023-04-01 22:15:36 - 1501083698.py - <module> - 93 - INFO\n",
      "valid step = 1499\n",
      "2023-04-01 22:15:36 - 1501083698.py - <module> - 96 - INFO\n",
      "valid finished, valid loss = 1.9584604502\n",
      "2023-04-01 22:15:36 - 1501083698.py - <module> - 99 - INFO\n",
      "Early stopping\n",
      "2023-04-01 22:15:36 - 1501083698.py - <module> - 104 - INFO\n",
      "training finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 2\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "early_stopping = EarlyStopping(output_dir)\n",
    "train_step_per_epoch = len(train_dataloader)\n",
    "valid_step_per_epoch = len(valid_dataloader)\n",
    "for epoch in range(epochs):\n",
    "    logger.info('epoch {}'.format(epoch + 1))\n",
    "    now = datetime.now()\n",
    "    logger.info('time: {}'.format(now))\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_dataloader)\n",
    "    all_train_loss = 0.0\n",
    "    train_pbar.set_description('epoch-' + str(epoch + 1))\n",
    "    \n",
    "    for step, (input, label, private_positions) in enumerate(train_pbar):\n",
    "        input_ids = torch.tensor(label).long().to(device)\n",
    "        label_ids = torch.tensor(input).long().to(device)\n",
    "        private_positions = torch.tensor(private_positions, dtype=torch.long).to(device)\n",
    "\n",
    "        #  forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=label_ids, private_positions=private_positions, sigma=sigma)\n",
    "        loss, logits = outputs[:2]\n",
    "        \n",
    "        if gradient_accumulation > 1:\n",
    "            loss = loss / gradient_accumulation\n",
    "            \n",
    "        #  loss backward\n",
    "        # if fp16:\n",
    "        #     with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #         scaled_loss.backward()\n",
    "        #         torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), max_grad_norm)\n",
    "        # else:\n",
    "        #     loss.backward()\n",
    "        #     torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        loss.backward()\n",
    "        loss = loss.detach()\n",
    "        all_train_loss += loss\n",
    "        \n",
    "        writer.add_scalar('loss/train_step_loss', scalar_value=loss * gradient_accumulation, global_step=epoch * train_step_per_epoch+step)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        #  optimizer step\n",
    "        if (step + 1) % gradient_accumulation == 0:\n",
    "            running_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        if (step + 1) % log_step == 0:\n",
    "            logger.info('now time: {}:{}. Step {} of epoch {}, loss {}'.format(\n",
    "                datetime.now().hour,\n",
    "                datetime.now().minute,\n",
    "                (step + 1) // gradient_accumulation,\n",
    "                epoch + 1,\n",
    "                running_loss / log_step))\n",
    "            running_loss = 0\n",
    "        \n",
    "        train_pbar.set_postfix({'loss': '{:.7f}'.format(loss*gradient_accumulation)})\n",
    "        \n",
    "    logger.info('train step = {}'.format(step))\n",
    "    all_train_loss = all_train_loss / (step + 1)\n",
    "\n",
    "    writer.add_scalar('loss/train_epoch_loss', scalar_value=all_train_loss * gradient_accumulation, global_step=epoch + 1)\n",
    "    logger.info('saving model for epoch {}'.format(epoch + 1))\n",
    "    if not os.path.exists(output_dir + 'model_epoch{}'.format(epoch + 1)):\n",
    "        os.mkdir(output_dir + 'model_epoch{}'.format(epoch + 1))\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    model_to_save.save_pretrained(output_dir + 'model_epoch{}'.format(epoch + 1))\n",
    "\n",
    "    logger.info('epoch {} finished, train loss = {:.10f}'.format(epoch + 1, all_train_loss * gradient_accumulation))\n",
    "\n",
    "    then = datetime.now()\n",
    "    logger.info('time: {}'.format(then))\n",
    "    logger.info('time for one epoch: {}'.format(then - now))\n",
    "    \n",
    "    logger.info('start validate')\n",
    "    model.eval()\n",
    "    all_valid_loss = 0.0\n",
    "    valid_pbar = tqdm(valid_dataloader)\n",
    "    valid_pbar.set_description('valid ' + str(epoch + 1))\n",
    "    for step, (input, label, private_positions) in enumerate(valid_pbar):\n",
    "        input_ids = torch.tensor(label).long().to(device)\n",
    "        label_ids = torch.tensor(input).long().to(device)\n",
    "        private_positions = torch.tensor(private_positions, dtype=torch.long).to(device)\n",
    "\n",
    "        #  forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=label_ids, private_positions=private_positions, sigma=sigma)\n",
    "        loss = outputs[0].detach()\n",
    "        writer.add_scalar('loss/valid_step_loss', scalar_value=loss, global_step=epoch * valid_step_per_epoch + step)\n",
    "        all_valid_loss += loss\n",
    "        valid_pbar.set_postfix({'loss': '{:.7f}'.format(loss)})\n",
    "    \n",
    "    logger.info('valid step = {}'.format(step))\n",
    "    all_valid_loss = all_valid_loss / (step + 1)\n",
    "    writer.add_scalar('loss/valid_epoch_loss', scalar_value=all_valid_loss, global_step=epoch+1)\n",
    "    logger.info('valid finished, valid loss = {:.10f}'.format(all_valid_loss))\n",
    "    early_stopping(all_valid_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        logger.info(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "writer.close()    \n",
    "\n",
    "logger.info('training finished')\n",
    "if not os.path.exists(output_dir + 'final_model'):\n",
    "    os.mkdir(output_dir + 'final_model')\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir + 'final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f7b73ba524e88845b42eccf09a61b9b08c93ae28f46a34fd5f42c74d9518f42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
