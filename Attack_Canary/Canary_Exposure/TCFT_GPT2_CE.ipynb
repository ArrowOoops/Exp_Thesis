{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import math\n",
    "from transformers import BertTokenizer, GPT2LMHeadModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CanaryDataset(Dataset):\n",
    "    def __init__(self, canary, tokenizer, num_digit):\n",
    "        self.canary = canary\n",
    "        self.tokenizer = tokenizer\n",
    "        if num_digit == 1:\n",
    "            self.data = self.build_data_1()\n",
    "        elif num_digit == 2:\n",
    "            self.data = self.build_data_2()\n",
    "        elif num_digit == 3:\n",
    "            self.data = self.build_data_3()\n",
    "        elif num_digit == 4:\n",
    "            self.data = self.build_data_4()\n",
    "        elif num_digit == 5:\n",
    "            self.data = self.build_data_5()\n",
    "        elif num_digit == 6:\n",
    "            self.data = self.build_data_6()\n",
    "    \n",
    "    def build_data_1(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            text = f'我的单号是54168{i}'\n",
    "            texts.append(text)\n",
    "            encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "    \n",
    "    def build_data_2(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                text = f'我的单号是5416{i}{j}'\n",
    "                texts.append(text)\n",
    "                encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "\n",
    "    def build_data_3(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    text = f'我的单号是541{i}{j}{k}'\n",
    "                    texts.append(text)\n",
    "                    encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "    \n",
    "    def build_data_4(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    for l in range(10):\n",
    "                        text = f'我的单号是54{i}{j}{k}{l}'\n",
    "                        texts.append(text)\n",
    "                        encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "    \n",
    "    def build_data_5(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    for l in range(10):\n",
    "                        for m in range(10):\n",
    "                            text = f'我的单号是5{i}{j}{k}{l}{m}'\n",
    "                            texts.append(text)\n",
    "                            encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "    \n",
    "    def build_data_6(self):\n",
    "        # '我的单号是541684'\n",
    "        texts = []\n",
    "        encoded_texts = []\n",
    "        for i in tqdm(range(10)):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    for l in range(10):\n",
    "                        for m in range(10):\n",
    "                            for n in range(10):\n",
    "                                text = f'我的单号是{i}{j}{k}{l}{m}{n}'\n",
    "                                texts.append(text)\n",
    "                                encoded_texts.append(self.tokenizer.encode(text))\n",
    "        assert self.canary in texts\n",
    "        return list(zip(texts, encoded_texts))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def collate(self, unpacked_data):\n",
    "        texts, encoded_texts = zip(*unpacked_data)\n",
    "        max_length = max([len(encoded_text) for encoded_text in encoded_texts])\n",
    "        padded_encoded_texts = [\n",
    "            encoded_text + [self.tokenizer.pad_token_id] * (max_length - len(encoded_text))\n",
    "            for encoded_text in encoded_texts\n",
    "        ]\n",
    "        return texts, torch.tensor(padded_encoded_texts)\n",
    "\n",
    "def calculate_ppl(inputs, model):\n",
    "    device = model.device\n",
    "    input_ids = inputs.to(device)\n",
    "    label_ids = input_ids.clone()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, labels=label_ids)\n",
    "        loss = output.loss\n",
    "        sequence_lengths = len(input_ids)\n",
    "        ppl_steps = torch.exp(loss / sequence_lengths)\n",
    "\n",
    "    return ppl_steps.cpu().numpy()\n",
    "\n",
    "def get_exposure(model, dataloader, CANARY, TOTAL_CANDIDATES):\n",
    "    ppls = {}\n",
    "    forward_pbar = tqdm(dataloader)\n",
    "    forward_pbar.set_description('forward execution')\n",
    "    for batch_input in forward_pbar:\n",
    "        input_text, input_encoded_text = batch_input\n",
    "        # batch_ppl = calculate_ppl(input_encoded_text, model)\n",
    "        batch_ppl = [calculate_ppl(encoded_text, model) for encoded_text in input_encoded_text]\n",
    "        ppls.update(dict(zip(input_text, batch_ppl)))\n",
    "        forward_pbar.set_postfix({'ppl': '{:.7f}'.format(np.array(batch_ppl).mean())})\n",
    "\n",
    "    sorted_ppls = {k: (i+1, v) for i, (k, v) in enumerate(sorted(ppls.items(), key=lambda item: item[1]))}\n",
    "    N = len(sorted_ppls)\n",
    "    canary_rank, canary_ppl = sorted_ppls[CANARY]\n",
    "\n",
    "    canary_exposure = math.log(TOTAL_CANDIDATES, 2) - math.log(canary_rank, 2)\n",
    "\n",
    "    print(\"canary ppl = \", canary_ppl)\n",
    "    print(\"canary exposure = \", canary_exposure)\n",
    "    print(\"canary ranking = \", canary_rank)\n",
    "\n",
    "    return canary_exposure, canary_rank, canary_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(21128, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"..\\\\Tiny_CFT_GPT2\\\\model\\\\best_model\\\\\"\n",
    "tok_path = '..\\\\..\\\\Raw_GPT2\\\\vocab.txt'\n",
    "CANARY = '我的单号是541684'\n",
    "tokenizer = BertTokenizer(vocab_file=tok_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device:{}'.format(device))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "now testing generate  1  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 3335.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s, ppl=1.4894146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  1.4762846\n",
      "canary exposure =  2.3219280948873626\n",
      "canary ranking =  2\n",
      "============================================================\n",
      "============================================================\n",
      "now testing generate  2  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 588.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 7/7 [00:05<00:00,  1.28it/s, ppl=1.5280195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  1.4762846\n",
      "canary exposure =  5.643856189774725\n",
      "canary ranking =  2\n",
      "============================================================\n",
      "============================================================\n",
      "now testing generate  3  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 62.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 63/63 [00:53<00:00,  1.18it/s, ppl=1.5303351]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  1.4762846\n",
      "canary exposure =  5.573466861883326\n",
      "canary ranking =  21\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_num = [1, 2, 3]\n",
    "for i in test_num:\n",
    "    print('='*60)\n",
    "    print('now testing generate ', i, ' number:')\n",
    "    canary_corpus = CanaryDataset(CANARY, tokenizer, i)\n",
    "    print('len(canary_corpus) = ', len(canary_corpus))\n",
    "    dataloader = DataLoader(dataset=canary_corpus,\n",
    "                            shuffle=False,\n",
    "                            batch_size=16,\n",
    "                            collate_fn=canary_corpus.collate)\n",
    "\n",
    "    canary_exposure, canary_rank, canary_ppl = get_exposure(model, dataloader, CANARY, len(canary_corpus))\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "now testing generate  4  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 625/625 [08:30<00:00,  1.23it/s, ppl=1.5515778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  1.4762846\n",
      "canary exposure =  6.779917739350754\n",
      "canary ranking =  91\n",
      "============================================================\n",
      "============================================================\n",
      "now testing generate  5  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:07<00:00, 12.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution:   1%|          | 581/62500 [08:22<14:53:20,  1.16it/s, ppl=1.5533221]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\VSCode\\Experiment_Thesis\\Attack_Canary\\Canary_Exposure\\TCFT_GPT2_CE.ipynb 单元格 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlen(canary_corpus) = \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(canary_corpus))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39mcanary_corpus,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                         shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                         batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                         collate_fn\u001b[39m=\u001b[39mcanary_corpus\u001b[39m.\u001b[39mcollate)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m canary_exposure, canary_rank, canary_ppl \u001b[39m=\u001b[39m get_exposure(model, dataloader, CANARY, \u001b[39mlen\u001b[39;49m(canary_corpus))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m)\n",
      "\u001b[1;32md:\\VSCode\\Experiment_Thesis\\Attack_Canary\\Canary_Exposure\\TCFT_GPT2_CE.ipynb 单元格 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m input_text, input_encoded_text \u001b[39m=\u001b[39m batch_input\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39m# batch_ppl = calculate_ppl(input_encoded_text, model)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m batch_ppl \u001b[39m=\u001b[39m [calculate_ppl(encoded_text, model) \u001b[39mfor\u001b[39;00m encoded_text \u001b[39min\u001b[39;00m input_encoded_text]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m ppls\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(input_text, batch_ppl)))\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m forward_pbar\u001b[39m.\u001b[39mset_postfix({\u001b[39m'\u001b[39m\u001b[39mppl\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m{:.7f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39marray(batch_ppl)\u001b[39m.\u001b[39mmean())})\n",
      "\u001b[1;32md:\\VSCode\\Experiment_Thesis\\Attack_Canary\\Canary_Exposure\\TCFT_GPT2_CE.ipynb 单元格 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m input_text, input_encoded_text \u001b[39m=\u001b[39m batch_input\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39m# batch_ppl = calculate_ppl(input_encoded_text, model)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m batch_ppl \u001b[39m=\u001b[39m [calculate_ppl(encoded_text, model) \u001b[39mfor\u001b[39;00m encoded_text \u001b[39min\u001b[39;00m input_encoded_text]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m ppls\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(input_text, batch_ppl)))\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m forward_pbar\u001b[39m.\u001b[39mset_postfix({\u001b[39m'\u001b[39m\u001b[39mppl\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m{:.7f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39marray(batch_ppl)\u001b[39m.\u001b[39mmean())})\n",
      "\u001b[1;32md:\\VSCode\\Experiment_Thesis\\Attack_Canary\\Canary_Exposure\\TCFT_GPT2_CE.ipynb 单元格 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m label_ids \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mclone()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m     output \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39;49minput_ids, labels\u001b[39m=\u001b[39;49mlabel_ids)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m     loss \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mloss\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#X11sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     sequence_lengths \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(input_ids)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1046\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1046\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m   1047\u001b[0m     input_ids,\n\u001b[0;32m   1048\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1049\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1050\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1051\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1052\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1053\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1054\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1055\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1056\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1057\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1058\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1059\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1060\u001b[0m )\n\u001b[0;32m   1061\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1063\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:889\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    879\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    880\u001b[0m         create_custom_forward(block),\n\u001b[0;32m    881\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[0;32m    890\u001b[0m         hidden_states,\n\u001b[0;32m    891\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    892\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    893\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    894\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    895\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m    896\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    897\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    898\u001b[0m     )\n\u001b[0;32m    900\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    901\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:426\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    424\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m    425\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(hidden_states)\n\u001b[1;32m--> 426\u001b[0m feed_forward_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[0;32m    427\u001b[0m \u001b[39m# residual connection\u001b[39;00m\n\u001b[0;32m    428\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:355\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    353\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_fc(hidden_states)\n\u001b[0;32m    354\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(hidden_states)\n\u001b[1;32m--> 355\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc_proj(hidden_states)\n\u001b[0;32m    356\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    357\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\pytorch_utils.py:112\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    111\u001b[0m     size_out \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnf,)\n\u001b[1;32m--> 112\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49maddmm(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, x\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, x\u001b[39m.\u001b[39;49msize(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n\u001b[0;32m    113\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(size_out)\n\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_num = [4, 5]\n",
    "for i in test_num:\n",
    "    print('='*60)\n",
    "    print('now testing generate ', i, ' number:')\n",
    "    canary_corpus = CanaryDataset(CANARY, tokenizer, i)\n",
    "    print('len(canary_corpus) = ', len(canary_corpus))\n",
    "    dataloader = DataLoader(dataset=canary_corpus,\n",
    "                            shuffle=False,\n",
    "                            batch_size=16,\n",
    "                            collate_fn=canary_corpus.collate)\n",
    "\n",
    "    canary_exposure, canary_rank, canary_ppl = get_exposure(model, dataloader, CANARY, len(canary_corpus))\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "now testing generate  5  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:04<00:00, 12.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution: 100%|██████████| 7813/7813 [3:36:40<00:00,  1.66s/it, ppl=1.5337584]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canary ppl =  1.4762858\n",
      "canary exposure =  6.54382046861288\n",
      "canary ranking =  10718\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "test_num = [5]\n",
    "for i in test_num:\n",
    "    print('='*60)\n",
    "    print('now testing generate ', i, ' number:')\n",
    "    canary_corpus = CanaryDataset(CANARY, tokenizer, i)\n",
    "    print('len(canary_corpus) = ', len(canary_corpus))\n",
    "    dataloader = DataLoader(dataset=canary_corpus,\n",
    "                            shuffle=False,\n",
    "                            batch_size=128,\n",
    "                            collate_fn=canary_corpus.collate)\n",
    "\n",
    "    canary_exposure, canary_rank, canary_ppl = get_exposure(model, dataloader, CANARY, len(canary_corpus))\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "now testing generate  6  number:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:03<00:00, 12.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(canary_corpus) =  1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "forward execution:   2%|▏         | 64/3907 [03:41<3:41:38,  3.46s/it, ppl=1.5474856]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\VSCode\\Experiment_Thesis\\Attack_Canary\\Canary_Exposure\\TCFT_GPT2_CE.ipynb 单元格 7\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlen(canary_corpus) = \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(canary_corpus))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39mcanary_corpus,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                         shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                         batch_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                         collate_fn\u001b[39m=\u001b[39mcanary_corpus\u001b[39m.\u001b[39mcollate)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m canary_exposure, canary_rank, canary_ppl \u001b[39m=\u001b[39m get_exposure(model, dataloader, CANARY, \u001b[39mlen\u001b[39;49m(canary_corpus))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m)\n",
      "\u001b[1;32md:\\VSCode\\Experiment_Thesis\\Attack_Canary\\Canary_Exposure\\TCFT_GPT2_CE.ipynb 单元格 7\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m input_text, input_encoded_text \u001b[39m=\u001b[39m batch_input\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39m# batch_ppl = calculate_ppl(input_encoded_text, model)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m batch_ppl \u001b[39m=\u001b[39m [calculate_ppl(encoded_text, model) \u001b[39mfor\u001b[39;00m encoded_text \u001b[39min\u001b[39;00m input_encoded_text]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m ppls\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(input_text, batch_ppl)))\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m forward_pbar\u001b[39m.\u001b[39mset_postfix({\u001b[39m'\u001b[39m\u001b[39mppl\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m{:.7f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39marray(batch_ppl)\u001b[39m.\u001b[39mmean())})\n",
      "\u001b[1;32md:\\VSCode\\Experiment_Thesis\\Attack_Canary\\Canary_Exposure\\TCFT_GPT2_CE.ipynb 单元格 7\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m input_text, input_encoded_text \u001b[39m=\u001b[39m batch_input\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39m# batch_ppl = calculate_ppl(input_encoded_text, model)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m batch_ppl \u001b[39m=\u001b[39m [calculate_ppl(encoded_text, model) \u001b[39mfor\u001b[39;00m encoded_text \u001b[39min\u001b[39;00m input_encoded_text]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m ppls\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(input_text, batch_ppl)))\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m forward_pbar\u001b[39m.\u001b[39mset_postfix({\u001b[39m'\u001b[39m\u001b[39mppl\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m{:.7f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39marray(batch_ppl)\u001b[39m.\u001b[39mmean())})\n",
      "\u001b[1;32md:\\VSCode\\Experiment_Thesis\\Attack_Canary\\Canary_Exposure\\TCFT_GPT2_CE.ipynb 单元格 7\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m label_ids \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mclone()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m     output \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39;49minput_ids, labels\u001b[39m=\u001b[39;49mlabel_ids)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m     loss \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mloss\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/VSCode/Experiment_Thesis/Attack_Canary/Canary_Exposure/TCFT_GPT2_CE.ipynb#W6sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     sequence_lengths \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(input_ids)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1046\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1046\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m   1047\u001b[0m     input_ids,\n\u001b[0;32m   1048\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1049\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1050\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1051\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1052\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1053\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1054\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1055\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1056\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1057\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1058\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1059\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1060\u001b[0m )\n\u001b[0;32m   1061\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1063\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:889\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    879\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    880\u001b[0m         create_custom_forward(block),\n\u001b[0;32m    881\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[0;32m    890\u001b[0m         hidden_states,\n\u001b[0;32m    891\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    892\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    893\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    894\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    895\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m    896\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    897\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    898\u001b[0m     )\n\u001b[0;32m    900\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    901\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:389\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    387\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m    388\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(hidden_states)\n\u001b[1;32m--> 389\u001b[0m attn_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[0;32m    390\u001b[0m     hidden_states,\n\u001b[0;32m    391\u001b[0m     layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    392\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    393\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    394\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    395\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    396\u001b[0m )\n\u001b[0;32m    397\u001b[0m attn_output \u001b[39m=\u001b[39m attn_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[0;32m    398\u001b[0m outputs \u001b[39m=\u001b[39m attn_outputs[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:330\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    328\u001b[0m     attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m     attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attn(query, key, value, attention_mask, head_mask)\n\u001b[0;32m    332\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_heads(attn_output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n\u001b[0;32m    333\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_proj(attn_output)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201\u001b[0m, in \u001b[0;36mGPT2Attention._attn\u001b[1;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[39m# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[39m# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     mask_value \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(mask_value, dtype\u001b[39m=\u001b[39mattn_weights\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mto(attn_weights\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 201\u001b[0m     attn_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mwhere(causal_mask, attn_weights, mask_value)\n\u001b[0;32m    203\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m     \u001b[39m# Apply the attention mask\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights \u001b[39m+\u001b[39m attention_mask\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_num = [6]\n",
    "for i in test_num:\n",
    "    print('='*60)\n",
    "    print('now testing generate ', i, ' number:')\n",
    "    canary_corpus = CanaryDataset(CANARY, tokenizer, i)\n",
    "    print('len(canary_corpus) = ', len(canary_corpus))\n",
    "    dataloader = DataLoader(dataset=canary_corpus,\n",
    "                            shuffle=False,\n",
    "                            batch_size=256,\n",
    "                            collate_fn=canary_corpus.collate)\n",
    "\n",
    "    canary_exposure, canary_rank, canary_ppl = get_exposure(model, dataloader, CANARY, len(canary_corpus))\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f7b73ba524e88845b42eccf09a61b9b08c93ae28f46a34fd5f42c74d9518f42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
